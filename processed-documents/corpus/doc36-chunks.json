{"References": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nDeclaration of competing interest\nThe authors declare that they have no known competing finan-\ncial interests or personal relationships that could have appeared to\ninfluence the work reported in this paper.\nAcknowledgements\nThe authors would like to express their sincere gratitude to the\nEngineering and Physical Science Research Council (EPSRC) grant ref:\nEP/S031480/1 and the Innovate UK (Grant Application No 10137 and\nFile No 104367) for providing the financial support for this study.\nAppendix A. Nullness of features contained in the raw weather\ndatasets of the major cities of UK\nSee Figs. 14 and 15\nAppendix B. Comparison of rainfall predictions and true observed\nrainfall\nSee Fig. 16\nReferences\nAbadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., et al. (2015).\nTensorFlow: Large-scale machine learning on heterogeneous systems. URL http:\n//tensorflow.org/, Software available from tensorflow.org.\nAguasca-Colomo, R., Castellanos-Nieves, D., & M\u00e9ndez, M. (2019). Comparative analysis\nof rainfall prediction models using machine learning in islands with complex\norography: Tenerife island. Applied Sciences, 9(22), 4931.\nAkbari Asanjan, A., Yang, T., Hsu, K., Sorooshian, S., Lin, J., & Peng, Q. (2018). Short-\nterm precipitation forecast based on the PERSIANN System and LSTM recurrent\nneural networks. Journal of Geophysical Research: Atmospheres, 123(22), 12\u2013543.\nAltan, A., Karasu, S., & Zio, E. (2021). A new hybrid model for wind speed forecasting\ncombining long short-term memory neural network, decomposition methods and\ngrey wolf optimizer. Applied Soft Computing, 100, Article 106996.\nAswin, S., Geetha, P., & Vinayakumar, R. (2018). Deep learning models for the\nprediction of rainfall. In 2018 International Conference on Communication and Signal\nProcessing (ICCSP) (pp. 0657\u20130661). IEEE.\nBalluff, S., Bendfeld, J., & Krauter, S. (2020). Meteorological data forecast using RNN.\nIn Deep Learning and Neural Networks: Concepts, Methodologies, Tools, and Applications\n(pp. 905\u2013920). IGI Global.\nBarnston, A. G. (1992). Correspondence among the correlation, RMSE, and heidke fore-\ncast verification measures; refinement of the heidke score. Weather and Forecasting,\n7(4), 699\u2013709.\nBell, V., Carrington, D., & Moore, R. (1994). Rainfall forecasting using a simple\nadvected cloud model with weather radar, satellite infra-red and surface weather\nobservations: an initial appraisal under UK conditions.\nChao, Z., Pu, F., Yin, Y., Han, B., & Chen, X. (2018). Research on real-time local rainfall\nprediction based on MEMS sensors. Journal of Sensors, 2018.\nCharles, P. (2013). Project title. https://github.com/charlespwd/project-title.\nChen, T., & Guestrin, C. (2016). Xgboost: A scalable tree boosting system. In Proceedings\nof the 22nd Acm Sigkdd International Conference on Knowledge Discovery and Data\nMining (pp. 785\u2013794).\nCui, Z., Ke, R., Pu, Z., & Wang, Y. (2018). Deep bidirectional and unidirectional LSTM\nrecurrent neural network for network-wide traffic speed prediction. arXiv preprint\narXiv:1801.02143.\nCzarnecka, M., Nidzgorska-Lencewicz, J., et al. (2011). Impact of weather conditions\non winter and summer air quality. International Agrophysics, 25(1), 7\u201312.\nElman, J. L. (1990). Finding structure in time. Cognitive Science, 14(2), 179\u2013211.\nGan, K., Sun, S., Wang, S., & Wei, Y. (2018). A secondary-decomposition-ensemble\nlearning paradigm for forecasting PM2. 5 concentration. Atmospheric Pollution\nResearch, 9(6), 989\u2013999.\nGoodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.\nGreff, K., Srivastava, R. K., Koutn\u00edk, J., Steunebrink, B. R., & Schmidhuber, J. (2016).\nLSTM: A search space odyssey. IEEE Transactions on Neural Networks and Learning\nSystems, 28(10), 2222\u20132232.\nGulli, A., Kapoor, A., & Pal, S. (2019). Deep Learning with TensorFlow 2.0 and Keras:\nRegression, ConvNets, GANs, RNNs, NLP & more with TF 2.0 and the Keras API. Packt\nPublishing Ltd.\nHossain, I., Rasel, H., Imteaz, M. A., & Mekanik, F. (2020). Long-term seasonal rainfall\nforecasting using linear and non-linear modelling approaches: A case study for\nwestern Australia. Meteorology and Atmospheric Physics, 132(1), 131\u2013141.\nHutter, F., Kotthoff, L., & Vanschoren, J. (2019). Automated Machine Learning: Methods,\nSystems, Challenges. Springer Nature.\nKarasu, S., & Altan, A. (2019). Recognition model for solar radiation time series\nbased on random forest with feature selection approach. In 2019 11th International\nConference on Electrical and Electronics Engineering (ELECO) (pp. 8\u201311). IEEE.\nKim, H.-U., & Bae, T.-S. (2017). Preliminary study of deep learning-based precipitation\nprediction. Journal of the Korean Society of Surveying, Geodesy, Photogrammetry and\nCartography, 35(5), 423\u2013429.\nKim, S., Hong, S., Joh, M., & Song, S.-k. (2017). Deeprain: Convlstm network for\nprecipitation prediction using multichannel radar data. arXiv preprint arXiv:1711.\n02316.\nKratzert, F., Klotz, D., Brenner, C., Schulz, K., & Herrnegger, M. (2018). Rainfall\u2013runoff\nmodelling using long short-term memory (LSTM) networks. Hydrology and Earth\nSystem Sciences, 22(11), 6005\u20136022.\nKumar, D., Singh, A., Samui, P., & Jha, R. K. (2019). Forecasting monthly precipitation\nusing sequential modelling. Hydrological Sciences Journal, 64(6), 690\u2013700.\nLe, T. T., Fu, W., & Moore, J. H. (2020). Scaling tree-based automated machine learning\nto biomedical big data with a feature set selector. Bioinformatics, 36(1), 250\u2013256.\nLe, T.-T., Pham, B. T., Ly, H.-B., Shirzadi, A., & Le, L. M. (2020). Development of 48-\nhour precipitation forecasting model using nonlinear autoregressive neural network.\nIn CIGOS 2019, Innovation for Sustainable Infrastructure (pp. 1191\u20131196). Springer.\nLiu, Q., Zou, Y., Liu, X., & Linge, N. (2019). A survey on rainfall forecasting using\nartificial neural network. International Journal of Embedded Systems, 11(2), 240\u2013249.\nMokrani, H., Lounas, R., Bennai, M. T., Salhi, D. E., & Djerbi, R. (2019). Air quality\nmonitoring using iot: A survey. In 2019 IEEE International Conference on Smart\nInternet of Things (SmartIoT) (pp. 127\u2013134). IEEE.\nNi, L., Wang, D., Singh, V. P., Wu, J., Wang, Y., Tao, Y., et al. (2020). Streamflow\nand rainfall forecasting by two long short-term memory-based models. Journal of\nHydrology, 583, Article 124296.\nPedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., et\nal. (2011). Scikit-learn: Machine learning in python. Journal of Machine Learning\nResearch, 12, 2825\u20132830.\nPoornima, S., & Pushpalatha, M. (2019). Prediction of rainfall using intensified LSTM\nbased recurrent neural network with weighted linear units. Atmosphere, 10(11),\n668.\nRamachandran, P., Zoph, B., & Le, Q. V. (2017). Swish: a self-gated activation function.\n(p. 7). arXiv preprint arXiv:1710.05941.\nRamos, M. M. P., Del Alamo, C. L., & Zapana, R. A. (2019). Forecasting of mete-\norological weather time series through a feature vector based on correlation. In\nInternational Conference on Computer Analysis of Images and Patterns (pp. 542\u2013553).\nSpringer.\nvan Rossum, G. (1995). Python tutorial: Technical Report CS-R9526, Centrum Voor\nWiskunde En Informatica (CWI), Amsterdam.\nSalman, A. G., Heryadi, Y., Abdurahman, E., & Suparta, W. (2018). Single layer &\nmulti-layer long short-term memory (LSTM) model with intermediate variables for\nweather forecasting. Procedia Computer Science, 135, 89\u201398.\nShanker, M., Hu, M. Y., & Hung, M. S. (1996). Effect of data standardization on neural\nnetwork training. Omega, 24(4), 385\u2013397.\nSingh, P. (2021). FQTSFM: A fuzzy-quantum time series forecasting model. Information\nSciences, 566, 57\u201379.\nSingh, P., & Borah, B. (2013). Indian summer monsoon rainfall prediction using\nartificial neural network. Stochastic Environmental Research and Risk Assessment,\n27(7), 1585\u20131599.\nSingh, U., Chauhan, S., Krishnamachari, A., & Vig, L. (2015). Ensemble of deep long\nshort term memory networks for labelling origin of replication sequences. In 2015\nIEEE International Conference on Data Science and Advanced Analytics (DSAA) (pp.\n1\u20137). IEEE.\nWillmott, C. J., & Matsuura, K. (2005). Advantages of the mean absolute error (MAE)\nover the root mean square error (RMSE) in assessing average model performance.\nClimate Research, 30(1), 79\u201382.\nWu, C., & Chau, K.-W. (2013). Prediction of rainfall time series using modular\nsoft computingmethods. Engineering Applications of Artificial Intelligence, 26(3),\n997\u20131007.\nXiang, Y., Gou, L., He, L., Xia, S., & Wang, W. (2018). A SVR\u2013ANN combined model\nbased on ensemble EMD for rainfall prediction. Applied Soft Computing, 73, 874\u2013883.\nXingjian, S., Chen, Z., Wang, H., Yeung, D.-Y., Wong, W.-K., & Woo, W.-c. (2015).\nConvolutional LSTM network: A machine learning approach for precipitation\nnowcasting. In Advances in Neural Information Processing Systems (pp. 802\u2013810).\nYucel, I., Onen, A., Yilmaz, K., & Gochis, D. (2015). Calibration and evaluation of\na flood forecasting system: Utility of numerical weather prediction model, data\nassimilation and satellite-based rainfall. Journal of Hydrology, 523, 49\u201366.\nYunpeng, L., Di, H., Junpeng, B., & Yong, Q. (2017). Multi-step ahead time series\nforecasting for different data patterns based on LSTM recurrent neural network.\nIn 2017 14th Web Information Systems and Applications Conference (WISA) (pp.\n305\u2013310). IEEE.\nZadtootaghaj, P., Mohammadian, A., Mahbanooei, B., & Ghasemi, R. (2019). Internet\nof things: A survey for the individuals\u2019 E-health applications. Journal of Information\nTechnology Management, 11(1), 102\u2013129.\nZhang, J., Zhu, Y., Zhang, X., Ye, M., & Yang, J. (2018). Developing a long short-term\nmemory (LSTM) based model for predicting water table depth in agricultural areas.\nJournal of Hydrology, 561, 918\u2013929.\nZou, M., Fang, D., Harrison, G., & Djokic, S. (2019). Weather based day-ahead and\nweek-ahead load forecasting using deep recurrent neural network. In 2019 IEEE\n5th International Forum on Research and Technology for Society and Industry (RTSI)\n(pp. 341\u2013346). IEEE.\n20\n", []], "Appendix B. Comparison of rainfall predictions and true observed rainfall": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nDeclaration of competing interest\nThe authors declare that they have no known competing finan-\ncial interests or personal relationships that could have appeared to\ninfluence the work reported in this paper.\nAcknowledgements\nThe authors would like to express their sincere gratitude to the\nEngineering and Physical Science Research Council (EPSRC) grant ref:\nEP/S031480/1 and the Innovate UK (Grant Application No 10137 and\nFile No 104367) for providing the financial support for this study.\nAppendix A. Nullness of features contained in the raw weather\ndatasets of the major cities of UK\nSee Figs. 14 and 15\nAppendix B. Comparison of rainfall predictions and true observed\nrainfall\nSee Fig. 16\nReferences\nAbadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., et al. (2015).\nTensorFlow: Large-scale machine learning on heterogeneous systems. URL http:\n//tensorflow.org/, Software available from tensorflow.org.\nAguasca-Colomo, R., Castellanos-Nieves, D., & M\u00e9ndez, M. (2019). Comparative analysis\nof rainfall prediction models using machine learning in islands with complex\norography: Tenerife island. Applied Sciences, 9(22), 4931.\nAkbari Asanjan, A., Yang, T., Hsu, K., Sorooshian, S., Lin, J., & Peng, Q. (2018). Short-\nterm precipitation forecast based on the PERSIANN System and LSTM recurrent\nneural networks. Journal of Geophysical Research: Atmospheres, 123(22), 12\u2013543.\nAltan, A., Karasu, S., & Zio, E. (2021). A new hybrid model for wind speed forecasting\ncombining long short-term memory neural network, decomposition methods and\ngrey wolf optimizer. Applied Soft Computing, 100, Article 106996.\nAswin, S., Geetha, P., & Vinayakumar, R. (2018). Deep learning models for the\nprediction of rainfall. In 2018 International Conference on Communication and Signal\nProcessing (ICCSP) (pp. 0657\u20130661). IEEE.\nBalluff, S., Bendfeld, J., & Krauter, S. (2020). Meteorological data forecast using RNN.\nIn Deep Learning and Neural Networks: Concepts, Methodologies, Tools, and Applications\n(pp. 905\u2013920). IGI Global.\nBarnston, A. G. (1992). Correspondence among the correlation, RMSE, and heidke fore-\ncast verification measures; refinement of the heidke score. Weather and Forecasting,\n7(4), 699\u2013709.\nBell, V., Carrington, D., & Moore, R. (1994). Rainfall forecasting using a simple\nadvected cloud model with weather radar, satellite infra-red and surface weather\nobservations: an initial appraisal under UK conditions.\nChao, Z., Pu, F., Yin, Y., Han, B., & Chen, X. (2018). Research on real-time local rainfall\nprediction based on MEMS sensors. Journal of Sensors, 2018.\nCharles, P. (2013). Project title. https://github.com/charlespwd/project-title.\nChen, T., & Guestrin, C. (2016). Xgboost: A scalable tree boosting system. In Proceedings\nof the 22nd Acm Sigkdd International Conference on Knowledge Discovery and Data\nMining (pp. 785\u2013794).\nCui, Z., Ke, R., Pu, Z., & Wang, Y. (2018). Deep bidirectional and unidirectional LSTM\nrecurrent neural network for network-wide traffic speed prediction. arXiv preprint\narXiv:1801.02143.\nCzarnecka, M., Nidzgorska-Lencewicz, J., et al. (2011). Impact of weather conditions\non winter and summer air quality. International Agrophysics, 25(1), 7\u201312.\nElman, J. L. (1990). Finding structure in time. Cognitive Science, 14(2), 179\u2013211.\nGan, K., Sun, S., Wang, S., & Wei, Y. (2018). A secondary-decomposition-ensemble\nlearning paradigm for forecasting PM2. 5 concentration. Atmospheric Pollution\nResearch, 9(6), 989\u2013999.\nGoodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.\nGreff, K., Srivastava, R. K., Koutn\u00edk, J., Steunebrink, B. R., & Schmidhuber, J. (2016).\nLSTM: A search space odyssey. IEEE Transactions on Neural Networks and Learning\nSystems, 28(10), 2222\u20132232.\nGulli, A., Kapoor, A., & Pal, S. (2019). Deep Learning with TensorFlow 2.0 and Keras:\nRegression, ConvNets, GANs, RNNs, NLP & more with TF 2.0 and the Keras API. Packt\nPublishing Ltd.\nHossain, I., Rasel, H., Imteaz, M. A., & Mekanik, F. (2020). Long-term seasonal rainfall\nforecasting using linear and non-linear modelling approaches: A case study for\nwestern Australia. Meteorology and Atmospheric Physics, 132(1), 131\u2013141.\nHutter, F., Kotthoff, L., & Vanschoren, J. (2019). Automated Machine Learning: Methods,\nSystems, Challenges. Springer Nature.\nKarasu, S., & Altan, A. (2019). Recognition model for solar radiation time series\nbased on random forest with feature selection approach. In 2019 11th International\nConference on Electrical and Electronics Engineering (ELECO) (pp. 8\u201311). IEEE.\nKim, H.-U., & Bae, T.-S. (2017). Preliminary study of deep learning-based precipitation\nprediction. Journal of the Korean Society of Surveying, Geodesy, Photogrammetry and\nCartography, 35(5), 423\u2013429.\nKim, S., Hong, S., Joh, M., & Song, S.-k. (2017). Deeprain: Convlstm network for\nprecipitation prediction using multichannel radar data. arXiv preprint arXiv:1711.\n02316.\nKratzert, F., Klotz, D., Brenner, C., Schulz, K., & Herrnegger, M. (2018). Rainfall\u2013runoff\nmodelling using long short-term memory (LSTM) networks. Hydrology and Earth\nSystem Sciences, 22(11), 6005\u20136022.\nKumar, D., Singh, A., Samui, P., & Jha, R. K. (2019). Forecasting monthly precipitation\nusing sequential modelling. Hydrological Sciences Journal, 64(6), 690\u2013700.\nLe, T. T., Fu, W., & Moore, J. H. (2020). Scaling tree-based automated machine learning\nto biomedical big data with a feature set selector. Bioinformatics, 36(1), 250\u2013256.\nLe, T.-T., Pham, B. T., Ly, H.-B., Shirzadi, A., & Le, L. M. (2020). Development of 48-\nhour precipitation forecasting model using nonlinear autoregressive neural network.\nIn CIGOS 2019, Innovation for Sustainable Infrastructure (pp. 1191\u20131196). Springer.\nLiu, Q., Zou, Y., Liu, X., & Linge, N. (2019). A survey on rainfall forecasting using\nartificial neural network. International Journal of Embedded Systems, 11(2), 240\u2013249.\nMokrani, H., Lounas, R., Bennai, M. T., Salhi, D. E., & Djerbi, R. (2019). Air quality\nmonitoring using iot: A survey. In 2019 IEEE International Conference on Smart\nInternet of Things (SmartIoT) (pp. 127\u2013134). IEEE.\nNi, L., Wang, D., Singh, V. P., Wu, J., Wang, Y., Tao, Y., et al. (2020). Streamflow\nand rainfall forecasting by two long short-term memory-based models. Journal of\nHydrology, 583, Article 124296.\nPedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., et\nal. (2011). Scikit-learn: Machine learning in python. Journal of Machine Learning\nResearch, 12, 2825\u20132830.\nPoornima, S., & Pushpalatha, M. (2019). Prediction of rainfall using intensified LSTM\nbased recurrent neural network with weighted linear units. Atmosphere, 10(11),\n668.\nRamachandran, P., Zoph, B., & Le, Q. V. (2017). Swish: a self-gated activation function.\n(p. 7). arXiv preprint arXiv:1710.05941.\nRamos, M. M. P., Del Alamo, C. L., & Zapana, R. A. (2019). Forecasting of mete-\norological weather time series through a feature vector based on correlation. In\nInternational Conference on Computer Analysis of Images and Patterns (pp. 542\u2013553).\nSpringer.\nvan Rossum, G. (1995). Python tutorial: Technical Report CS-R9526, Centrum Voor\nWiskunde En Informatica (CWI), Amsterdam.\nSalman, A. G., Heryadi, Y., Abdurahman, E., & Suparta, W. (2018). Single layer &\nmulti-layer long short-term memory (LSTM) model with intermediate variables for\nweather forecasting. Procedia Computer Science, 135, 89\u201398.\nShanker, M., Hu, M. Y., & Hung, M. S. (1996). Effect of data standardization on neural\nnetwork training. Omega, 24(4), 385\u2013397.\nSingh, P. (2021). FQTSFM: A fuzzy-quantum time series forecasting model. Information\nSciences, 566, 57\u201379.\nSingh, P., & Borah, B. (2013). Indian summer monsoon rainfall prediction using\nartificial neural network. Stochastic Environmental Research and Risk Assessment,\n27(7), 1585\u20131599.\nSingh, U., Chauhan, S., Krishnamachari, A., & Vig, L. (2015). Ensemble of deep long\nshort term memory networks for labelling origin of replication sequences. In 2015\nIEEE International Conference on Data Science and Advanced Analytics (DSAA) (pp.\n1\u20137). IEEE.\nWillmott, C. J., & Matsuura, K. (2005). Advantages of the mean absolute error (MAE)\nover the root mean square error (RMSE) in assessing average model performance.\nClimate Research, 30(1), 79\u201382.\nWu, C., & Chau, K.-W. (2013). Prediction of rainfall time series using modular\nsoft computingmethods. Engineering Applications of Artificial Intelligence, 26(3),\n997\u20131007.\nXiang, Y., Gou, L., He, L., Xia, S., & Wang, W. (2018). A SVR\u2013ANN combined model\nbased on ensemble EMD for rainfall prediction. Applied Soft Computing, 73, 874\u2013883.\nXingjian, S., Chen, Z., Wang, H., Yeung, D.-Y., Wong, W.-K., & Woo, W.-c. (2015).\nConvolutional LSTM network: A machine learning approach for precipitation\nnowcasting. In Advances in Neural Information Processing Systems (pp. 802\u2013810).\nYucel, I., Onen, A., Yilmaz, K., & Gochis, D. (2015). Calibration and evaluation of\na flood forecasting system: Utility of numerical weather prediction model, data\nassimilation and satellite-based rainfall. Journal of Hydrology, 523, 49\u201366.\nYunpeng, L., Di, H., Junpeng, B., & Yong, Q. (2017). Multi-step ahead time series\nforecasting for different data patterns based on LSTM recurrent neural network.\nIn 2017 14th Web Information Systems and Applications Conference (WISA) (pp.\n305\u2013310). IEEE.\nZadtootaghaj, P., Mohammadian, A., Mahbanooei, B., & Ghasemi, R. (2019). Internet\nof things: A survey for the individuals\u2019 E-health applications. Journal of Information\nTechnology Management, 11(1), 102\u2013129.\nZhang, J., Zhu, Y., Zhang, X., Ye, M., & Yang, J. (2018). Developing a long short-term\nmemory (LSTM) based model for predicting water table depth in agricultural areas.\nJournal of Hydrology, 561, 918\u2013929.\nZou, M., Fang, D., Harrison, G., & Djokic, S. (2019). Weather based day-ahead and\nweek-ahead load forecasting using deep recurrent neural network. In 2019 IEEE\n5th International Forum on Research and Technology for Society and Industry (RTSI)\n(pp. 341\u2013346). IEEE.\n20\n", []], "Appendix A. Nullness of features contained in the raw weather datasets of the major cities of UK": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nDeclaration of competing interest\nThe authors declare that they have no known competing finan-\ncial interests or personal relationships that could have appeared to\ninfluence the work reported in this paper.\nAcknowledgements\nThe authors would like to express their sincere gratitude to the\nEngineering and Physical Science Research Council (EPSRC) grant ref:\nEP/S031480/1 and the Innovate UK (Grant Application No 10137 and\nFile No 104367) for providing the financial support for this study.\nAppendix A. Nullness of features contained in the raw weather\ndatasets of the major cities of UK\nSee Figs. 14 and 15\nAppendix B. Comparison of rainfall predictions and true observed\nrainfall\nSee Fig. 16\nReferences\nAbadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., et al. (2015).\nTensorFlow: Large-scale machine learning on heterogeneous systems. URL http:\n//tensorflow.org/, Software available from tensorflow.org.\nAguasca-Colomo, R., Castellanos-Nieves, D., & M\u00e9ndez, M. (2019). Comparative analysis\nof rainfall prediction models using machine learning in islands with complex\norography: Tenerife island. Applied Sciences, 9(22), 4931.\nAkbari Asanjan, A., Yang, T., Hsu, K., Sorooshian, S., Lin, J., & Peng, Q. (2018). Short-\nterm precipitation forecast based on the PERSIANN System and LSTM recurrent\nneural networks. Journal of Geophysical Research: Atmospheres, 123(22), 12\u2013543.\nAltan, A., Karasu, S., & Zio, E. (2021). A new hybrid model for wind speed forecasting\ncombining long short-term memory neural network, decomposition methods and\ngrey wolf optimizer. Applied Soft Computing, 100, Article 106996.\nAswin, S., Geetha, P., & Vinayakumar, R. (2018). Deep learning models for the\nprediction of rainfall. In 2018 International Conference on Communication and Signal\nProcessing (ICCSP) (pp. 0657\u20130661). IEEE.\nBalluff, S., Bendfeld, J., & Krauter, S. (2020). Meteorological data forecast using RNN.\nIn Deep Learning and Neural Networks: Concepts, Methodologies, Tools, and Applications\n(pp. 905\u2013920). IGI Global.\nBarnston, A. G. (1992). Correspondence among the correlation, RMSE, and heidke fore-\ncast verification measures; refinement of the heidke score. Weather and Forecasting,\n7(4), 699\u2013709.\nBell, V., Carrington, D., & Moore, R. (1994). Rainfall forecasting using a simple\nadvected cloud model with weather radar, satellite infra-red and surface weather\nobservations: an initial appraisal under UK conditions.\nChao, Z., Pu, F., Yin, Y., Han, B., & Chen, X. (2018). Research on real-time local rainfall\nprediction based on MEMS sensors. Journal of Sensors, 2018.\nCharles, P. (2013). Project title. https://github.com/charlespwd/project-title.\nChen, T., & Guestrin, C. (2016). Xgboost: A scalable tree boosting system. In Proceedings\nof the 22nd Acm Sigkdd International Conference on Knowledge Discovery and Data\nMining (pp. 785\u2013794).\nCui, Z., Ke, R., Pu, Z., & Wang, Y. (2018). Deep bidirectional and unidirectional LSTM\nrecurrent neural network for network-wide traffic speed prediction. arXiv preprint\narXiv:1801.02143.\nCzarnecka, M., Nidzgorska-Lencewicz, J., et al. (2011). Impact of weather conditions\non winter and summer air quality. International Agrophysics, 25(1), 7\u201312.\nElman, J. L. (1990). Finding structure in time. Cognitive Science, 14(2), 179\u2013211.\nGan, K., Sun, S., Wang, S., & Wei, Y. (2018). A secondary-decomposition-ensemble\nlearning paradigm for forecasting PM2. 5 concentration. Atmospheric Pollution\nResearch, 9(6), 989\u2013999.\nGoodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.\nGreff, K., Srivastava, R. K., Koutn\u00edk, J., Steunebrink, B. R., & Schmidhuber, J. (2016).\nLSTM: A search space odyssey. IEEE Transactions on Neural Networks and Learning\nSystems, 28(10), 2222\u20132232.\nGulli, A., Kapoor, A., & Pal, S. (2019). Deep Learning with TensorFlow 2.0 and Keras:\nRegression, ConvNets, GANs, RNNs, NLP & more with TF 2.0 and the Keras API. Packt\nPublishing Ltd.\nHossain, I., Rasel, H., Imteaz, M. A., & Mekanik, F. (2020). Long-term seasonal rainfall\nforecasting using linear and non-linear modelling approaches: A case study for\nwestern Australia. Meteorology and Atmospheric Physics, 132(1), 131\u2013141.\nHutter, F., Kotthoff, L., & Vanschoren, J. (2019). Automated Machine Learning: Methods,\nSystems, Challenges. Springer Nature.\nKarasu, S., & Altan, A. (2019). Recognition model for solar radiation time series\nbased on random forest with feature selection approach. In 2019 11th International\nConference on Electrical and Electronics Engineering (ELECO) (pp. 8\u201311). IEEE.\nKim, H.-U., & Bae, T.-S. (2017). Preliminary study of deep learning-based precipitation\nprediction. Journal of the Korean Society of Surveying, Geodesy, Photogrammetry and\nCartography, 35(5), 423\u2013429.\nKim, S., Hong, S., Joh, M., & Song, S.-k. (2017). Deeprain: Convlstm network for\nprecipitation prediction using multichannel radar data. arXiv preprint arXiv:1711.\n02316.\nKratzert, F., Klotz, D., Brenner, C., Schulz, K., & Herrnegger, M. (2018). Rainfall\u2013runoff\nmodelling using long short-term memory (LSTM) networks. Hydrology and Earth\nSystem Sciences, 22(11), 6005\u20136022.\nKumar, D., Singh, A., Samui, P., & Jha, R. K. (2019). Forecasting monthly precipitation\nusing sequential modelling. Hydrological Sciences Journal, 64(6), 690\u2013700.\nLe, T. T., Fu, W., & Moore, J. H. (2020). Scaling tree-based automated machine learning\nto biomedical big data with a feature set selector. Bioinformatics, 36(1), 250\u2013256.\nLe, T.-T., Pham, B. T., Ly, H.-B., Shirzadi, A., & Le, L. M. (2020). Development of 48-\nhour precipitation forecasting model using nonlinear autoregressive neural network.\nIn CIGOS 2019, Innovation for Sustainable Infrastructure (pp. 1191\u20131196). Springer.\nLiu, Q., Zou, Y., Liu, X., & Linge, N. (2019). A survey on rainfall forecasting using\nartificial neural network. International Journal of Embedded Systems, 11(2), 240\u2013249.\nMokrani, H., Lounas, R., Bennai, M. T., Salhi, D. E., & Djerbi, R. (2019). Air quality\nmonitoring using iot: A survey. In 2019 IEEE International Conference on Smart\nInternet of Things (SmartIoT) (pp. 127\u2013134). IEEE.\nNi, L., Wang, D., Singh, V. P., Wu, J., Wang, Y., Tao, Y., et al. (2020). Streamflow\nand rainfall forecasting by two long short-term memory-based models. Journal of\nHydrology, 583, Article 124296.\nPedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., et\nal. (2011). Scikit-learn: Machine learning in python. Journal of Machine Learning\nResearch, 12, 2825\u20132830.\nPoornima, S., & Pushpalatha, M. (2019). Prediction of rainfall using intensified LSTM\nbased recurrent neural network with weighted linear units. Atmosphere, 10(11),\n668.\nRamachandran, P., Zoph, B., & Le, Q. V. (2017). Swish: a self-gated activation function.\n(p. 7). arXiv preprint arXiv:1710.05941.\nRamos, M. M. P., Del Alamo, C. L., & Zapana, R. A. (2019). Forecasting of mete-\norological weather time series through a feature vector based on correlation. In\nInternational Conference on Computer Analysis of Images and Patterns (pp. 542\u2013553).\nSpringer.\nvan Rossum, G. (1995). Python tutorial: Technical Report CS-R9526, Centrum Voor\nWiskunde En Informatica (CWI), Amsterdam.\nSalman, A. G., Heryadi, Y., Abdurahman, E., & Suparta, W. (2018). Single layer &\nmulti-layer long short-term memory (LSTM) model with intermediate variables for\nweather forecasting. Procedia Computer Science, 135, 89\u201398.\nShanker, M., Hu, M. Y., & Hung, M. S. (1996). Effect of data standardization on neural\nnetwork training. Omega, 24(4), 385\u2013397.\nSingh, P. (2021). FQTSFM: A fuzzy-quantum time series forecasting model. Information\nSciences, 566, 57\u201379.\nSingh, P., & Borah, B. (2013). Indian summer monsoon rainfall prediction using\nartificial neural network. Stochastic Environmental Research and Risk Assessment,\n27(7), 1585\u20131599.\nSingh, U., Chauhan, S., Krishnamachari, A., & Vig, L. (2015). Ensemble of deep long\nshort term memory networks for labelling origin of replication sequences. In 2015\nIEEE International Conference on Data Science and Advanced Analytics (DSAA) (pp.\n1\u20137). IEEE.\nWillmott, C. J., & Matsuura, K. (2005). Advantages of the mean absolute error (MAE)\nover the root mean square error (RMSE) in assessing average model performance.\nClimate Research, 30(1), 79\u201382.\nWu, C., & Chau, K.-W. (2013). Prediction of rainfall time series using modular\nsoft computingmethods. Engineering Applications of Artificial Intelligence, 26(3),\n997\u20131007.\nXiang, Y., Gou, L., He, L., Xia, S., & Wang, W. (2018). A SVR\u2013ANN combined model\nbased on ensemble EMD for rainfall prediction. Applied Soft Computing, 73, 874\u2013883.\nXingjian, S., Chen, Z., Wang, H., Yeung, D.-Y., Wong, W.-K., & Woo, W.-c. (2015).\nConvolutional LSTM network: A machine learning approach for precipitation\nnowcasting. In Advances in Neural Information Processing Systems (pp. 802\u2013810).\nYucel, I., Onen, A., Yilmaz, K., & Gochis, D. (2015). Calibration and evaluation of\na flood forecasting system: Utility of numerical weather prediction model, data\nassimilation and satellite-based rainfall. Journal of Hydrology, 523, 49\u201366.\nYunpeng, L., Di, H., Junpeng, B., & Yong, Q. (2017). Multi-step ahead time series\nforecasting for different data patterns based on LSTM recurrent neural network.\nIn 2017 14th Web Information Systems and Applications Conference (WISA) (pp.\n305\u2013310). IEEE.\nZadtootaghaj, P., Mohammadian, A., Mahbanooei, B., & Ghasemi, R. (2019). Internet\nof things: A survey for the individuals\u2019 E-health applications. Journal of Information\nTechnology Management, 11(1), 102\u2013129.\nZhang, J., Zhu, Y., Zhang, X., Ye, M., & Yang, J. (2018). Developing a long short-term\nmemory (LSTM) based model for predicting water table depth in agricultural areas.\nJournal of Hydrology, 561, 918\u2013929.\nZou, M., Fang, D., Harrison, G., & Djokic, S. (2019). Weather based day-ahead and\nweek-ahead load forecasting using deep recurrent neural network. In 2019 IEEE\n5th International Forum on Research and Technology for Society and Industry (RTSI)\n(pp. 341\u2013346). IEEE.\n20\n", []], "Acknowledgements": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nDeclaration of competing interest\nThe authors declare that they have no known competing finan-\ncial interests or personal relationships that could have appeared to\ninfluence the work reported in this paper.\nAcknowledgements\nThe authors would like to express their sincere gratitude to the\nEngineering and Physical Science Research Council (EPSRC) grant ref:\nEP/S031480/1 and the Innovate UK (Grant Application No 10137 and\nFile No 104367) for providing the financial support for this study.\nAppendix A. Nullness of features contained in the raw weather\ndatasets of the major cities of UK\nSee Figs. 14 and 15\nAppendix B. Comparison of rainfall predictions and true observed\nrainfall\nSee Fig. 16\nReferences\nAbadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., et al. (2015).\nTensorFlow: Large-scale machine learning on heterogeneous systems. URL http:\n//tensorflow.org/, Software available from tensorflow.org.\nAguasca-Colomo, R., Castellanos-Nieves, D., & M\u00e9ndez, M. (2019). Comparative analysis\nof rainfall prediction models using machine learning in islands with complex\norography: Tenerife island. Applied Sciences, 9(22), 4931.\nAkbari Asanjan, A., Yang, T., Hsu, K., Sorooshian, S., Lin, J., & Peng, Q. (2018). Short-\nterm precipitation forecast based on the PERSIANN System and LSTM recurrent\nneural networks. Journal of Geophysical Research: Atmospheres, 123(22), 12\u2013543.\nAltan, A., Karasu, S., & Zio, E. (2021). A new hybrid model for wind speed forecasting\ncombining long short-term memory neural network, decomposition methods and\ngrey wolf optimizer. Applied Soft Computing, 100, Article 106996.\nAswin, S., Geetha, P., & Vinayakumar, R. (2018). Deep learning models for the\nprediction of rainfall. In 2018 International Conference on Communication and Signal\nProcessing (ICCSP) (pp. 0657\u20130661). IEEE.\nBalluff, S., Bendfeld, J., & Krauter, S. (2020). Meteorological data forecast using RNN.\nIn Deep Learning and Neural Networks: Concepts, Methodologies, Tools, and Applications\n(pp. 905\u2013920). IGI Global.\nBarnston, A. G. (1992). Correspondence among the correlation, RMSE, and heidke fore-\ncast verification measures; refinement of the heidke score. Weather and Forecasting,\n7(4), 699\u2013709.\nBell, V., Carrington, D., & Moore, R. (1994). Rainfall forecasting using a simple\nadvected cloud model with weather radar, satellite infra-red and surface weather\nobservations: an initial appraisal under UK conditions.\nChao, Z., Pu, F., Yin, Y., Han, B., & Chen, X. (2018). Research on real-time local rainfall\nprediction based on MEMS sensors. Journal of Sensors, 2018.\nCharles, P. (2013). Project title. https://github.com/charlespwd/project-title.\nChen, T., & Guestrin, C. (2016). Xgboost: A scalable tree boosting system. In Proceedings\nof the 22nd Acm Sigkdd International Conference on Knowledge Discovery and Data\nMining (pp. 785\u2013794).\nCui, Z., Ke, R., Pu, Z., & Wang, Y. (2018). Deep bidirectional and unidirectional LSTM\nrecurrent neural network for network-wide traffic speed prediction. arXiv preprint\narXiv:1801.02143.\nCzarnecka, M., Nidzgorska-Lencewicz, J., et al. (2011). Impact of weather conditions\non winter and summer air quality. International Agrophysics, 25(1), 7\u201312.\nElman, J. L. (1990). Finding structure in time. Cognitive Science, 14(2), 179\u2013211.\nGan, K., Sun, S., Wang, S., & Wei, Y. (2018). A secondary-decomposition-ensemble\nlearning paradigm for forecasting PM2. 5 concentration. Atmospheric Pollution\nResearch, 9(6), 989\u2013999.\nGoodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.\nGreff, K., Srivastava, R. K., Koutn\u00edk, J., Steunebrink, B. R., & Schmidhuber, J. (2016).\nLSTM: A search space odyssey. IEEE Transactions on Neural Networks and Learning\nSystems, 28(10), 2222\u20132232.\nGulli, A., Kapoor, A., & Pal, S. (2019). Deep Learning with TensorFlow 2.0 and Keras:\nRegression, ConvNets, GANs, RNNs, NLP & more with TF 2.0 and the Keras API. Packt\nPublishing Ltd.\nHossain, I., Rasel, H., Imteaz, M. A., & Mekanik, F. (2020). Long-term seasonal rainfall\nforecasting using linear and non-linear modelling approaches: A case study for\nwestern Australia. Meteorology and Atmospheric Physics, 132(1), 131\u2013141.\nHutter, F., Kotthoff, L., & Vanschoren, J. (2019). Automated Machine Learning: Methods,\nSystems, Challenges. Springer Nature.\nKarasu, S., & Altan, A. (2019). Recognition model for solar radiation time series\nbased on random forest with feature selection approach. In 2019 11th International\nConference on Electrical and Electronics Engineering (ELECO) (pp. 8\u201311). IEEE.\nKim, H.-U., & Bae, T.-S. (2017). Preliminary study of deep learning-based precipitation\nprediction. Journal of the Korean Society of Surveying, Geodesy, Photogrammetry and\nCartography, 35(5), 423\u2013429.\nKim, S., Hong, S., Joh, M., & Song, S.-k. (2017). Deeprain: Convlstm network for\nprecipitation prediction using multichannel radar data. arXiv preprint arXiv:1711.\n02316.\nKratzert, F., Klotz, D., Brenner, C., Schulz, K., & Herrnegger, M. (2018). Rainfall\u2013runoff\nmodelling using long short-term memory (LSTM) networks. Hydrology and Earth\nSystem Sciences, 22(11), 6005\u20136022.\nKumar, D., Singh, A., Samui, P., & Jha, R. K. (2019). Forecasting monthly precipitation\nusing sequential modelling. Hydrological Sciences Journal, 64(6), 690\u2013700.\nLe, T. T., Fu, W., & Moore, J. H. (2020). Scaling tree-based automated machine learning\nto biomedical big data with a feature set selector. Bioinformatics, 36(1), 250\u2013256.\nLe, T.-T., Pham, B. T., Ly, H.-B., Shirzadi, A., & Le, L. M. (2020). Development of 48-\nhour precipitation forecasting model using nonlinear autoregressive neural network.\nIn CIGOS 2019, Innovation for Sustainable Infrastructure (pp. 1191\u20131196). Springer.\nLiu, Q., Zou, Y., Liu, X., & Linge, N. (2019). A survey on rainfall forecasting using\nartificial neural network. International Journal of Embedded Systems, 11(2), 240\u2013249.\nMokrani, H., Lounas, R., Bennai, M. T., Salhi, D. E., & Djerbi, R. (2019). Air quality\nmonitoring using iot: A survey. In 2019 IEEE International Conference on Smart\nInternet of Things (SmartIoT) (pp. 127\u2013134). IEEE.\nNi, L., Wang, D., Singh, V. P., Wu, J., Wang, Y., Tao, Y., et al. (2020). Streamflow\nand rainfall forecasting by two long short-term memory-based models. Journal of\nHydrology, 583, Article 124296.\nPedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., et\nal. (2011). Scikit-learn: Machine learning in python. Journal of Machine Learning\nResearch, 12, 2825\u20132830.\nPoornima, S., & Pushpalatha, M. (2019). Prediction of rainfall using intensified LSTM\nbased recurrent neural network with weighted linear units. Atmosphere, 10(11),\n668.\nRamachandran, P., Zoph, B., & Le, Q. V. (2017). Swish: a self-gated activation function.\n(p. 7). arXiv preprint arXiv:1710.05941.\nRamos, M. M. P., Del Alamo, C. L., & Zapana, R. A. (2019). Forecasting of mete-\norological weather time series through a feature vector based on correlation. In\nInternational Conference on Computer Analysis of Images and Patterns (pp. 542\u2013553).\nSpringer.\nvan Rossum, G. (1995). Python tutorial: Technical Report CS-R9526, Centrum Voor\nWiskunde En Informatica (CWI), Amsterdam.\nSalman, A. G., Heryadi, Y., Abdurahman, E., & Suparta, W. (2018). Single layer &\nmulti-layer long short-term memory (LSTM) model with intermediate variables for\nweather forecasting. Procedia Computer Science, 135, 89\u201398.\nShanker, M., Hu, M. Y., & Hung, M. S. (1996). Effect of data standardization on neural\nnetwork training. Omega, 24(4), 385\u2013397.\nSingh, P. (2021). FQTSFM: A fuzzy-quantum time series forecasting model. Information\nSciences, 566, 57\u201379.\nSingh, P., & Borah, B. (2013). Indian summer monsoon rainfall prediction using\nartificial neural network. Stochastic Environmental Research and Risk Assessment,\n27(7), 1585\u20131599.\nSingh, U., Chauhan, S., Krishnamachari, A., & Vig, L. (2015). Ensemble of deep long\nshort term memory networks for labelling origin of replication sequences. In 2015\nIEEE International Conference on Data Science and Advanced Analytics (DSAA) (pp.\n1\u20137). IEEE.\nWillmott, C. J., & Matsuura, K. (2005). Advantages of the mean absolute error (MAE)\nover the root mean square error (RMSE) in assessing average model performance.\nClimate Research, 30(1), 79\u201382.\nWu, C., & Chau, K.-W. (2013). Prediction of rainfall time series using modular\nsoft computingmethods. Engineering Applications of Artificial Intelligence, 26(3),\n997\u20131007.\nXiang, Y., Gou, L., He, L., Xia, S., & Wang, W. (2018). A SVR\u2013ANN combined model\nbased on ensemble EMD for rainfall prediction. Applied Soft Computing, 73, 874\u2013883.\nXingjian, S., Chen, Z., Wang, H., Yeung, D.-Y., Wong, W.-K., & Woo, W.-c. (2015).\nConvolutional LSTM network: A machine learning approach for precipitation\nnowcasting. In Advances in Neural Information Processing Systems (pp. 802\u2013810).\nYucel, I., Onen, A., Yilmaz, K., & Gochis, D. (2015). Calibration and evaluation of\na flood forecasting system: Utility of numerical weather prediction model, data\nassimilation and satellite-based rainfall. Journal of Hydrology, 523, 49\u201366.\nYunpeng, L., Di, H., Junpeng, B., & Yong, Q. (2017). Multi-step ahead time series\nforecasting for different data patterns based on LSTM recurrent neural network.\nIn 2017 14th Web Information Systems and Applications Conference (WISA) (pp.\n305\u2013310). IEEE.\nZadtootaghaj, P., Mohammadian, A., Mahbanooei, B., & Ghasemi, R. (2019). Internet\nof things: A survey for the individuals\u2019 E-health applications. Journal of Information\nTechnology Management, 11(1), 102\u2013129.\nZhang, J., Zhu, Y., Zhang, X., Ye, M., & Yang, J. (2018). Developing a long short-term\nmemory (LSTM) based model for predicting water table depth in agricultural areas.\nJournal of Hydrology, 561, 918\u2013929.\nZou, M., Fang, D., Harrison, G., & Djokic, S. (2019). Weather based day-ahead and\nweek-ahead load forecasting using deep recurrent neural network. In 2019 IEEE\n5th International Forum on Research and Technology for Society and Industry (RTSI)\n(pp. 341\u2013346). IEEE.\n20\n", []], "Declaration of competing interest": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nDeclaration of competing interest\nThe authors declare that they have no known competing finan-\ncial interests or personal relationships that could have appeared to\ninfluence the work reported in this paper.\nAcknowledgements\nThe authors would like to express their sincere gratitude to the\nEngineering and Physical Science Research Council (EPSRC) grant ref:\nEP/S031480/1 and the Innovate UK (Grant Application No 10137 and\nFile No 104367) for providing the financial support for this study.\nAppendix A. Nullness of features contained in the raw weather\ndatasets of the major cities of UK\nSee Figs. 14 and 15\nAppendix B. Comparison of rainfall predictions and true observed\nrainfall\nSee Fig. 16\nReferences\nAbadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., et al. (2015).\nTensorFlow: Large-scale machine learning on heterogeneous systems. URL http:\n//tensorflow.org/, Software available from tensorflow.org.\nAguasca-Colomo, R., Castellanos-Nieves, D., & M\u00e9ndez, M. (2019). Comparative analysis\nof rainfall prediction models using machine learning in islands with complex\norography: Tenerife island. Applied Sciences, 9(22), 4931.\nAkbari Asanjan, A., Yang, T., Hsu, K., Sorooshian, S., Lin, J., & Peng, Q. (2018). Short-\nterm precipitation forecast based on the PERSIANN System and LSTM recurrent\nneural networks. Journal of Geophysical Research: Atmospheres, 123(22), 12\u2013543.\nAltan, A., Karasu, S., & Zio, E. (2021). A new hybrid model for wind speed forecasting\ncombining long short-term memory neural network, decomposition methods and\ngrey wolf optimizer. Applied Soft Computing, 100, Article 106996.\nAswin, S., Geetha, P., & Vinayakumar, R. (2018). Deep learning models for the\nprediction of rainfall. In 2018 International Conference on Communication and Signal\nProcessing (ICCSP) (pp. 0657\u20130661). IEEE.\nBalluff, S., Bendfeld, J., & Krauter, S. (2020). Meteorological data forecast using RNN.\nIn Deep Learning and Neural Networks: Concepts, Methodologies, Tools, and Applications\n(pp. 905\u2013920). IGI Global.\nBarnston, A. G. (1992). Correspondence among the correlation, RMSE, and heidke fore-\ncast verification measures; refinement of the heidke score. Weather and Forecasting,\n7(4), 699\u2013709.\nBell, V., Carrington, D., & Moore, R. (1994). Rainfall forecasting using a simple\nadvected cloud model with weather radar, satellite infra-red and surface weather\nobservations: an initial appraisal under UK conditions.\nChao, Z., Pu, F., Yin, Y., Han, B., & Chen, X. (2018). Research on real-time local rainfall\nprediction based on MEMS sensors. Journal of Sensors, 2018.\nCharles, P. (2013). Project title. https://github.com/charlespwd/project-title.\nChen, T., & Guestrin, C. (2016). Xgboost: A scalable tree boosting system. In Proceedings\nof the 22nd Acm Sigkdd International Conference on Knowledge Discovery and Data\nMining (pp. 785\u2013794).\nCui, Z., Ke, R., Pu, Z., & Wang, Y. (2018). Deep bidirectional and unidirectional LSTM\nrecurrent neural network for network-wide traffic speed prediction. arXiv preprint\narXiv:1801.02143.\nCzarnecka, M., Nidzgorska-Lencewicz, J., et al. (2011). Impact of weather conditions\non winter and summer air quality. International Agrophysics, 25(1), 7\u201312.\nElman, J. L. (1990). Finding structure in time. Cognitive Science, 14(2), 179\u2013211.\nGan, K., Sun, S., Wang, S., & Wei, Y. (2018). A secondary-decomposition-ensemble\nlearning paradigm for forecasting PM2. 5 concentration. Atmospheric Pollution\nResearch, 9(6), 989\u2013999.\nGoodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.\nGreff, K., Srivastava, R. K., Koutn\u00edk, J., Steunebrink, B. R., & Schmidhuber, J. (2016).\nLSTM: A search space odyssey. IEEE Transactions on Neural Networks and Learning\nSystems, 28(10), 2222\u20132232.\nGulli, A., Kapoor, A., & Pal, S. (2019). Deep Learning with TensorFlow 2.0 and Keras:\nRegression, ConvNets, GANs, RNNs, NLP & more with TF 2.0 and the Keras API. Packt\nPublishing Ltd.\nHossain, I., Rasel, H., Imteaz, M. A., & Mekanik, F. (2020). Long-term seasonal rainfall\nforecasting using linear and non-linear modelling approaches: A case study for\nwestern Australia. Meteorology and Atmospheric Physics, 132(1), 131\u2013141.\nHutter, F., Kotthoff, L., & Vanschoren, J. (2019). Automated Machine Learning: Methods,\nSystems, Challenges. Springer Nature.\nKarasu, S., & Altan, A. (2019). Recognition model for solar radiation time series\nbased on random forest with feature selection approach. In 2019 11th International\nConference on Electrical and Electronics Engineering (ELECO) (pp. 8\u201311). IEEE.\nKim, H.-U., & Bae, T.-S. (2017). Preliminary study of deep learning-based precipitation\nprediction. Journal of the Korean Society of Surveying, Geodesy, Photogrammetry and\nCartography, 35(5), 423\u2013429.\nKim, S., Hong, S., Joh, M., & Song, S.-k. (2017). Deeprain: Convlstm network for\nprecipitation prediction using multichannel radar data. arXiv preprint arXiv:1711.\n02316.\nKratzert, F., Klotz, D., Brenner, C., Schulz, K., & Herrnegger, M. (2018). Rainfall\u2013runoff\nmodelling using long short-term memory (LSTM) networks. Hydrology and Earth\nSystem Sciences, 22(11), 6005\u20136022.\nKumar, D., Singh, A., Samui, P., & Jha, R. K. (2019). Forecasting monthly precipitation\nusing sequential modelling. Hydrological Sciences Journal, 64(6), 690\u2013700.\nLe, T. T., Fu, W., & Moore, J. H. (2020). Scaling tree-based automated machine learning\nto biomedical big data with a feature set selector. Bioinformatics, 36(1), 250\u2013256.\nLe, T.-T., Pham, B. T., Ly, H.-B., Shirzadi, A., & Le, L. M. (2020). Development of 48-\nhour precipitation forecasting model using nonlinear autoregressive neural network.\nIn CIGOS 2019, Innovation for Sustainable Infrastructure (pp. 1191\u20131196). Springer.\nLiu, Q., Zou, Y., Liu, X., & Linge, N. (2019). A survey on rainfall forecasting using\nartificial neural network. International Journal of Embedded Systems, 11(2), 240\u2013249.\nMokrani, H., Lounas, R., Bennai, M. T., Salhi, D. E., & Djerbi, R. (2019). Air quality\nmonitoring using iot: A survey. In 2019 IEEE International Conference on Smart\nInternet of Things (SmartIoT) (pp. 127\u2013134). IEEE.\nNi, L., Wang, D., Singh, V. P., Wu, J., Wang, Y., Tao, Y., et al. (2020). Streamflow\nand rainfall forecasting by two long short-term memory-based models. Journal of\nHydrology, 583, Article 124296.\nPedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., et\nal. (2011). Scikit-learn: Machine learning in python. Journal of Machine Learning\nResearch, 12, 2825\u20132830.\nPoornima, S., & Pushpalatha, M. (2019). Prediction of rainfall using intensified LSTM\nbased recurrent neural network with weighted linear units. Atmosphere, 10(11),\n668.\nRamachandran, P., Zoph, B., & Le, Q. V. (2017). Swish: a self-gated activation function.\n(p. 7). arXiv preprint arXiv:1710.05941.\nRamos, M. M. P., Del Alamo, C. L., & Zapana, R. A. (2019). Forecasting of mete-\norological weather time series through a feature vector based on correlation. In\nInternational Conference on Computer Analysis of Images and Patterns (pp. 542\u2013553).\nSpringer.\nvan Rossum, G. (1995). Python tutorial: Technical Report CS-R9526, Centrum Voor\nWiskunde En Informatica (CWI), Amsterdam.\nSalman, A. G., Heryadi, Y., Abdurahman, E., & Suparta, W. (2018). Single layer &\nmulti-layer long short-term memory (LSTM) model with intermediate variables for\nweather forecasting. Procedia Computer Science, 135, 89\u201398.\nShanker, M., Hu, M. Y., & Hung, M. S. (1996). Effect of data standardization on neural\nnetwork training. Omega, 24(4), 385\u2013397.\nSingh, P. (2021). FQTSFM: A fuzzy-quantum time series forecasting model. Information\nSciences, 566, 57\u201379.\nSingh, P., & Borah, B. (2013). Indian summer monsoon rainfall prediction using\nartificial neural network. Stochastic Environmental Research and Risk Assessment,\n27(7), 1585\u20131599.\nSingh, U., Chauhan, S., Krishnamachari, A., & Vig, L. (2015). Ensemble of deep long\nshort term memory networks for labelling origin of replication sequences. In 2015\nIEEE International Conference on Data Science and Advanced Analytics (DSAA) (pp.\n1\u20137). IEEE.\nWillmott, C. J., & Matsuura, K. (2005). Advantages of the mean absolute error (MAE)\nover the root mean square error (RMSE) in assessing average model performance.\nClimate Research, 30(1), 79\u201382.\nWu, C., & Chau, K.-W. (2013). Prediction of rainfall time series using modular\nsoft computingmethods. Engineering Applications of Artificial Intelligence, 26(3),\n997\u20131007.\nXiang, Y., Gou, L., He, L., Xia, S., & Wang, W. (2018). A SVR\u2013ANN combined model\nbased on ensemble EMD for rainfall prediction. Applied Soft Computing, 73, 874\u2013883.\nXingjian, S., Chen, Z., Wang, H., Yeung, D.-Y., Wong, W.-K., & Woo, W.-c. (2015).\nConvolutional LSTM network: A machine learning approach for precipitation\nnowcasting. In Advances in Neural Information Processing Systems (pp. 802\u2013810).\nYucel, I., Onen, A., Yilmaz, K., & Gochis, D. (2015). Calibration and evaluation of\na flood forecasting system: Utility of numerical weather prediction model, data\nassimilation and satellite-based rainfall. Journal of Hydrology, 523, 49\u201366.\nYunpeng, L., Di, H., Junpeng, B., & Yong, Q. (2017). Multi-step ahead time series\nforecasting for different data patterns based on LSTM recurrent neural network.\nIn 2017 14th Web Information Systems and Applications Conference (WISA) (pp.\n305\u2013310). IEEE.\nZadtootaghaj, P., Mohammadian, A., Mahbanooei, B., & Ghasemi, R. (2019). Internet\nof things: A survey for the individuals\u2019 E-health applications. Journal of Information\nTechnology Management, 11(1), 102\u2013129.\nZhang, J., Zhu, Y., Zhang, X., Ye, M., & Yang, J. (2018). Developing a long short-term\nmemory (LSTM) based model for predicting water table depth in agricultural areas.\nJournal of Hydrology, 561, 918\u2013929.\nZou, M., Fang, D., Harrison, G., & Djokic, S. (2019). Weather based day-ahead and\nweek-ahead load forecasting using deep recurrent neural network. In 2019 IEEE\n5th International Forum on Research and Technology for Society and Industry (RTSI)\n(pp. 341\u2013346). IEEE.\n20\n", []], "CRediT authorship contribution statement": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nand Model 5, it can be noticed that the addition of an LSTM hidden\nlayer (Model 5) impacts the learning ability of the rainfall prediction\nmodel in the five cities. This impact on the learning behaviour of Model\n5 causes that (1) training and validation loss is reduced by a factor of\none, and (2) training loss curves do not stabilise through the epochs.\nRegarding the comparison between Model 4 and Model 6, it can be\nnoticed that both models show similar training and validation loss\ncurves behaviour and values.\nLast, but not least, it is performed a comparison between Model 3,\nModel 4, Model 5, and Model 6. From Tables 9 and 10 it can be seen\nthat in general Model 4 and Model 6 present better performance than\nModel 3. Between Model 3, Model 4 and Model 6, the Loss values are\nsimilar with the exception of the city of Cardiff in Model 3, where the\nvalue is higher. Regarding the RMSE evaluation metric, the values of\nModel 4 and Model 6 are lower for all cities, with the exception of\nSwindon in Model 6 where the values are equal to Model 3 for this city.\nFor the MAE metric, Model 4 and Model 6 reached lower values than\nModel 3 except for the city of Swindon in Model 6, where Model 3 has\na lower value. Model 4 and Model 6 obtained lower RMSLE values than\nModel 3 for the five major UK cities. Consequently, the comparison of\nModel 3, Model 4 and Model 6 denotes that, in general, Model 4 and\nModel 6 perform better than Model 3 for the rainfall prediction task.\nFig. 13 shows examples of an 8-hour rainfall forecast for the five\nmajor UK cities using Model 4 and Model 6. The complete comparison\nbetween the actual rainfall observations and the forecasts made by\nModel 4 and Model 6 for the five cities can be consulted in Appendix B.\nDespite the fact that the performance of Model 4 and Model 6, in\nthe evaluation metrics, is better than the rest of the models based on\nLSTM-Networks, XGBoost and the ensemble; the predictions presented\nin Fig. 13 show how the models struggle to adapt to abrupt variations\nin the precipitation pattern. An explanation for this shortcoming may\nlie in the selection of the values of the hyperparameters, where the non-\nexhaustive grid search shows that a small change, such as passing from\na batch size of 15 to 32 or using different batches of observations to\nmake the predictions, have a great impact on the performance of the\nLSTM-Networks.\n7. Conclusions\nThis study set out to compare the prediction performance of rainfall\nforecasting models based on LSTM-Networks architectures with modern\nMachine Learning algorithms. To achieve this objective, 2 models\nbased on LSTM-Networks, 3 models based on Stacked-LSTM, and 1\nBidirectional-LSTM Networks model were compared with an XGBoost\n(baseline model) and an ensemble model that resulted from carrying\nout an Automated Machine Learning approach.\nIn order to evaluate the performance of the implemented rainfall\nforecasting models, historical weather data of two decades from the\nUK cities of Bath, Bristol, Cardiff, Newport, and Swindon were used.\nGood practices were implemented when conducting Machine Learning\nexperiments such as (a) a pre-processing procedure to eliminate cate-\ngorical and incomplete data within the datasets, (b) a feature selection\nprocess carried out through a Correlation Matrix analysis, (c) imple-\nmentation of a non-exhaustive hyperparameters grid search to obtain\nthe best performance of models based on XGBoost and LSTM-Networks\narchitectures.\nTo the authors\u2019 knowledge, this study is the first to present a\ncomparative analysis of the performance of rainfall forecasting models\nbased on modern Machine Learning algorithms in predicting hourly\nrainfall volume using weather time-series data from cities in the United\nKingdom. Specifically, the main contributions of this study are high-\nlighted below:\n\u2022 From the literature reviewed, three models based on the LSTM\nand Stacked-LSTM Networks were adapted for the task of fore-\ncasting hourly rainfall using time-series data from five major UK\ncities.\n\u2022 A model based on Bidirectional-LSTM Networks was proposed for\nthe task of forecasting rainfall on an hourly basis using time-series\ndata from five major UK cities.\n\u2022 A comparison of the performance of models based on LSTM-\nNetworks,\nStacked-LSTM\nNetworks,\nBidirectional-LSTM\nNetworks, XGBoost, and an ensemble model resulted from per-\nforming an AutoML approach was performed in the task of\nforecasting the amount of rainfall per hour using time-series data\nfrom five major UK cities.\nResults showed that a Bidirectional-LSTM Network can be used as\na rainfall forecast model with comparable performance to a Stacked-\nLSTM Network with two hidden layers. Among all the rainfall pre-\ndiction models tested in the comparison, which included three mod-\nels adapted from the literature, the Stacked-LSTM (Model 4) and\nBidirectional-LSTM (Model 6) models achieved, in general, lower val-\nues in the evaluation metrics RMSE, MAE, and RMSLE. Model 4\nachieved Loss values between 0.0014\u20130.0001, RMSE values in the\nrange of 0.0375\u20130.0084, MAE values between 0.0071\u20130.0013, and\nRMSLE values ranging between 0.0157\u20130.0037. On the other hand,\nModel 6 obtained values ranging between 0.0014\u20130.0001, 0.0377\u2013\n0.0099, 0.0072\u20130.0015, and 0.0111\u20130.0044 for Loss, RMSE, MAE, and\nRMSLE, respectively.\nThe Stacked-LSTM Network with 10 hidden layers (Model 1) pre-\nsented the worst performance in the training and validation loss curves,\namong all the rainfall prediction models. Moreover, Model 5 (a Stacked-\nLSTM with three hidden layers) showed worst training and validation\nloss curves than Model 4 (a Stacked-LSTM with two hidden layers)\nand Model 5 (a Bidirectional-LSTM Network). This suggest that LSTM\nNeural Networks with a large number of hidden layers are less suitable\nto learn the singularities of weather time-series to forecast hourly\nrainfall volume values.\nAlthough these results are encouraging and even suggest that it\nis possible to use Bidirectional-LSTM Networks as a rainfall predic-\ntion model, the tested models share one major drawback. This major\ndrawback, similar to other approaches that use models based on LSTM-\nNetworks, is the inability to generalise adequately. For the most part,\nmodels overfit training data and cannot record accurate predictions in\ntest and validation sets.\nFuture work would be directed at fine-tuning the parameters and\nhyperparameters of the prediction models with the aim of further\nclosing the gap between the predicted values and the observed rainfall\nvolumes. In addition, different approaches can also be considered to\ndeal with missing values of features in time-series data, such as moving\naverage (Karasu & Altan, 2019) and to calculate lag features. On\nthe other hand, recent related approaches in forecasting using fuzzy\ntime-series (E.g. Singh, 2021) or hybrid models of LSTM-Networks,\ndecomposition methods and grey wolf optimiser (Altan, Karasu, &\nZio, 2021) will be investigated. In addition, it is worth considering\na comprehensive analysis of the importance of the features and the\ninclusion of other weather factors to achieve better performance of the\nrainfall forecasting models.\nCRediT authorship contribution statement\nAri Yair Barrera-Animas: Conceptualisation, Methodology, Soft-\nware, Validation, Writing \u2013 original draft, Writing \u2013 review & editing,\nResources, Data curation, Visualisation. Lukumon O. Oyedele: Writing\n\u2013 review & editing, Supervision, Funding acquisition. Muhammad\nBilal: Conceptualisation, Methodology, Validation, Writing \u2013 review &\nediting, Resources, Data curation, Visualisation, Supervision, Project\nadministration. Taofeek Dolapo Akinosho: Methodology, Writing \u2013\nreview & editing, Resources, Visualisation. Juan Manuel Davila Del-\ngado: Methodology, Writing \u2013 review & editing, Visualisation. Lukman\nAdewale Akanbi: Writing \u2013 review & editing, Supervision.\n19\n", []], "Conclusions": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nand Model 5, it can be noticed that the addition of an LSTM hidden\nlayer (Model 5) impacts the learning ability of the rainfall prediction\nmodel in the five cities. This impact on the learning behaviour of Model\n5 causes that (1) training and validation loss is reduced by a factor of\none, and (2) training loss curves do not stabilise through the epochs.\nRegarding the comparison between Model 4 and Model 6, it can be\nnoticed that both models show similar training and validation loss\ncurves behaviour and values.\nLast, but not least, it is performed a comparison between Model 3,\nModel 4, Model 5, and Model 6. From Tables 9 and 10 it can be seen\nthat in general Model 4 and Model 6 present better performance than\nModel 3. Between Model 3, Model 4 and Model 6, the Loss values are\nsimilar with the exception of the city of Cardiff in Model 3, where the\nvalue is higher. Regarding the RMSE evaluation metric, the values of\nModel 4 and Model 6 are lower for all cities, with the exception of\nSwindon in Model 6 where the values are equal to Model 3 for this city.\nFor the MAE metric, Model 4 and Model 6 reached lower values than\nModel 3 except for the city of Swindon in Model 6, where Model 3 has\na lower value. Model 4 and Model 6 obtained lower RMSLE values than\nModel 3 for the five major UK cities. Consequently, the comparison of\nModel 3, Model 4 and Model 6 denotes that, in general, Model 4 and\nModel 6 perform better than Model 3 for the rainfall prediction task.\nFig. 13 shows examples of an 8-hour rainfall forecast for the five\nmajor UK cities using Model 4 and Model 6. The complete comparison\nbetween the actual rainfall observations and the forecasts made by\nModel 4 and Model 6 for the five cities can be consulted in Appendix B.\nDespite the fact that the performance of Model 4 and Model 6, in\nthe evaluation metrics, is better than the rest of the models based on\nLSTM-Networks, XGBoost and the ensemble; the predictions presented\nin Fig. 13 show how the models struggle to adapt to abrupt variations\nin the precipitation pattern. An explanation for this shortcoming may\nlie in the selection of the values of the hyperparameters, where the non-\nexhaustive grid search shows that a small change, such as passing from\na batch size of 15 to 32 or using different batches of observations to\nmake the predictions, have a great impact on the performance of the\nLSTM-Networks.\n7. Conclusions\nThis study set out to compare the prediction performance of rainfall\nforecasting models based on LSTM-Networks architectures with modern\nMachine Learning algorithms. To achieve this objective, 2 models\nbased on LSTM-Networks, 3 models based on Stacked-LSTM, and 1\nBidirectional-LSTM Networks model were compared with an XGBoost\n(baseline model) and an ensemble model that resulted from carrying\nout an Automated Machine Learning approach.\nIn order to evaluate the performance of the implemented rainfall\nforecasting models, historical weather data of two decades from the\nUK cities of Bath, Bristol, Cardiff, Newport, and Swindon were used.\nGood practices were implemented when conducting Machine Learning\nexperiments such as (a) a pre-processing procedure to eliminate cate-\ngorical and incomplete data within the datasets, (b) a feature selection\nprocess carried out through a Correlation Matrix analysis, (c) imple-\nmentation of a non-exhaustive hyperparameters grid search to obtain\nthe best performance of models based on XGBoost and LSTM-Networks\narchitectures.\nTo the authors\u2019 knowledge, this study is the first to present a\ncomparative analysis of the performance of rainfall forecasting models\nbased on modern Machine Learning algorithms in predicting hourly\nrainfall volume using weather time-series data from cities in the United\nKingdom. Specifically, the main contributions of this study are high-\nlighted below:\n\u2022 From the literature reviewed, three models based on the LSTM\nand Stacked-LSTM Networks were adapted for the task of fore-\ncasting hourly rainfall using time-series data from five major UK\ncities.\n\u2022 A model based on Bidirectional-LSTM Networks was proposed for\nthe task of forecasting rainfall on an hourly basis using time-series\ndata from five major UK cities.\n\u2022 A comparison of the performance of models based on LSTM-\nNetworks,\nStacked-LSTM\nNetworks,\nBidirectional-LSTM\nNetworks, XGBoost, and an ensemble model resulted from per-\nforming an AutoML approach was performed in the task of\nforecasting the amount of rainfall per hour using time-series data\nfrom five major UK cities.\nResults showed that a Bidirectional-LSTM Network can be used as\na rainfall forecast model with comparable performance to a Stacked-\nLSTM Network with two hidden layers. Among all the rainfall pre-\ndiction models tested in the comparison, which included three mod-\nels adapted from the literature, the Stacked-LSTM (Model 4) and\nBidirectional-LSTM (Model 6) models achieved, in general, lower val-\nues in the evaluation metrics RMSE, MAE, and RMSLE. Model 4\nachieved Loss values between 0.0014\u20130.0001, RMSE values in the\nrange of 0.0375\u20130.0084, MAE values between 0.0071\u20130.0013, and\nRMSLE values ranging between 0.0157\u20130.0037. On the other hand,\nModel 6 obtained values ranging between 0.0014\u20130.0001, 0.0377\u2013\n0.0099, 0.0072\u20130.0015, and 0.0111\u20130.0044 for Loss, RMSE, MAE, and\nRMSLE, respectively.\nThe Stacked-LSTM Network with 10 hidden layers (Model 1) pre-\nsented the worst performance in the training and validation loss curves,\namong all the rainfall prediction models. Moreover, Model 5 (a Stacked-\nLSTM with three hidden layers) showed worst training and validation\nloss curves than Model 4 (a Stacked-LSTM with two hidden layers)\nand Model 5 (a Bidirectional-LSTM Network). This suggest that LSTM\nNeural Networks with a large number of hidden layers are less suitable\nto learn the singularities of weather time-series to forecast hourly\nrainfall volume values.\nAlthough these results are encouraging and even suggest that it\nis possible to use Bidirectional-LSTM Networks as a rainfall predic-\ntion model, the tested models share one major drawback. This major\ndrawback, similar to other approaches that use models based on LSTM-\nNetworks, is the inability to generalise adequately. For the most part,\nmodels overfit training data and cannot record accurate predictions in\ntest and validation sets.\nFuture work would be directed at fine-tuning the parameters and\nhyperparameters of the prediction models with the aim of further\nclosing the gap between the predicted values and the observed rainfall\nvolumes. In addition, different approaches can also be considered to\ndeal with missing values of features in time-series data, such as moving\naverage (Karasu & Altan, 2019) and to calculate lag features. On\nthe other hand, recent related approaches in forecasting using fuzzy\ntime-series (E.g. Singh, 2021) or hybrid models of LSTM-Networks,\ndecomposition methods and grey wolf optimiser (Altan, Karasu, &\nZio, 2021) will be investigated. In addition, it is worth considering\na comprehensive analysis of the importance of the features and the\ninclusion of other weather factors to achieve better performance of the\nrainfall forecasting models.\nCRediT authorship contribution statement\nAri Yair Barrera-Animas: Conceptualisation, Methodology, Soft-\nware, Validation, Writing \u2013 original draft, Writing \u2013 review & editing,\nResources, Data curation, Visualisation. Lukumon O. Oyedele: Writing\n\u2013 review & editing, Supervision, Funding acquisition. Muhammad\nBilal: Conceptualisation, Methodology, Validation, Writing \u2013 review &\nediting, Resources, Data curation, Visualisation, Supervision, Project\nadministration. Taofeek Dolapo Akinosho: Methodology, Writing \u2013\nreview & editing, Resources, Visualisation. Juan Manuel Davila Del-\ngado: Methodology, Writing \u2013 review & editing, Visualisation. Lukman\nAdewale Akanbi: Writing \u2013 review & editing, Supervision.\n19\n", []], "Results of the proposed models based on Stacked-LSTM and Bidirectional-LSTM networks": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nBy comparing the rainfall prediction results made by the XGBoost\nmodel (Table 7) and the stacked ensemble model (Table 8), the follow-\ning observations are found. For both models, the behaviour of rainfall\nfor the city of Swindon and the city of Cardiff was more difficult and\nless difficult to learn, respectively. In the city of Bath, both models\nobtained similar values in the RMSE and RMSLE metrics. Regarding the\nMAE metric, the lowest value was obtained by the ensemble model. For\nthe Bristol and Swindon cities, the ensemble prediction model achieved\nlower values in all the metrics except for the RMSE in Bristol (which is\nthe same value in both models). For the city of Cardiff, it can be noticed\nthat all the metrics values are the same for both models. Regarding the\nperformance with the city of Newport, the values of both prediction\nmodels in the MAE and RMSE metrics are similar; while the ensemble\nmodel achieved a lower RMSLE value.\nIn general, the best performance, according to the evaluation met-\nrics, was obtained by the ensemble model of Gradient Boosting Regres-\nsor, Linear Support Vector Regression, and Extra-trees Regressor; where\na considerable difference in the performance in the city of Swindon for\nthe RMSE metric can be seen.\nDespite the fact that the XGBoost model and the stacked ensemble\nuse decision trees as final or only steps to deliver a prediction, the\nresults show that a good approach to follow is not to rely on just a single\nregression algorithm, but to take advantage of the benefits offered by\nensemble approaches. Consequently, this result opens the possibility of\nexploring joint approaches as a follow-up study.\n6.2.3. Results of the LSTM and Stacked-LSTM models adapted from the\nliterature\nThe results of the hyperparameter grid search performed for Model\n1, Model 2, and Model 3 with each of the five datasets showed that a\nbatch size of 32, using the tanh activation function for the LSTM cells\nand SGD optimiser achieved the best performance. Regarding the best\nvalues for the Learning Rate, the non-exhaustive grid search showed\nthat: (1) a value of 0.001 was the best for all the cities when they\nwere trained in Model 2 and Model 3, as well as for the cities of Bristol\nand Swindon with Model 1; and (2) a value of 0.01 is better suited to\ntraining Model 1 with the Bath, Cardiff and Newport datasets.\nTable 9 shows the results obtained by Model 1, Model 2 and Model\n3 after being trained with the identified hyperparameter values.\nBecause the stacked ensemble model performed better than the\nXGBoost model, a comparison of the models based on LSTM-Networks\nwith the XGBoost model is not performed. Therefore, the first com-\nparison carried out is between the rainfall prediction models based\non LSTM-Networks and the ensemble model. To this end, the results\nconcentrated in Tables 7 and 9 are contrasted.\nFrom both tables, it can be noticed that all values of the RMSE, MAE,\nand RMSLE metrics for Model 1, Model 2, and Model 3 are lower than\nthose obtained by the ensemble model for the five cities. These results\nindicate that the prediction models based on LSTM and Stacked-LSTM\nNetworks can achieve better performance values for the evaluation\nmetrics RMSE, MAE and RMSLE than the model based on an ensemble\nof Gradient Boosting Regressor, Linear Support Vector Regression, and\nExtra-trees Regressor for the task of forecasting the volume of rainfall.\nConsequently, a comparison between the three models based on LSTM-\nNetworks is required to determine which model performs better in the\nrain prediction task.\nThe results in Table 9 show that for the RMSE metric, Model 1\nachieves the lowest values except for the city of Swindon where the\nlowest value is obtained by Model 2. Regarding the MAE evaluation\nmetric, Model 1 and Model 2 have the same number of cities with the\nlowest values. Model 1 achieves the lowest MAE values for the cities\nof Bristol and Newport, while Model 2 has lowest MAE values for the\ncities of Bath and Swindon. Both models show the same MAE value for\nthe city of Cardiff. As for the RMSLE and the Loss metrics, Model 1\nachieved the lowest values for the five cities among the three models.\nHowever, analysing the evaluation metrics themselves is only one\npart of the Deep Neural Networks evaluation. The other equally rele-\nvant part of the evaluation is the visual analysis of the training and\nvalidation loss curves. This visual evaluation allows the inspection of\nthe performance of the Neural Network during the training process,\nrevealing aspects such as overfitting, underfitting and diagnosis of\nnon-representative datasets. The aim of the evaluation is to find an\noptimal learning curve, that is, the training and validation loss curves\ndecrease to a point of stabilisation while the generalisation gap is\nminimal (Goodfellow et al., 2016; Gulli et al., 2019).\nThe evaluation of the models resulting from the hyperparameter\ngrid search also considered this second part of the analysis to identify\nthose models with the best training and validation loss curves for each\nof the five datasets. That is, the models with the best performance in\nthe evaluation metrics and with the best training and validation loss\ncurves of all the models tested in the hyperparameter grid search were\nselected and identified as Model 1, Model 2 and Model 3 as appropriate.\nFigs. 7\u20139 show the training and validation loss plots of Model 1, Model\n2 and Model 3, respectively.\nFrom Figs. 7, 8, and 9, it can be noticed that Model 3 has better\ntraining and validation loss curves than Model 1 and Model 2. Although\nModel 1 achieved the lowest values in the evaluation metrics for most\nof the five cities, it can be seen that the Stacked-LSTM Network model\ndid not learn properly. This drawback in Model 1 may be due to the fact\nthat the model is a stack with 10 hidden LSTM layers, while Model 2\nand Model 3 only have one hidden layer; suggesting that the complexity\nof the five datasets can be better learned with shallower Neural Net-\nworks. Furthermore, Model 3 shows that configuring a greater number\nof memory cells and allowing the backwards processing of the input\nsequence while training with a greater number of epochs helps the\nnetwork learn better.\n6.2.4. Results of the proposed models based on Stacked-LSTM and\nBidirectional-LSTM networks\nDue to Model 3 presents the best training and validation loss curves,\nits parameters and hyperparameters were used as the basis to build\nModel 4, Model 5 and Model 6 following the experimental procedure\ndescribed in Section 5.7.\nThe results of the hyperparameter grid search performed for Model\n4, Model 5 and Model 6 with each of the five datasets corroborate that\na batch size of 32, using tanh as the activation function for the LSTM\ncells and SGD as an optimiser, makes all three models achieve better\nperformance. On the other hand, the results show that for all three\nmodels, the best Learning Rate value was 0.001.\nTable 10 shows the results of the evaluation metrics obtained by\nModel 4 (Stacked-LSTM with two hidden layers), Model 5 (Stacked-\nLSTM with three hidden layers), and Model 6 (Bidirectional-LSTM\nNetworks) after being trained with the identified hyperparameter val-\nues.\nThe results in Table 10 show the following: (1) The three models\nachieved equal Loss values for all cities with the exception of the city\nof Bristol with Model 5, where the Loss value is lower; and (2) In the\nevaluation metrics RMSE, MAE, and RMSLE, Model 5 obtained lower\nvalues in the five cities, while Model 6 presents the highest values.\nThese results indicate that the performance of Model 5 is better than\nModel 4 and Model 6 according to the evaluation metrics. Nevertheless,\ntraining and validation loss curves should also be analysed.\nSimilar to the approach followed to present the results of the\nprevious models, Model 4, Model 5 and Model 6 are the models with the\nbest performance in the evaluation metrics and with the best training\nand validation loss curves of all models tested in the hyperparameter\ngrid search. Training and validation loss plots for the five cities for\nModel 4, Model 5, and Model 6 are shown in Figs. 10, 11, and 12,\nrespectively.\nFigs. 10\u201312 show that Model 4 presents better training and valida-\ntion loss curve behaviour for the five cities tested. Between Model 4\n18\n", []], "Results of the LSTM and Stacked-LSTM models adapted from the literature": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nBy comparing the rainfall prediction results made by the XGBoost\nmodel (Table 7) and the stacked ensemble model (Table 8), the follow-\ning observations are found. For both models, the behaviour of rainfall\nfor the city of Swindon and the city of Cardiff was more difficult and\nless difficult to learn, respectively. In the city of Bath, both models\nobtained similar values in the RMSE and RMSLE metrics. Regarding the\nMAE metric, the lowest value was obtained by the ensemble model. For\nthe Bristol and Swindon cities, the ensemble prediction model achieved\nlower values in all the metrics except for the RMSE in Bristol (which is\nthe same value in both models). For the city of Cardiff, it can be noticed\nthat all the metrics values are the same for both models. Regarding the\nperformance with the city of Newport, the values of both prediction\nmodels in the MAE and RMSE metrics are similar; while the ensemble\nmodel achieved a lower RMSLE value.\nIn general, the best performance, according to the evaluation met-\nrics, was obtained by the ensemble model of Gradient Boosting Regres-\nsor, Linear Support Vector Regression, and Extra-trees Regressor; where\na considerable difference in the performance in the city of Swindon for\nthe RMSE metric can be seen.\nDespite the fact that the XGBoost model and the stacked ensemble\nuse decision trees as final or only steps to deliver a prediction, the\nresults show that a good approach to follow is not to rely on just a single\nregression algorithm, but to take advantage of the benefits offered by\nensemble approaches. Consequently, this result opens the possibility of\nexploring joint approaches as a follow-up study.\n6.2.3. Results of the LSTM and Stacked-LSTM models adapted from the\nliterature\nThe results of the hyperparameter grid search performed for Model\n1, Model 2, and Model 3 with each of the five datasets showed that a\nbatch size of 32, using the tanh activation function for the LSTM cells\nand SGD optimiser achieved the best performance. Regarding the best\nvalues for the Learning Rate, the non-exhaustive grid search showed\nthat: (1) a value of 0.001 was the best for all the cities when they\nwere trained in Model 2 and Model 3, as well as for the cities of Bristol\nand Swindon with Model 1; and (2) a value of 0.01 is better suited to\ntraining Model 1 with the Bath, Cardiff and Newport datasets.\nTable 9 shows the results obtained by Model 1, Model 2 and Model\n3 after being trained with the identified hyperparameter values.\nBecause the stacked ensemble model performed better than the\nXGBoost model, a comparison of the models based on LSTM-Networks\nwith the XGBoost model is not performed. Therefore, the first com-\nparison carried out is between the rainfall prediction models based\non LSTM-Networks and the ensemble model. To this end, the results\nconcentrated in Tables 7 and 9 are contrasted.\nFrom both tables, it can be noticed that all values of the RMSE, MAE,\nand RMSLE metrics for Model 1, Model 2, and Model 3 are lower than\nthose obtained by the ensemble model for the five cities. These results\nindicate that the prediction models based on LSTM and Stacked-LSTM\nNetworks can achieve better performance values for the evaluation\nmetrics RMSE, MAE and RMSLE than the model based on an ensemble\nof Gradient Boosting Regressor, Linear Support Vector Regression, and\nExtra-trees Regressor for the task of forecasting the volume of rainfall.\nConsequently, a comparison between the three models based on LSTM-\nNetworks is required to determine which model performs better in the\nrain prediction task.\nThe results in Table 9 show that for the RMSE metric, Model 1\nachieves the lowest values except for the city of Swindon where the\nlowest value is obtained by Model 2. Regarding the MAE evaluation\nmetric, Model 1 and Model 2 have the same number of cities with the\nlowest values. Model 1 achieves the lowest MAE values for the cities\nof Bristol and Newport, while Model 2 has lowest MAE values for the\ncities of Bath and Swindon. Both models show the same MAE value for\nthe city of Cardiff. As for the RMSLE and the Loss metrics, Model 1\nachieved the lowest values for the five cities among the three models.\nHowever, analysing the evaluation metrics themselves is only one\npart of the Deep Neural Networks evaluation. The other equally rele-\nvant part of the evaluation is the visual analysis of the training and\nvalidation loss curves. This visual evaluation allows the inspection of\nthe performance of the Neural Network during the training process,\nrevealing aspects such as overfitting, underfitting and diagnosis of\nnon-representative datasets. The aim of the evaluation is to find an\noptimal learning curve, that is, the training and validation loss curves\ndecrease to a point of stabilisation while the generalisation gap is\nminimal (Goodfellow et al., 2016; Gulli et al., 2019).\nThe evaluation of the models resulting from the hyperparameter\ngrid search also considered this second part of the analysis to identify\nthose models with the best training and validation loss curves for each\nof the five datasets. That is, the models with the best performance in\nthe evaluation metrics and with the best training and validation loss\ncurves of all the models tested in the hyperparameter grid search were\nselected and identified as Model 1, Model 2 and Model 3 as appropriate.\nFigs. 7\u20139 show the training and validation loss plots of Model 1, Model\n2 and Model 3, respectively.\nFrom Figs. 7, 8, and 9, it can be noticed that Model 3 has better\ntraining and validation loss curves than Model 1 and Model 2. Although\nModel 1 achieved the lowest values in the evaluation metrics for most\nof the five cities, it can be seen that the Stacked-LSTM Network model\ndid not learn properly. This drawback in Model 1 may be due to the fact\nthat the model is a stack with 10 hidden LSTM layers, while Model 2\nand Model 3 only have one hidden layer; suggesting that the complexity\nof the five datasets can be better learned with shallower Neural Net-\nworks. Furthermore, Model 3 shows that configuring a greater number\nof memory cells and allowing the backwards processing of the input\nsequence while training with a greater number of epochs helps the\nnetwork learn better.\n6.2.4. Results of the proposed models based on Stacked-LSTM and\nBidirectional-LSTM networks\nDue to Model 3 presents the best training and validation loss curves,\nits parameters and hyperparameters were used as the basis to build\nModel 4, Model 5 and Model 6 following the experimental procedure\ndescribed in Section 5.7.\nThe results of the hyperparameter grid search performed for Model\n4, Model 5 and Model 6 with each of the five datasets corroborate that\na batch size of 32, using tanh as the activation function for the LSTM\ncells and SGD as an optimiser, makes all three models achieve better\nperformance. On the other hand, the results show that for all three\nmodels, the best Learning Rate value was 0.001.\nTable 10 shows the results of the evaluation metrics obtained by\nModel 4 (Stacked-LSTM with two hidden layers), Model 5 (Stacked-\nLSTM with three hidden layers), and Model 6 (Bidirectional-LSTM\nNetworks) after being trained with the identified hyperparameter val-\nues.\nThe results in Table 10 show the following: (1) The three models\nachieved equal Loss values for all cities with the exception of the city\nof Bristol with Model 5, where the Loss value is lower; and (2) In the\nevaluation metrics RMSE, MAE, and RMSLE, Model 5 obtained lower\nvalues in the five cities, while Model 6 presents the highest values.\nThese results indicate that the performance of Model 5 is better than\nModel 4 and Model 6 according to the evaluation metrics. Nevertheless,\ntraining and validation loss curves should also be analysed.\nSimilar to the approach followed to present the results of the\nprevious models, Model 4, Model 5 and Model 6 are the models with the\nbest performance in the evaluation metrics and with the best training\nand validation loss curves of all models tested in the hyperparameter\ngrid search. Training and validation loss plots for the five cities for\nModel 4, Model 5, and Model 6 are shown in Figs. 10, 11, and 12,\nrespectively.\nFigs. 10\u201312 show that Model 4 presents better training and valida-\ntion loss curve behaviour for the five cities tested. Between Model 4\n18\n", []], "AutoML results": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\ntested optimisers were Adam and Stochastic Gradient Descent (SGD).\nTested Learning Rate values were 0.3, 0.1, 0.05, 0.01, 0.007, and 0.001.\nMoreover, the hyperparameter grid search also included test batch size\nvalues of 15 and 32, as well as tanh, ReLU, and Swish (Ramachandran,\nZoph, & Le, 2017) as activation functions of the LSTM neurons.\nIn all models, the ReLU activation function was used in the output\nlayer and the Mean Square Error (MSE) was used as Loss function.\nNo dropout or early stop approaches were implemented for any of the\nmodels.\nTables 4, 5, and 6 show the fixed values of the parameters and\nhyperparameters, as well as the percentage of training, validation\nand testing of the datasets used in Model 1, Model 2, and Model 3,\nrespectively. The number of past observations used to predict 8-hours\nof rainfall was established according to the adapted approach and is\ndenoted as the time steps parameter.\n5.7. Proposed models based on Stacked-LSTM and Bidirectional-LSTM\nnetworks\nAfter completing the experiments described in Section 5.6, a perfor-\nmance comparison of Model 1, Model 2, and Model 3 will be performed.\nFrom the three models, the one with the best performance across\nall five datasets will be selected as a base to develop two Stacked-\nLSTM Network models and one Bidirectional-LSTM Network model.\nThe corresponding fixed values of the parameters and hyperparameters\nof this model will be preserved, with the exception of the number of\nhidden layers.\nOf the two proposed models based on Stacked-LSTM Networks, one\nwill include two hidden layers (Model 4) and the other will com-\nprise three hidden layers (Model 5). The proposed Bidirectional-LSTM\nNetwork model (Model 6) will contain only one hidden layer.\nFollowing the same experimental procedure as before, for each\nof the five data sets, a Model 4, a Model 5 and a Model 6 will be\ntrained with the non-exhaustive hyperparameter grid search previously\ndescribed.\n6. Results and discussion\nThis section describes the evaluation metrics used to measure the\nperformance of the trained rainfall prediction models, the structure\nof the datasets used in the experiments carried out, and the results\nof the prediction models tested with the best values obtained by the\nhyperparameter search.\n6.1. Evaluation metrics\nFollowing the approach of the related works to evaluate the perfor-\nmance of the prediction models (Akbari Asanjan et al., 2018; Aswin\net al., 2018; Bell, Carrington, & Moore, 1994; Chao et al., 2018;\nKim & Bae, 2017; Kim et al., 2017; Kumar et al., 2019; Poornima &\nPushpalatha, 2019; Salman et al., 2018; Zhang et al., 2018; Zou et al.,\n2019), the metrics used in this study are:\n\u2022 Loss: The error associated to the proportion of examples for which\nthe model produces an incorrect output (Goodfellow et al., 2016)\nas depicted in Eq. (3).\n\ud835\udc59\ud835\udc5c\ud835\udc60\ud835\udc60=\n{\n1\nif error\n0\notherwise\n(3)\n\u2022 Root Mean Squared Error (RMSE): The sum of the square root\nof the mean of the squared differences between corresponding\nmodel outputs and observations (Barnston, 1992; Willmott &\nMatsuura, 2005).\n\ud835\udc45\ud835\udc40\ud835\udc46\ud835\udc38\ud835\udc53\ud835\udc5c=\n\u221a\u2211\ud835\udc5b\n\ud835\udc56=1(\ud835\udc67\ud835\udc53\ud835\udc56\u2212\ud835\udc67\ud835\udc5c\ud835\udc56)2\n\ud835\udc5b\n(4)\nFormula (4) describes the RMSE evaluation metric, where f is the\nmodel outputs (forecasts), o is the observations, \u2211is summation,\nn is the sample size, and i is the \ud835\udc56th element.\n\u2022 Mean Absolute Error (MAE): The sum of the magnitudes of differ-\nence between the corresponding model outputs and observations\ndivided by the total number of examples (Willmott & Matsuura,\n2005). This metric can be expressed as in Eq. (5).\n\ud835\udc40\ud835\udc34\ud835\udc38\ud835\udc53\ud835\udc5c=\n\u2211\ud835\udc5b\n\ud835\udc56=1(|\ud835\udc67\ud835\udc53\ud835\udc56\u2212\ud835\udc67\ud835\udc5c\ud835\udc56|)\n\ud835\udc5b\n(5)\n\u2022 Root Mean Squared Logarithmic Error (RMSLE): A variant of\nthe RMSE which computes the logarithmic difference between\ncorresponding model outputs and observations. This measure de-\nflates the influence of a large error when the observations rate is\nhigher than the model outputs (Bell et al., 1994). A mathematical\nrepresentation of this evaluation metric is given in Eq. (6); where\nlog is the logarithm.\n\ud835\udc45\ud835\udc40\ud835\udc46\ud835\udc3f\ud835\udc38\ud835\udc53\ud835\udc5c=\n\u221a\u2211\ud835\udc5b\n\ud835\udc56=1(\ud835\udc59\ud835\udc5c\ud835\udc54(\ud835\udc67\ud835\udc53\ud835\udc56+ 1) \u2212\ud835\udc59\ud835\udc5c\ud835\udc54(\ud835\udc67\ud835\udc5c\ud835\udc56+ 1))2\n\ud835\udc5b\n(6)\n6.2. Prediction models results\n6.2.1. XGBoost results\nThe XGBoost regression model was considered to serve as the base-\nline for subsequent rainfall prediction models. Prior to the training\nprocess, a non-exhaustive hyperparameter search was performed for\neach of the five datasets. The results of the best hyperparameter values\nfound by this search are concentrated in the first part of Table 7.\nSubsequently, an individual XGBoost model was trained with each\ndataset and its corresponding hyperparameter values. The performance\nresults of these models are presented in the lower part of Table 7.\nResults show that the Swindon dataset obtained the biggest evalua-\ntion metrics values, denoting that it was more difficult for the model to\nlearn the singularities of the rainfall behaviour for this city compared\nto the rest. On the contrary, the city with the best performance values,\nin general, was Cardiff.\n6.2.2. AutoML results\nAfterwards, the TPOT library was used to perform the AutoML\napproach. A stacked ensemble of Gradient Boosting Regressor, Lin-\near Support Vector Regression, and an Extra-trees Regressor was the\nresulting model.\nThe resulting parameters values for the Gradient Boosting Regressor\nwere: alpha of 0.75, a Learning Rate of 1.0, quantile as loss function,\na maximum depth individual regression estimators of 1, a value of 0.5\nfor the number of features to consider for the best split, a minimum\nof 15 samples required in a leaf, a minimum of 12 samples required\nto split an internal node, 100 boosting stages, and 0.45 as samples\nfraction to fit individual base learners. Regarding the Linear Support\nVector Regression, the resulting parameters were: a regularisation of\n0.1, set to false the option to solve the dual optimisation problem, an\nepsilon value of 0.001, squared epsilon insensitive as loss function, and\na tolerance stopping criteria of 0.001. Lastly, the resulting parameters\nvalues for the Extra-trees Regressor were: 100 estimators (trees), set to\ntrue the bootstrap of samples, a number of one feature to consider when\nlooking for the best split, a minimum number of 16 samples required\nto be at a leaf, and a minimum number of 17 samples required to split\nan internal node.\nSubsequently, an independent stacked ensemble model, with the\nvalues of the parameters described above, was trained with each of\nthe five data sets. Table 8 shows the results obtained by the ensemble\nmodel in the evaluation metrics.\nThe results in Table 8 show that the behaviour of rainfall in Swindon\nwas more difficult to learn than in the rest of the cities. Moreover, the\nCardiff dataset achieved the best performance in the evaluation metrics.\n17\n", []], "XGBoost results": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\ntested optimisers were Adam and Stochastic Gradient Descent (SGD).\nTested Learning Rate values were 0.3, 0.1, 0.05, 0.01, 0.007, and 0.001.\nMoreover, the hyperparameter grid search also included test batch size\nvalues of 15 and 32, as well as tanh, ReLU, and Swish (Ramachandran,\nZoph, & Le, 2017) as activation functions of the LSTM neurons.\nIn all models, the ReLU activation function was used in the output\nlayer and the Mean Square Error (MSE) was used as Loss function.\nNo dropout or early stop approaches were implemented for any of the\nmodels.\nTables 4, 5, and 6 show the fixed values of the parameters and\nhyperparameters, as well as the percentage of training, validation\nand testing of the datasets used in Model 1, Model 2, and Model 3,\nrespectively. The number of past observations used to predict 8-hours\nof rainfall was established according to the adapted approach and is\ndenoted as the time steps parameter.\n5.7. Proposed models based on Stacked-LSTM and Bidirectional-LSTM\nnetworks\nAfter completing the experiments described in Section 5.6, a perfor-\nmance comparison of Model 1, Model 2, and Model 3 will be performed.\nFrom the three models, the one with the best performance across\nall five datasets will be selected as a base to develop two Stacked-\nLSTM Network models and one Bidirectional-LSTM Network model.\nThe corresponding fixed values of the parameters and hyperparameters\nof this model will be preserved, with the exception of the number of\nhidden layers.\nOf the two proposed models based on Stacked-LSTM Networks, one\nwill include two hidden layers (Model 4) and the other will com-\nprise three hidden layers (Model 5). The proposed Bidirectional-LSTM\nNetwork model (Model 6) will contain only one hidden layer.\nFollowing the same experimental procedure as before, for each\nof the five data sets, a Model 4, a Model 5 and a Model 6 will be\ntrained with the non-exhaustive hyperparameter grid search previously\ndescribed.\n6. Results and discussion\nThis section describes the evaluation metrics used to measure the\nperformance of the trained rainfall prediction models, the structure\nof the datasets used in the experiments carried out, and the results\nof the prediction models tested with the best values obtained by the\nhyperparameter search.\n6.1. Evaluation metrics\nFollowing the approach of the related works to evaluate the perfor-\nmance of the prediction models (Akbari Asanjan et al., 2018; Aswin\net al., 2018; Bell, Carrington, & Moore, 1994; Chao et al., 2018;\nKim & Bae, 2017; Kim et al., 2017; Kumar et al., 2019; Poornima &\nPushpalatha, 2019; Salman et al., 2018; Zhang et al., 2018; Zou et al.,\n2019), the metrics used in this study are:\n\u2022 Loss: The error associated to the proportion of examples for which\nthe model produces an incorrect output (Goodfellow et al., 2016)\nas depicted in Eq. (3).\n\ud835\udc59\ud835\udc5c\ud835\udc60\ud835\udc60=\n{\n1\nif error\n0\notherwise\n(3)\n\u2022 Root Mean Squared Error (RMSE): The sum of the square root\nof the mean of the squared differences between corresponding\nmodel outputs and observations (Barnston, 1992; Willmott &\nMatsuura, 2005).\n\ud835\udc45\ud835\udc40\ud835\udc46\ud835\udc38\ud835\udc53\ud835\udc5c=\n\u221a\u2211\ud835\udc5b\n\ud835\udc56=1(\ud835\udc67\ud835\udc53\ud835\udc56\u2212\ud835\udc67\ud835\udc5c\ud835\udc56)2\n\ud835\udc5b\n(4)\nFormula (4) describes the RMSE evaluation metric, where f is the\nmodel outputs (forecasts), o is the observations, \u2211is summation,\nn is the sample size, and i is the \ud835\udc56th element.\n\u2022 Mean Absolute Error (MAE): The sum of the magnitudes of differ-\nence between the corresponding model outputs and observations\ndivided by the total number of examples (Willmott & Matsuura,\n2005). This metric can be expressed as in Eq. (5).\n\ud835\udc40\ud835\udc34\ud835\udc38\ud835\udc53\ud835\udc5c=\n\u2211\ud835\udc5b\n\ud835\udc56=1(|\ud835\udc67\ud835\udc53\ud835\udc56\u2212\ud835\udc67\ud835\udc5c\ud835\udc56|)\n\ud835\udc5b\n(5)\n\u2022 Root Mean Squared Logarithmic Error (RMSLE): A variant of\nthe RMSE which computes the logarithmic difference between\ncorresponding model outputs and observations. This measure de-\nflates the influence of a large error when the observations rate is\nhigher than the model outputs (Bell et al., 1994). A mathematical\nrepresentation of this evaluation metric is given in Eq. (6); where\nlog is the logarithm.\n\ud835\udc45\ud835\udc40\ud835\udc46\ud835\udc3f\ud835\udc38\ud835\udc53\ud835\udc5c=\n\u221a\u2211\ud835\udc5b\n\ud835\udc56=1(\ud835\udc59\ud835\udc5c\ud835\udc54(\ud835\udc67\ud835\udc53\ud835\udc56+ 1) \u2212\ud835\udc59\ud835\udc5c\ud835\udc54(\ud835\udc67\ud835\udc5c\ud835\udc56+ 1))2\n\ud835\udc5b\n(6)\n6.2. Prediction models results\n6.2.1. XGBoost results\nThe XGBoost regression model was considered to serve as the base-\nline for subsequent rainfall prediction models. Prior to the training\nprocess, a non-exhaustive hyperparameter search was performed for\neach of the five datasets. The results of the best hyperparameter values\nfound by this search are concentrated in the first part of Table 7.\nSubsequently, an individual XGBoost model was trained with each\ndataset and its corresponding hyperparameter values. The performance\nresults of these models are presented in the lower part of Table 7.\nResults show that the Swindon dataset obtained the biggest evalua-\ntion metrics values, denoting that it was more difficult for the model to\nlearn the singularities of the rainfall behaviour for this city compared\nto the rest. On the contrary, the city with the best performance values,\nin general, was Cardiff.\n6.2.2. AutoML results\nAfterwards, the TPOT library was used to perform the AutoML\napproach. A stacked ensemble of Gradient Boosting Regressor, Lin-\near Support Vector Regression, and an Extra-trees Regressor was the\nresulting model.\nThe resulting parameters values for the Gradient Boosting Regressor\nwere: alpha of 0.75, a Learning Rate of 1.0, quantile as loss function,\na maximum depth individual regression estimators of 1, a value of 0.5\nfor the number of features to consider for the best split, a minimum\nof 15 samples required in a leaf, a minimum of 12 samples required\nto split an internal node, 100 boosting stages, and 0.45 as samples\nfraction to fit individual base learners. Regarding the Linear Support\nVector Regression, the resulting parameters were: a regularisation of\n0.1, set to false the option to solve the dual optimisation problem, an\nepsilon value of 0.001, squared epsilon insensitive as loss function, and\na tolerance stopping criteria of 0.001. Lastly, the resulting parameters\nvalues for the Extra-trees Regressor were: 100 estimators (trees), set to\ntrue the bootstrap of samples, a number of one feature to consider when\nlooking for the best split, a minimum number of 16 samples required\nto be at a leaf, and a minimum number of 17 samples required to split\nan internal node.\nSubsequently, an independent stacked ensemble model, with the\nvalues of the parameters described above, was trained with each of\nthe five data sets. Table 8 shows the results obtained by the ensemble\nmodel in the evaluation metrics.\nThe results in Table 8 show that the behaviour of rainfall in Swindon\nwas more difficult to learn than in the rest of the cities. Moreover, the\nCardiff dataset achieved the best performance in the evaluation metrics.\n17\n", []], "Prediction models results": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\ntested optimisers were Adam and Stochastic Gradient Descent (SGD).\nTested Learning Rate values were 0.3, 0.1, 0.05, 0.01, 0.007, and 0.001.\nMoreover, the hyperparameter grid search also included test batch size\nvalues of 15 and 32, as well as tanh, ReLU, and Swish (Ramachandran,\nZoph, & Le, 2017) as activation functions of the LSTM neurons.\nIn all models, the ReLU activation function was used in the output\nlayer and the Mean Square Error (MSE) was used as Loss function.\nNo dropout or early stop approaches were implemented for any of the\nmodels.\nTables 4, 5, and 6 show the fixed values of the parameters and\nhyperparameters, as well as the percentage of training, validation\nand testing of the datasets used in Model 1, Model 2, and Model 3,\nrespectively. The number of past observations used to predict 8-hours\nof rainfall was established according to the adapted approach and is\ndenoted as the time steps parameter.\n5.7. Proposed models based on Stacked-LSTM and Bidirectional-LSTM\nnetworks\nAfter completing the experiments described in Section 5.6, a perfor-\nmance comparison of Model 1, Model 2, and Model 3 will be performed.\nFrom the three models, the one with the best performance across\nall five datasets will be selected as a base to develop two Stacked-\nLSTM Network models and one Bidirectional-LSTM Network model.\nThe corresponding fixed values of the parameters and hyperparameters\nof this model will be preserved, with the exception of the number of\nhidden layers.\nOf the two proposed models based on Stacked-LSTM Networks, one\nwill include two hidden layers (Model 4) and the other will com-\nprise three hidden layers (Model 5). The proposed Bidirectional-LSTM\nNetwork model (Model 6) will contain only one hidden layer.\nFollowing the same experimental procedure as before, for each\nof the five data sets, a Model 4, a Model 5 and a Model 6 will be\ntrained with the non-exhaustive hyperparameter grid search previously\ndescribed.\n6. Results and discussion\nThis section describes the evaluation metrics used to measure the\nperformance of the trained rainfall prediction models, the structure\nof the datasets used in the experiments carried out, and the results\nof the prediction models tested with the best values obtained by the\nhyperparameter search.\n6.1. Evaluation metrics\nFollowing the approach of the related works to evaluate the perfor-\nmance of the prediction models (Akbari Asanjan et al., 2018; Aswin\net al., 2018; Bell, Carrington, & Moore, 1994; Chao et al., 2018;\nKim & Bae, 2017; Kim et al., 2017; Kumar et al., 2019; Poornima &\nPushpalatha, 2019; Salman et al., 2018; Zhang et al., 2018; Zou et al.,\n2019), the metrics used in this study are:\n\u2022 Loss: The error associated to the proportion of examples for which\nthe model produces an incorrect output (Goodfellow et al., 2016)\nas depicted in Eq. (3).\n\ud835\udc59\ud835\udc5c\ud835\udc60\ud835\udc60=\n{\n1\nif error\n0\notherwise\n(3)\n\u2022 Root Mean Squared Error (RMSE): The sum of the square root\nof the mean of the squared differences between corresponding\nmodel outputs and observations (Barnston, 1992; Willmott &\nMatsuura, 2005).\n\ud835\udc45\ud835\udc40\ud835\udc46\ud835\udc38\ud835\udc53\ud835\udc5c=\n\u221a\u2211\ud835\udc5b\n\ud835\udc56=1(\ud835\udc67\ud835\udc53\ud835\udc56\u2212\ud835\udc67\ud835\udc5c\ud835\udc56)2\n\ud835\udc5b\n(4)\nFormula (4) describes the RMSE evaluation metric, where f is the\nmodel outputs (forecasts), o is the observations, \u2211is summation,\nn is the sample size, and i is the \ud835\udc56th element.\n\u2022 Mean Absolute Error (MAE): The sum of the magnitudes of differ-\nence between the corresponding model outputs and observations\ndivided by the total number of examples (Willmott & Matsuura,\n2005). This metric can be expressed as in Eq. (5).\n\ud835\udc40\ud835\udc34\ud835\udc38\ud835\udc53\ud835\udc5c=\n\u2211\ud835\udc5b\n\ud835\udc56=1(|\ud835\udc67\ud835\udc53\ud835\udc56\u2212\ud835\udc67\ud835\udc5c\ud835\udc56|)\n\ud835\udc5b\n(5)\n\u2022 Root Mean Squared Logarithmic Error (RMSLE): A variant of\nthe RMSE which computes the logarithmic difference between\ncorresponding model outputs and observations. This measure de-\nflates the influence of a large error when the observations rate is\nhigher than the model outputs (Bell et al., 1994). A mathematical\nrepresentation of this evaluation metric is given in Eq. (6); where\nlog is the logarithm.\n\ud835\udc45\ud835\udc40\ud835\udc46\ud835\udc3f\ud835\udc38\ud835\udc53\ud835\udc5c=\n\u221a\u2211\ud835\udc5b\n\ud835\udc56=1(\ud835\udc59\ud835\udc5c\ud835\udc54(\ud835\udc67\ud835\udc53\ud835\udc56+ 1) \u2212\ud835\udc59\ud835\udc5c\ud835\udc54(\ud835\udc67\ud835\udc5c\ud835\udc56+ 1))2\n\ud835\udc5b\n(6)\n6.2. Prediction models results\n6.2.1. XGBoost results\nThe XGBoost regression model was considered to serve as the base-\nline for subsequent rainfall prediction models. Prior to the training\nprocess, a non-exhaustive hyperparameter search was performed for\neach of the five datasets. The results of the best hyperparameter values\nfound by this search are concentrated in the first part of Table 7.\nSubsequently, an individual XGBoost model was trained with each\ndataset and its corresponding hyperparameter values. The performance\nresults of these models are presented in the lower part of Table 7.\nResults show that the Swindon dataset obtained the biggest evalua-\ntion metrics values, denoting that it was more difficult for the model to\nlearn the singularities of the rainfall behaviour for this city compared\nto the rest. On the contrary, the city with the best performance values,\nin general, was Cardiff.\n6.2.2. AutoML results\nAfterwards, the TPOT library was used to perform the AutoML\napproach. A stacked ensemble of Gradient Boosting Regressor, Lin-\near Support Vector Regression, and an Extra-trees Regressor was the\nresulting model.\nThe resulting parameters values for the Gradient Boosting Regressor\nwere: alpha of 0.75, a Learning Rate of 1.0, quantile as loss function,\na maximum depth individual regression estimators of 1, a value of 0.5\nfor the number of features to consider for the best split, a minimum\nof 15 samples required in a leaf, a minimum of 12 samples required\nto split an internal node, 100 boosting stages, and 0.45 as samples\nfraction to fit individual base learners. Regarding the Linear Support\nVector Regression, the resulting parameters were: a regularisation of\n0.1, set to false the option to solve the dual optimisation problem, an\nepsilon value of 0.001, squared epsilon insensitive as loss function, and\na tolerance stopping criteria of 0.001. Lastly, the resulting parameters\nvalues for the Extra-trees Regressor were: 100 estimators (trees), set to\ntrue the bootstrap of samples, a number of one feature to consider when\nlooking for the best split, a minimum number of 16 samples required\nto be at a leaf, and a minimum number of 17 samples required to split\nan internal node.\nSubsequently, an independent stacked ensemble model, with the\nvalues of the parameters described above, was trained with each of\nthe five data sets. Table 8 shows the results obtained by the ensemble\nmodel in the evaluation metrics.\nThe results in Table 8 show that the behaviour of rainfall in Swindon\nwas more difficult to learn than in the rest of the cities. Moreover, the\nCardiff dataset achieved the best performance in the evaluation metrics.\n17\n", []], "Evaluation metrics": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\ntested optimisers were Adam and Stochastic Gradient Descent (SGD).\nTested Learning Rate values were 0.3, 0.1, 0.05, 0.01, 0.007, and 0.001.\nMoreover, the hyperparameter grid search also included test batch size\nvalues of 15 and 32, as well as tanh, ReLU, and Swish (Ramachandran,\nZoph, & Le, 2017) as activation functions of the LSTM neurons.\nIn all models, the ReLU activation function was used in the output\nlayer and the Mean Square Error (MSE) was used as Loss function.\nNo dropout or early stop approaches were implemented for any of the\nmodels.\nTables 4, 5, and 6 show the fixed values of the parameters and\nhyperparameters, as well as the percentage of training, validation\nand testing of the datasets used in Model 1, Model 2, and Model 3,\nrespectively. The number of past observations used to predict 8-hours\nof rainfall was established according to the adapted approach and is\ndenoted as the time steps parameter.\n5.7. Proposed models based on Stacked-LSTM and Bidirectional-LSTM\nnetworks\nAfter completing the experiments described in Section 5.6, a perfor-\nmance comparison of Model 1, Model 2, and Model 3 will be performed.\nFrom the three models, the one with the best performance across\nall five datasets will be selected as a base to develop two Stacked-\nLSTM Network models and one Bidirectional-LSTM Network model.\nThe corresponding fixed values of the parameters and hyperparameters\nof this model will be preserved, with the exception of the number of\nhidden layers.\nOf the two proposed models based on Stacked-LSTM Networks, one\nwill include two hidden layers (Model 4) and the other will com-\nprise three hidden layers (Model 5). The proposed Bidirectional-LSTM\nNetwork model (Model 6) will contain only one hidden layer.\nFollowing the same experimental procedure as before, for each\nof the five data sets, a Model 4, a Model 5 and a Model 6 will be\ntrained with the non-exhaustive hyperparameter grid search previously\ndescribed.\n6. Results and discussion\nThis section describes the evaluation metrics used to measure the\nperformance of the trained rainfall prediction models, the structure\nof the datasets used in the experiments carried out, and the results\nof the prediction models tested with the best values obtained by the\nhyperparameter search.\n6.1. Evaluation metrics\nFollowing the approach of the related works to evaluate the perfor-\nmance of the prediction models (Akbari Asanjan et al., 2018; Aswin\net al., 2018; Bell, Carrington, & Moore, 1994; Chao et al., 2018;\nKim & Bae, 2017; Kim et al., 2017; Kumar et al., 2019; Poornima &\nPushpalatha, 2019; Salman et al., 2018; Zhang et al., 2018; Zou et al.,\n2019), the metrics used in this study are:\n\u2022 Loss: The error associated to the proportion of examples for which\nthe model produces an incorrect output (Goodfellow et al., 2016)\nas depicted in Eq. (3).\n\ud835\udc59\ud835\udc5c\ud835\udc60\ud835\udc60=\n{\n1\nif error\n0\notherwise\n(3)\n\u2022 Root Mean Squared Error (RMSE): The sum of the square root\nof the mean of the squared differences between corresponding\nmodel outputs and observations (Barnston, 1992; Willmott &\nMatsuura, 2005).\n\ud835\udc45\ud835\udc40\ud835\udc46\ud835\udc38\ud835\udc53\ud835\udc5c=\n\u221a\u2211\ud835\udc5b\n\ud835\udc56=1(\ud835\udc67\ud835\udc53\ud835\udc56\u2212\ud835\udc67\ud835\udc5c\ud835\udc56)2\n\ud835\udc5b\n(4)\nFormula (4) describes the RMSE evaluation metric, where f is the\nmodel outputs (forecasts), o is the observations, \u2211is summation,\nn is the sample size, and i is the \ud835\udc56th element.\n\u2022 Mean Absolute Error (MAE): The sum of the magnitudes of differ-\nence between the corresponding model outputs and observations\ndivided by the total number of examples (Willmott & Matsuura,\n2005). This metric can be expressed as in Eq. (5).\n\ud835\udc40\ud835\udc34\ud835\udc38\ud835\udc53\ud835\udc5c=\n\u2211\ud835\udc5b\n\ud835\udc56=1(|\ud835\udc67\ud835\udc53\ud835\udc56\u2212\ud835\udc67\ud835\udc5c\ud835\udc56|)\n\ud835\udc5b\n(5)\n\u2022 Root Mean Squared Logarithmic Error (RMSLE): A variant of\nthe RMSE which computes the logarithmic difference between\ncorresponding model outputs and observations. This measure de-\nflates the influence of a large error when the observations rate is\nhigher than the model outputs (Bell et al., 1994). A mathematical\nrepresentation of this evaluation metric is given in Eq. (6); where\nlog is the logarithm.\n\ud835\udc45\ud835\udc40\ud835\udc46\ud835\udc3f\ud835\udc38\ud835\udc53\ud835\udc5c=\n\u221a\u2211\ud835\udc5b\n\ud835\udc56=1(\ud835\udc59\ud835\udc5c\ud835\udc54(\ud835\udc67\ud835\udc53\ud835\udc56+ 1) \u2212\ud835\udc59\ud835\udc5c\ud835\udc54(\ud835\udc67\ud835\udc5c\ud835\udc56+ 1))2\n\ud835\udc5b\n(6)\n6.2. Prediction models results\n6.2.1. XGBoost results\nThe XGBoost regression model was considered to serve as the base-\nline for subsequent rainfall prediction models. Prior to the training\nprocess, a non-exhaustive hyperparameter search was performed for\neach of the five datasets. The results of the best hyperparameter values\nfound by this search are concentrated in the first part of Table 7.\nSubsequently, an individual XGBoost model was trained with each\ndataset and its corresponding hyperparameter values. The performance\nresults of these models are presented in the lower part of Table 7.\nResults show that the Swindon dataset obtained the biggest evalua-\ntion metrics values, denoting that it was more difficult for the model to\nlearn the singularities of the rainfall behaviour for this city compared\nto the rest. On the contrary, the city with the best performance values,\nin general, was Cardiff.\n6.2.2. AutoML results\nAfterwards, the TPOT library was used to perform the AutoML\napproach. A stacked ensemble of Gradient Boosting Regressor, Lin-\near Support Vector Regression, and an Extra-trees Regressor was the\nresulting model.\nThe resulting parameters values for the Gradient Boosting Regressor\nwere: alpha of 0.75, a Learning Rate of 1.0, quantile as loss function,\na maximum depth individual regression estimators of 1, a value of 0.5\nfor the number of features to consider for the best split, a minimum\nof 15 samples required in a leaf, a minimum of 12 samples required\nto split an internal node, 100 boosting stages, and 0.45 as samples\nfraction to fit individual base learners. Regarding the Linear Support\nVector Regression, the resulting parameters were: a regularisation of\n0.1, set to false the option to solve the dual optimisation problem, an\nepsilon value of 0.001, squared epsilon insensitive as loss function, and\na tolerance stopping criteria of 0.001. Lastly, the resulting parameters\nvalues for the Extra-trees Regressor were: 100 estimators (trees), set to\ntrue the bootstrap of samples, a number of one feature to consider when\nlooking for the best split, a minimum number of 16 samples required\nto be at a leaf, and a minimum number of 17 samples required to split\nan internal node.\nSubsequently, an independent stacked ensemble model, with the\nvalues of the parameters described above, was trained with each of\nthe five data sets. Table 8 shows the results obtained by the ensemble\nmodel in the evaluation metrics.\nThe results in Table 8 show that the behaviour of rainfall in Swindon\nwas more difficult to learn than in the rest of the cities. Moreover, the\nCardiff dataset achieved the best performance in the evaluation metrics.\n17\n", []], "Results and discussion": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\ntested optimisers were Adam and Stochastic Gradient Descent (SGD).\nTested Learning Rate values were 0.3, 0.1, 0.05, 0.01, 0.007, and 0.001.\nMoreover, the hyperparameter grid search also included test batch size\nvalues of 15 and 32, as well as tanh, ReLU, and Swish (Ramachandran,\nZoph, & Le, 2017) as activation functions of the LSTM neurons.\nIn all models, the ReLU activation function was used in the output\nlayer and the Mean Square Error (MSE) was used as Loss function.\nNo dropout or early stop approaches were implemented for any of the\nmodels.\nTables 4, 5, and 6 show the fixed values of the parameters and\nhyperparameters, as well as the percentage of training, validation\nand testing of the datasets used in Model 1, Model 2, and Model 3,\nrespectively. The number of past observations used to predict 8-hours\nof rainfall was established according to the adapted approach and is\ndenoted as the time steps parameter.\n5.7. Proposed models based on Stacked-LSTM and Bidirectional-LSTM\nnetworks\nAfter completing the experiments described in Section 5.6, a perfor-\nmance comparison of Model 1, Model 2, and Model 3 will be performed.\nFrom the three models, the one with the best performance across\nall five datasets will be selected as a base to develop two Stacked-\nLSTM Network models and one Bidirectional-LSTM Network model.\nThe corresponding fixed values of the parameters and hyperparameters\nof this model will be preserved, with the exception of the number of\nhidden layers.\nOf the two proposed models based on Stacked-LSTM Networks, one\nwill include two hidden layers (Model 4) and the other will com-\nprise three hidden layers (Model 5). The proposed Bidirectional-LSTM\nNetwork model (Model 6) will contain only one hidden layer.\nFollowing the same experimental procedure as before, for each\nof the five data sets, a Model 4, a Model 5 and a Model 6 will be\ntrained with the non-exhaustive hyperparameter grid search previously\ndescribed.\n6. Results and discussion\nThis section describes the evaluation metrics used to measure the\nperformance of the trained rainfall prediction models, the structure\nof the datasets used in the experiments carried out, and the results\nof the prediction models tested with the best values obtained by the\nhyperparameter search.\n6.1. Evaluation metrics\nFollowing the approach of the related works to evaluate the perfor-\nmance of the prediction models (Akbari Asanjan et al., 2018; Aswin\net al., 2018; Bell, Carrington, & Moore, 1994; Chao et al., 2018;\nKim & Bae, 2017; Kim et al., 2017; Kumar et al., 2019; Poornima &\nPushpalatha, 2019; Salman et al., 2018; Zhang et al., 2018; Zou et al.,\n2019), the metrics used in this study are:\n\u2022 Loss: The error associated to the proportion of examples for which\nthe model produces an incorrect output (Goodfellow et al., 2016)\nas depicted in Eq. (3).\n\ud835\udc59\ud835\udc5c\ud835\udc60\ud835\udc60=\n{\n1\nif error\n0\notherwise\n(3)\n\u2022 Root Mean Squared Error (RMSE): The sum of the square root\nof the mean of the squared differences between corresponding\nmodel outputs and observations (Barnston, 1992; Willmott &\nMatsuura, 2005).\n\ud835\udc45\ud835\udc40\ud835\udc46\ud835\udc38\ud835\udc53\ud835\udc5c=\n\u221a\u2211\ud835\udc5b\n\ud835\udc56=1(\ud835\udc67\ud835\udc53\ud835\udc56\u2212\ud835\udc67\ud835\udc5c\ud835\udc56)2\n\ud835\udc5b\n(4)\nFormula (4) describes the RMSE evaluation metric, where f is the\nmodel outputs (forecasts), o is the observations, \u2211is summation,\nn is the sample size, and i is the \ud835\udc56th element.\n\u2022 Mean Absolute Error (MAE): The sum of the magnitudes of differ-\nence between the corresponding model outputs and observations\ndivided by the total number of examples (Willmott & Matsuura,\n2005). This metric can be expressed as in Eq. (5).\n\ud835\udc40\ud835\udc34\ud835\udc38\ud835\udc53\ud835\udc5c=\n\u2211\ud835\udc5b\n\ud835\udc56=1(|\ud835\udc67\ud835\udc53\ud835\udc56\u2212\ud835\udc67\ud835\udc5c\ud835\udc56|)\n\ud835\udc5b\n(5)\n\u2022 Root Mean Squared Logarithmic Error (RMSLE): A variant of\nthe RMSE which computes the logarithmic difference between\ncorresponding model outputs and observations. This measure de-\nflates the influence of a large error when the observations rate is\nhigher than the model outputs (Bell et al., 1994). A mathematical\nrepresentation of this evaluation metric is given in Eq. (6); where\nlog is the logarithm.\n\ud835\udc45\ud835\udc40\ud835\udc46\ud835\udc3f\ud835\udc38\ud835\udc53\ud835\udc5c=\n\u221a\u2211\ud835\udc5b\n\ud835\udc56=1(\ud835\udc59\ud835\udc5c\ud835\udc54(\ud835\udc67\ud835\udc53\ud835\udc56+ 1) \u2212\ud835\udc59\ud835\udc5c\ud835\udc54(\ud835\udc67\ud835\udc5c\ud835\udc56+ 1))2\n\ud835\udc5b\n(6)\n6.2. Prediction models results\n6.2.1. XGBoost results\nThe XGBoost regression model was considered to serve as the base-\nline for subsequent rainfall prediction models. Prior to the training\nprocess, a non-exhaustive hyperparameter search was performed for\neach of the five datasets. The results of the best hyperparameter values\nfound by this search are concentrated in the first part of Table 7.\nSubsequently, an individual XGBoost model was trained with each\ndataset and its corresponding hyperparameter values. The performance\nresults of these models are presented in the lower part of Table 7.\nResults show that the Swindon dataset obtained the biggest evalua-\ntion metrics values, denoting that it was more difficult for the model to\nlearn the singularities of the rainfall behaviour for this city compared\nto the rest. On the contrary, the city with the best performance values,\nin general, was Cardiff.\n6.2.2. AutoML results\nAfterwards, the TPOT library was used to perform the AutoML\napproach. A stacked ensemble of Gradient Boosting Regressor, Lin-\near Support Vector Regression, and an Extra-trees Regressor was the\nresulting model.\nThe resulting parameters values for the Gradient Boosting Regressor\nwere: alpha of 0.75, a Learning Rate of 1.0, quantile as loss function,\na maximum depth individual regression estimators of 1, a value of 0.5\nfor the number of features to consider for the best split, a minimum\nof 15 samples required in a leaf, a minimum of 12 samples required\nto split an internal node, 100 boosting stages, and 0.45 as samples\nfraction to fit individual base learners. Regarding the Linear Support\nVector Regression, the resulting parameters were: a regularisation of\n0.1, set to false the option to solve the dual optimisation problem, an\nepsilon value of 0.001, squared epsilon insensitive as loss function, and\na tolerance stopping criteria of 0.001. Lastly, the resulting parameters\nvalues for the Extra-trees Regressor were: 100 estimators (trees), set to\ntrue the bootstrap of samples, a number of one feature to consider when\nlooking for the best split, a minimum number of 16 samples required\nto be at a leaf, and a minimum number of 17 samples required to split\nan internal node.\nSubsequently, an independent stacked ensemble model, with the\nvalues of the parameters described above, was trained with each of\nthe five data sets. Table 8 shows the results obtained by the ensemble\nmodel in the evaluation metrics.\nThe results in Table 8 show that the behaviour of rainfall in Swindon\nwas more difficult to learn than in the rest of the cities. Moreover, the\nCardiff dataset achieved the best performance in the evaluation metrics.\n17\n", []], "Proposed models based on Stacked-LSTM and Bidirectional-LSTM networks": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\ntested optimisers were Adam and Stochastic Gradient Descent (SGD).\nTested Learning Rate values were 0.3, 0.1, 0.05, 0.01, 0.007, and 0.001.\nMoreover, the hyperparameter grid search also included test batch size\nvalues of 15 and 32, as well as tanh, ReLU, and Swish (Ramachandran,\nZoph, & Le, 2017) as activation functions of the LSTM neurons.\nIn all models, the ReLU activation function was used in the output\nlayer and the Mean Square Error (MSE) was used as Loss function.\nNo dropout or early stop approaches were implemented for any of the\nmodels.\nTables 4, 5, and 6 show the fixed values of the parameters and\nhyperparameters, as well as the percentage of training, validation\nand testing of the datasets used in Model 1, Model 2, and Model 3,\nrespectively. The number of past observations used to predict 8-hours\nof rainfall was established according to the adapted approach and is\ndenoted as the time steps parameter.\n5.7. Proposed models based on Stacked-LSTM and Bidirectional-LSTM\nnetworks\nAfter completing the experiments described in Section 5.6, a perfor-\nmance comparison of Model 1, Model 2, and Model 3 will be performed.\nFrom the three models, the one with the best performance across\nall five datasets will be selected as a base to develop two Stacked-\nLSTM Network models and one Bidirectional-LSTM Network model.\nThe corresponding fixed values of the parameters and hyperparameters\nof this model will be preserved, with the exception of the number of\nhidden layers.\nOf the two proposed models based on Stacked-LSTM Networks, one\nwill include two hidden layers (Model 4) and the other will com-\nprise three hidden layers (Model 5). The proposed Bidirectional-LSTM\nNetwork model (Model 6) will contain only one hidden layer.\nFollowing the same experimental procedure as before, for each\nof the five data sets, a Model 4, a Model 5 and a Model 6 will be\ntrained with the non-exhaustive hyperparameter grid search previously\ndescribed.\n6. Results and discussion\nThis section describes the evaluation metrics used to measure the\nperformance of the trained rainfall prediction models, the structure\nof the datasets used in the experiments carried out, and the results\nof the prediction models tested with the best values obtained by the\nhyperparameter search.\n6.1. Evaluation metrics\nFollowing the approach of the related works to evaluate the perfor-\nmance of the prediction models (Akbari Asanjan et al., 2018; Aswin\net al., 2018; Bell, Carrington, & Moore, 1994; Chao et al., 2018;\nKim & Bae, 2017; Kim et al., 2017; Kumar et al., 2019; Poornima &\nPushpalatha, 2019; Salman et al., 2018; Zhang et al., 2018; Zou et al.,\n2019), the metrics used in this study are:\n\u2022 Loss: The error associated to the proportion of examples for which\nthe model produces an incorrect output (Goodfellow et al., 2016)\nas depicted in Eq. (3).\n\ud835\udc59\ud835\udc5c\ud835\udc60\ud835\udc60=\n{\n1\nif error\n0\notherwise\n(3)\n\u2022 Root Mean Squared Error (RMSE): The sum of the square root\nof the mean of the squared differences between corresponding\nmodel outputs and observations (Barnston, 1992; Willmott &\nMatsuura, 2005).\n\ud835\udc45\ud835\udc40\ud835\udc46\ud835\udc38\ud835\udc53\ud835\udc5c=\n\u221a\u2211\ud835\udc5b\n\ud835\udc56=1(\ud835\udc67\ud835\udc53\ud835\udc56\u2212\ud835\udc67\ud835\udc5c\ud835\udc56)2\n\ud835\udc5b\n(4)\nFormula (4) describes the RMSE evaluation metric, where f is the\nmodel outputs (forecasts), o is the observations, \u2211is summation,\nn is the sample size, and i is the \ud835\udc56th element.\n\u2022 Mean Absolute Error (MAE): The sum of the magnitudes of differ-\nence between the corresponding model outputs and observations\ndivided by the total number of examples (Willmott & Matsuura,\n2005). This metric can be expressed as in Eq. (5).\n\ud835\udc40\ud835\udc34\ud835\udc38\ud835\udc53\ud835\udc5c=\n\u2211\ud835\udc5b\n\ud835\udc56=1(|\ud835\udc67\ud835\udc53\ud835\udc56\u2212\ud835\udc67\ud835\udc5c\ud835\udc56|)\n\ud835\udc5b\n(5)\n\u2022 Root Mean Squared Logarithmic Error (RMSLE): A variant of\nthe RMSE which computes the logarithmic difference between\ncorresponding model outputs and observations. This measure de-\nflates the influence of a large error when the observations rate is\nhigher than the model outputs (Bell et al., 1994). A mathematical\nrepresentation of this evaluation metric is given in Eq. (6); where\nlog is the logarithm.\n\ud835\udc45\ud835\udc40\ud835\udc46\ud835\udc3f\ud835\udc38\ud835\udc53\ud835\udc5c=\n\u221a\u2211\ud835\udc5b\n\ud835\udc56=1(\ud835\udc59\ud835\udc5c\ud835\udc54(\ud835\udc67\ud835\udc53\ud835\udc56+ 1) \u2212\ud835\udc59\ud835\udc5c\ud835\udc54(\ud835\udc67\ud835\udc5c\ud835\udc56+ 1))2\n\ud835\udc5b\n(6)\n6.2. Prediction models results\n6.2.1. XGBoost results\nThe XGBoost regression model was considered to serve as the base-\nline for subsequent rainfall prediction models. Prior to the training\nprocess, a non-exhaustive hyperparameter search was performed for\neach of the five datasets. The results of the best hyperparameter values\nfound by this search are concentrated in the first part of Table 7.\nSubsequently, an individual XGBoost model was trained with each\ndataset and its corresponding hyperparameter values. The performance\nresults of these models are presented in the lower part of Table 7.\nResults show that the Swindon dataset obtained the biggest evalua-\ntion metrics values, denoting that it was more difficult for the model to\nlearn the singularities of the rainfall behaviour for this city compared\nto the rest. On the contrary, the city with the best performance values,\nin general, was Cardiff.\n6.2.2. AutoML results\nAfterwards, the TPOT library was used to perform the AutoML\napproach. A stacked ensemble of Gradient Boosting Regressor, Lin-\near Support Vector Regression, and an Extra-trees Regressor was the\nresulting model.\nThe resulting parameters values for the Gradient Boosting Regressor\nwere: alpha of 0.75, a Learning Rate of 1.0, quantile as loss function,\na maximum depth individual regression estimators of 1, a value of 0.5\nfor the number of features to consider for the best split, a minimum\nof 15 samples required in a leaf, a minimum of 12 samples required\nto split an internal node, 100 boosting stages, and 0.45 as samples\nfraction to fit individual base learners. Regarding the Linear Support\nVector Regression, the resulting parameters were: a regularisation of\n0.1, set to false the option to solve the dual optimisation problem, an\nepsilon value of 0.001, squared epsilon insensitive as loss function, and\na tolerance stopping criteria of 0.001. Lastly, the resulting parameters\nvalues for the Extra-trees Regressor were: 100 estimators (trees), set to\ntrue the bootstrap of samples, a number of one feature to consider when\nlooking for the best split, a minimum number of 16 samples required\nto be at a leaf, and a minimum number of 17 samples required to split\nan internal node.\nSubsequently, an independent stacked ensemble model, with the\nvalues of the parameters described above, was trained with each of\nthe five data sets. Table 8 shows the results obtained by the ensemble\nmodel in the evaluation metrics.\nThe results in Table 8 show that the behaviour of rainfall in Swindon\nwas more difficult to learn than in the rest of the cities. Moreover, the\nCardiff dataset achieved the best performance in the evaluation metrics.\n17\n", []], "LSTM and Stacked-LSTM models from the literature": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nperform a multiple output forecast with a single input. Suppose \ud835\udc4bis\nan input dataset with \ud835\udc5c1, \ud835\udc5c2, \u2026 , \ud835\udc5c\ud835\udc5bobservations where \ud835\udc5c\ud835\udc56is a record of\n\ud835\udc651, \ud835\udc652, \u2026 , \ud835\udc65\ud835\udc5afeatures registered in a time \ud835\udc61(\ud835\udc61= 1, 2, \u2026 , \ud835\udc57). Thus, \ud835\udc4b(\ud835\udc5c\ud835\udc56)(\ud835\udc61\ud835\udc57)\nwill be used to predict the volume of rainfall \ud835\udc53\ud835\udc58in \ud835\udc61\ud835\udc57+8.\nModels based on LSTM architectures can perform a multiple-output\nforecast for each entry point in an straightforward manner. On the other\nhand, the current implementation of XGBoost, as well as most AutoML\ntools, do not incorporate this capability in a direct way. Consequently,\neven though the LSTM-based prediction models will be built with\na multiple-output forecast strategy and the rest of the models with\na single-output forecast strategy, the comparisons of the predictions\nof the models will be made under the single-input single-output ba-\nsis. That is, \ud835\udc4b(\ud835\udc53\ud835\udc56)(\ud835\udc61\ud835\udc57)\ud835\udc5b\n\ud835\udc57=0 will be compared with \ud835\udc4b(\ud835\udc5c\ud835\udc56)(\ud835\udc65\ud835\udc5a)(\ud835\udc61\ud835\udc57)\ud835\udc5b\n\ud835\udc57=0. The\nmethodology used in the experimentation process is illustrated in Fig. 4.\nExperiments were performed in a MacBook Pro with a 2.9 GHz\nIntel Core i9 processor, and 32 GB DDR4 RAM. The prediction models\nwere implemented using Python (van Rossum, 1995) 3.6.10, Ten-\nsorflow (Abadi et al., 2015) 2.0, Keras (Charles, 2013) 2.2.4, Scikit\nLearn (Pedregosa et al., 2011) library version 0.22.1, TPOT (Le, Fu\net al., 2020) tool version 0.11.2, and XGBoost (Chen & Guestrin, 2016)\nlibrary version 0.90.\n5.2. Structure of datasets for rainfall forecasting\nIn order to train the rainfall prediction models, the steps described\nin Section 4.1 were carried out in each of the five weather datasets.\nThe result of the pre-processing procedure delivers a \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc65\ud835\udc5a)(\ud835\udc5a=\n1, 2, \u2026 , 11). Table 2 shows the features comprehended in each of the\nfive datasets.\nFrom Table 2 it can be noticed that feature 11, \u2018\u2018Rain 1h\u2019\u2019\n(\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc5a11)), is the actual volume of rain observed in a previous hour.\nThat is, for each record (row) in the dataset, the weather conditions\nassociated with the actual amount of rainfall are out of phase. There-\nfore, to train the rainfall prediction models, a vector containing the\nshifted value of \u2018\u2018Rain 1h\u2019\u2019 was computed. This results in \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc65\ud835\udc5a)(\ud835\udc5a=\n1, 2, \u2026 , 12) where \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc6512) is the actual value of rainfall amount for\nthat \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57). The shifted feature (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc6512)) is used only as the target\nfeature to predict by the models; that is, it is not used as a learnable\npredictor. Table 3 shows the structure of the weather dataset vectors\nused in the training process of the rainfall prediction models.\nFig. 5 shows the volume of rainfall recorded each hour in the period\nfrom 2000 to 2020 for each of the five datasets processed. In the Figure,\nthe horizontal red lines denote the average value of rainfall throughout\nthe period.\n5.3. Preparation for building the training, validation, and testing sets\nEach of the five datasets built in Section 5.2 is used to train and test\nindependent models for the task of predicting rainfall. This approach\nwill allow each model to learn the singularities of each city.\nIn the rainfall forecasting field, there is no established heuristic\nto divide the dataset into training, validation, and testing subsets.\nNotwithstanding, the historical weather datasets for the five major\nUK cities were built under the nature of time-series data for regres-\nsion problems. Consequently, the weather data was sorted in ascend-\ning order. That is, \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc5a\n\ud835\udc57=0 where \ud835\udc610 = 00:00:00 January-01-2000\nand \ud835\udc61\ud835\udc5a\n= 23:00:00 December-31-2020. Maintaining this order, the\ndatasets were divided into training (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc5b\ud835\udc54\ud835\udc49\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\n\ud835\udc57=0\n), validation\n(\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc63\ud835\udc4e\ud835\udc59\ud835\udc56\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc49\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\n\ud835\udc57=0\n), and test (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61\ud835\udc56\ud835\udc5b\ud835\udc54\ud835\udc49\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\n\ud835\udc57=0\n) sets. It is notewor-\nthy to mention, that data shuffle approaches were not carried out\nduring the partitioning of the datasets and during the training process\nof the rainfall prediction models.\nThe percentages used to build the training and test sets for the\nXGBoost and AutoML models were 85% and 15%, respectively. Due to\nthe experimental methodology involves testing the LSTM and Stacked-\nLSTM approaches from the literature reviewed, the percentages used to\nconstruct the corresponding sets for the LSTM-Networks based models\nare specified in Subsection 2 5.6.\n5.4. XGBoost model\nThe XGBoost regression model was selected as the baseline for this\ncomparison. An individual model was built for each of the five datasets.\nThe models were developed using the Python library provided in Chen\nand Guestrin (2016).\nIn this research study, a non-exhaustive hyperparameter grid search\nwas implemented for each dataset with the aim of minimising the RMSE\nvalues. The hyperparameters and their contemplated search ranges\nwere: an early stop of 20 iterations, a search for the best number of\nestimators, a subsample ratio of features and subsample ratio of the\ntraining instances within 0.5 to 1.0, values between six to 13 for the\nminimum sum of instance weight in a child and in the maximum depth\nof a tree, and Learning Rate values of 0.3, 0.1, 0.05, 0.01, and 0.007.\nAfter the non-exhaustive hyperparameter search, the best values ob-\ntained for each dataset were used to train the corresponding individual\nXGBoost regression model. The default values of gamma, alpha, and\nlambda were used in all the models.\n5.5. Automated machine learning\nThe TPOT tool (Le, Fu et al., 2020) was used to perform the AutoML\nexperiment. The default TPOT configuration for regression problems\nwas used in conjunction with the default values of generations and\npopulation size of 100.\nThe TPOT tool tests various regression models and techniques that\nfollow the scikit-learn API. Moreover, it performs a search over the\nhyperparameters of these models and techniques. Therefore, experi-\nmenting with each of the five datasets would be time-consuming and\ncomputationally expensive. For this reason, due to time and computa-\ntional resource constraints, the Bristol dataset was used to carry out\nthe AutoML experiment with this tool. As a result, the TPOT tool\nwill deliver a regression model with the corresponding hyperparameter\nvalues that achieved the best performance for the rainfall forecast task.\nSubsequently, the resulting model and the hyperparameter values\nwere used to train an independent model for each of the five datasets.\nNo hyperparameter search was carried out for this model.\n5.6. LSTM and Stacked-LSTM models from the literature\nThree models from the literature reviewed in Section 2 were\nadapted and implemented using TensorFlow (Abadi et al., 2015) and\nKeras (Charles, 2013).\nThe first adapted model (Model 1) is a Staked-LSTM Network intro-\nduced in Kim and Bae (2017). The second (Model 2) and third (Model\n3) adapted models are based on LSTM-Networks presented in Kumar\net al. (2019) and Aswin et al. (2018), respectively. All three models\npresent a fully connected layer structure. The general architecture of\nthe implemented Neural Networks is shown in Fig. 6, where \ud835\udc65\ud835\udc56is a\npredictor in the feature vector of the dataset \ud835\udc4b(Table 3), \u210e\ud835\udc5a\n\ud835\udc5bis a neuron\n\ud835\udc5bin a hidden layer \ud835\udc5a, and \ud835\udc53\ud835\udc5cis the output value.\nAll the LSTM-Networks and Stacked-LSTM Networks models imple-\nmented in this study have an input layer with 11 input neurons that cor-\nrespond to the 11 weather features used as predictors (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc65\ud835\udc5a)11\n\ud835\udc5a=1),\nand an output layer with one neuron corresponding to the forecasted\nrainfall value (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc6512)). The specific number of hidden layers, hidden\nneurons, and the rest of the parameters and hyperparameters values\nused for Model 1, Model 2, and Model 3 are the same as described\nin Kim and Bae (2017), Kumar et al. (2019) and Aswin et al. (2018),\nrespectively. The values of the hyperparameters not described in their\noriginal articles were proposed following common heuristics in the field\nof Deep Learning.\nA non-exhaustive hyperparameter grid search was performed inde-\npendently for each of the five datasets and for each of the three adapted\nmodels. The non-exhaustive hyperparameter grid search focused on\nfinding the best values for the optimiser and the Learning Rate. The\n16\n", []], "Automated machine learning": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nperform a multiple output forecast with a single input. Suppose \ud835\udc4bis\nan input dataset with \ud835\udc5c1, \ud835\udc5c2, \u2026 , \ud835\udc5c\ud835\udc5bobservations where \ud835\udc5c\ud835\udc56is a record of\n\ud835\udc651, \ud835\udc652, \u2026 , \ud835\udc65\ud835\udc5afeatures registered in a time \ud835\udc61(\ud835\udc61= 1, 2, \u2026 , \ud835\udc57). Thus, \ud835\udc4b(\ud835\udc5c\ud835\udc56)(\ud835\udc61\ud835\udc57)\nwill be used to predict the volume of rainfall \ud835\udc53\ud835\udc58in \ud835\udc61\ud835\udc57+8.\nModels based on LSTM architectures can perform a multiple-output\nforecast for each entry point in an straightforward manner. On the other\nhand, the current implementation of XGBoost, as well as most AutoML\ntools, do not incorporate this capability in a direct way. Consequently,\neven though the LSTM-based prediction models will be built with\na multiple-output forecast strategy and the rest of the models with\na single-output forecast strategy, the comparisons of the predictions\nof the models will be made under the single-input single-output ba-\nsis. That is, \ud835\udc4b(\ud835\udc53\ud835\udc56)(\ud835\udc61\ud835\udc57)\ud835\udc5b\n\ud835\udc57=0 will be compared with \ud835\udc4b(\ud835\udc5c\ud835\udc56)(\ud835\udc65\ud835\udc5a)(\ud835\udc61\ud835\udc57)\ud835\udc5b\n\ud835\udc57=0. The\nmethodology used in the experimentation process is illustrated in Fig. 4.\nExperiments were performed in a MacBook Pro with a 2.9 GHz\nIntel Core i9 processor, and 32 GB DDR4 RAM. The prediction models\nwere implemented using Python (van Rossum, 1995) 3.6.10, Ten-\nsorflow (Abadi et al., 2015) 2.0, Keras (Charles, 2013) 2.2.4, Scikit\nLearn (Pedregosa et al., 2011) library version 0.22.1, TPOT (Le, Fu\net al., 2020) tool version 0.11.2, and XGBoost (Chen & Guestrin, 2016)\nlibrary version 0.90.\n5.2. Structure of datasets for rainfall forecasting\nIn order to train the rainfall prediction models, the steps described\nin Section 4.1 were carried out in each of the five weather datasets.\nThe result of the pre-processing procedure delivers a \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc65\ud835\udc5a)(\ud835\udc5a=\n1, 2, \u2026 , 11). Table 2 shows the features comprehended in each of the\nfive datasets.\nFrom Table 2 it can be noticed that feature 11, \u2018\u2018Rain 1h\u2019\u2019\n(\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc5a11)), is the actual volume of rain observed in a previous hour.\nThat is, for each record (row) in the dataset, the weather conditions\nassociated with the actual amount of rainfall are out of phase. There-\nfore, to train the rainfall prediction models, a vector containing the\nshifted value of \u2018\u2018Rain 1h\u2019\u2019 was computed. This results in \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc65\ud835\udc5a)(\ud835\udc5a=\n1, 2, \u2026 , 12) where \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc6512) is the actual value of rainfall amount for\nthat \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57). The shifted feature (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc6512)) is used only as the target\nfeature to predict by the models; that is, it is not used as a learnable\npredictor. Table 3 shows the structure of the weather dataset vectors\nused in the training process of the rainfall prediction models.\nFig. 5 shows the volume of rainfall recorded each hour in the period\nfrom 2000 to 2020 for each of the five datasets processed. In the Figure,\nthe horizontal red lines denote the average value of rainfall throughout\nthe period.\n5.3. Preparation for building the training, validation, and testing sets\nEach of the five datasets built in Section 5.2 is used to train and test\nindependent models for the task of predicting rainfall. This approach\nwill allow each model to learn the singularities of each city.\nIn the rainfall forecasting field, there is no established heuristic\nto divide the dataset into training, validation, and testing subsets.\nNotwithstanding, the historical weather datasets for the five major\nUK cities were built under the nature of time-series data for regres-\nsion problems. Consequently, the weather data was sorted in ascend-\ning order. That is, \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc5a\n\ud835\udc57=0 where \ud835\udc610 = 00:00:00 January-01-2000\nand \ud835\udc61\ud835\udc5a\n= 23:00:00 December-31-2020. Maintaining this order, the\ndatasets were divided into training (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc5b\ud835\udc54\ud835\udc49\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\n\ud835\udc57=0\n), validation\n(\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc63\ud835\udc4e\ud835\udc59\ud835\udc56\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc49\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\n\ud835\udc57=0\n), and test (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61\ud835\udc56\ud835\udc5b\ud835\udc54\ud835\udc49\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\n\ud835\udc57=0\n) sets. It is notewor-\nthy to mention, that data shuffle approaches were not carried out\nduring the partitioning of the datasets and during the training process\nof the rainfall prediction models.\nThe percentages used to build the training and test sets for the\nXGBoost and AutoML models were 85% and 15%, respectively. Due to\nthe experimental methodology involves testing the LSTM and Stacked-\nLSTM approaches from the literature reviewed, the percentages used to\nconstruct the corresponding sets for the LSTM-Networks based models\nare specified in Subsection 2 5.6.\n5.4. XGBoost model\nThe XGBoost regression model was selected as the baseline for this\ncomparison. An individual model was built for each of the five datasets.\nThe models were developed using the Python library provided in Chen\nand Guestrin (2016).\nIn this research study, a non-exhaustive hyperparameter grid search\nwas implemented for each dataset with the aim of minimising the RMSE\nvalues. The hyperparameters and their contemplated search ranges\nwere: an early stop of 20 iterations, a search for the best number of\nestimators, a subsample ratio of features and subsample ratio of the\ntraining instances within 0.5 to 1.0, values between six to 13 for the\nminimum sum of instance weight in a child and in the maximum depth\nof a tree, and Learning Rate values of 0.3, 0.1, 0.05, 0.01, and 0.007.\nAfter the non-exhaustive hyperparameter search, the best values ob-\ntained for each dataset were used to train the corresponding individual\nXGBoost regression model. The default values of gamma, alpha, and\nlambda were used in all the models.\n5.5. Automated machine learning\nThe TPOT tool (Le, Fu et al., 2020) was used to perform the AutoML\nexperiment. The default TPOT configuration for regression problems\nwas used in conjunction with the default values of generations and\npopulation size of 100.\nThe TPOT tool tests various regression models and techniques that\nfollow the scikit-learn API. Moreover, it performs a search over the\nhyperparameters of these models and techniques. Therefore, experi-\nmenting with each of the five datasets would be time-consuming and\ncomputationally expensive. For this reason, due to time and computa-\ntional resource constraints, the Bristol dataset was used to carry out\nthe AutoML experiment with this tool. As a result, the TPOT tool\nwill deliver a regression model with the corresponding hyperparameter\nvalues that achieved the best performance for the rainfall forecast task.\nSubsequently, the resulting model and the hyperparameter values\nwere used to train an independent model for each of the five datasets.\nNo hyperparameter search was carried out for this model.\n5.6. LSTM and Stacked-LSTM models from the literature\nThree models from the literature reviewed in Section 2 were\nadapted and implemented using TensorFlow (Abadi et al., 2015) and\nKeras (Charles, 2013).\nThe first adapted model (Model 1) is a Staked-LSTM Network intro-\nduced in Kim and Bae (2017). The second (Model 2) and third (Model\n3) adapted models are based on LSTM-Networks presented in Kumar\net al. (2019) and Aswin et al. (2018), respectively. All three models\npresent a fully connected layer structure. The general architecture of\nthe implemented Neural Networks is shown in Fig. 6, where \ud835\udc65\ud835\udc56is a\npredictor in the feature vector of the dataset \ud835\udc4b(Table 3), \u210e\ud835\udc5a\n\ud835\udc5bis a neuron\n\ud835\udc5bin a hidden layer \ud835\udc5a, and \ud835\udc53\ud835\udc5cis the output value.\nAll the LSTM-Networks and Stacked-LSTM Networks models imple-\nmented in this study have an input layer with 11 input neurons that cor-\nrespond to the 11 weather features used as predictors (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc65\ud835\udc5a)11\n\ud835\udc5a=1),\nand an output layer with one neuron corresponding to the forecasted\nrainfall value (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc6512)). The specific number of hidden layers, hidden\nneurons, and the rest of the parameters and hyperparameters values\nused for Model 1, Model 2, and Model 3 are the same as described\nin Kim and Bae (2017), Kumar et al. (2019) and Aswin et al. (2018),\nrespectively. The values of the hyperparameters not described in their\noriginal articles were proposed following common heuristics in the field\nof Deep Learning.\nA non-exhaustive hyperparameter grid search was performed inde-\npendently for each of the five datasets and for each of the three adapted\nmodels. The non-exhaustive hyperparameter grid search focused on\nfinding the best values for the optimiser and the Learning Rate. The\n16\n", []], "XGBoost model": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nperform a multiple output forecast with a single input. Suppose \ud835\udc4bis\nan input dataset with \ud835\udc5c1, \ud835\udc5c2, \u2026 , \ud835\udc5c\ud835\udc5bobservations where \ud835\udc5c\ud835\udc56is a record of\n\ud835\udc651, \ud835\udc652, \u2026 , \ud835\udc65\ud835\udc5afeatures registered in a time \ud835\udc61(\ud835\udc61= 1, 2, \u2026 , \ud835\udc57). Thus, \ud835\udc4b(\ud835\udc5c\ud835\udc56)(\ud835\udc61\ud835\udc57)\nwill be used to predict the volume of rainfall \ud835\udc53\ud835\udc58in \ud835\udc61\ud835\udc57+8.\nModels based on LSTM architectures can perform a multiple-output\nforecast for each entry point in an straightforward manner. On the other\nhand, the current implementation of XGBoost, as well as most AutoML\ntools, do not incorporate this capability in a direct way. Consequently,\neven though the LSTM-based prediction models will be built with\na multiple-output forecast strategy and the rest of the models with\na single-output forecast strategy, the comparisons of the predictions\nof the models will be made under the single-input single-output ba-\nsis. That is, \ud835\udc4b(\ud835\udc53\ud835\udc56)(\ud835\udc61\ud835\udc57)\ud835\udc5b\n\ud835\udc57=0 will be compared with \ud835\udc4b(\ud835\udc5c\ud835\udc56)(\ud835\udc65\ud835\udc5a)(\ud835\udc61\ud835\udc57)\ud835\udc5b\n\ud835\udc57=0. The\nmethodology used in the experimentation process is illustrated in Fig. 4.\nExperiments were performed in a MacBook Pro with a 2.9 GHz\nIntel Core i9 processor, and 32 GB DDR4 RAM. The prediction models\nwere implemented using Python (van Rossum, 1995) 3.6.10, Ten-\nsorflow (Abadi et al., 2015) 2.0, Keras (Charles, 2013) 2.2.4, Scikit\nLearn (Pedregosa et al., 2011) library version 0.22.1, TPOT (Le, Fu\net al., 2020) tool version 0.11.2, and XGBoost (Chen & Guestrin, 2016)\nlibrary version 0.90.\n5.2. Structure of datasets for rainfall forecasting\nIn order to train the rainfall prediction models, the steps described\nin Section 4.1 were carried out in each of the five weather datasets.\nThe result of the pre-processing procedure delivers a \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc65\ud835\udc5a)(\ud835\udc5a=\n1, 2, \u2026 , 11). Table 2 shows the features comprehended in each of the\nfive datasets.\nFrom Table 2 it can be noticed that feature 11, \u2018\u2018Rain 1h\u2019\u2019\n(\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc5a11)), is the actual volume of rain observed in a previous hour.\nThat is, for each record (row) in the dataset, the weather conditions\nassociated with the actual amount of rainfall are out of phase. There-\nfore, to train the rainfall prediction models, a vector containing the\nshifted value of \u2018\u2018Rain 1h\u2019\u2019 was computed. This results in \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc65\ud835\udc5a)(\ud835\udc5a=\n1, 2, \u2026 , 12) where \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc6512) is the actual value of rainfall amount for\nthat \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57). The shifted feature (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc6512)) is used only as the target\nfeature to predict by the models; that is, it is not used as a learnable\npredictor. Table 3 shows the structure of the weather dataset vectors\nused in the training process of the rainfall prediction models.\nFig. 5 shows the volume of rainfall recorded each hour in the period\nfrom 2000 to 2020 for each of the five datasets processed. In the Figure,\nthe horizontal red lines denote the average value of rainfall throughout\nthe period.\n5.3. Preparation for building the training, validation, and testing sets\nEach of the five datasets built in Section 5.2 is used to train and test\nindependent models for the task of predicting rainfall. This approach\nwill allow each model to learn the singularities of each city.\nIn the rainfall forecasting field, there is no established heuristic\nto divide the dataset into training, validation, and testing subsets.\nNotwithstanding, the historical weather datasets for the five major\nUK cities were built under the nature of time-series data for regres-\nsion problems. Consequently, the weather data was sorted in ascend-\ning order. That is, \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc5a\n\ud835\udc57=0 where \ud835\udc610 = 00:00:00 January-01-2000\nand \ud835\udc61\ud835\udc5a\n= 23:00:00 December-31-2020. Maintaining this order, the\ndatasets were divided into training (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc5b\ud835\udc54\ud835\udc49\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\n\ud835\udc57=0\n), validation\n(\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc63\ud835\udc4e\ud835\udc59\ud835\udc56\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc49\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\n\ud835\udc57=0\n), and test (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61\ud835\udc56\ud835\udc5b\ud835\udc54\ud835\udc49\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\n\ud835\udc57=0\n) sets. It is notewor-\nthy to mention, that data shuffle approaches were not carried out\nduring the partitioning of the datasets and during the training process\nof the rainfall prediction models.\nThe percentages used to build the training and test sets for the\nXGBoost and AutoML models were 85% and 15%, respectively. Due to\nthe experimental methodology involves testing the LSTM and Stacked-\nLSTM approaches from the literature reviewed, the percentages used to\nconstruct the corresponding sets for the LSTM-Networks based models\nare specified in Subsection 2 5.6.\n5.4. XGBoost model\nThe XGBoost regression model was selected as the baseline for this\ncomparison. An individual model was built for each of the five datasets.\nThe models were developed using the Python library provided in Chen\nand Guestrin (2016).\nIn this research study, a non-exhaustive hyperparameter grid search\nwas implemented for each dataset with the aim of minimising the RMSE\nvalues. The hyperparameters and their contemplated search ranges\nwere: an early stop of 20 iterations, a search for the best number of\nestimators, a subsample ratio of features and subsample ratio of the\ntraining instances within 0.5 to 1.0, values between six to 13 for the\nminimum sum of instance weight in a child and in the maximum depth\nof a tree, and Learning Rate values of 0.3, 0.1, 0.05, 0.01, and 0.007.\nAfter the non-exhaustive hyperparameter search, the best values ob-\ntained for each dataset were used to train the corresponding individual\nXGBoost regression model. The default values of gamma, alpha, and\nlambda were used in all the models.\n5.5. Automated machine learning\nThe TPOT tool (Le, Fu et al., 2020) was used to perform the AutoML\nexperiment. The default TPOT configuration for regression problems\nwas used in conjunction with the default values of generations and\npopulation size of 100.\nThe TPOT tool tests various regression models and techniques that\nfollow the scikit-learn API. Moreover, it performs a search over the\nhyperparameters of these models and techniques. Therefore, experi-\nmenting with each of the five datasets would be time-consuming and\ncomputationally expensive. For this reason, due to time and computa-\ntional resource constraints, the Bristol dataset was used to carry out\nthe AutoML experiment with this tool. As a result, the TPOT tool\nwill deliver a regression model with the corresponding hyperparameter\nvalues that achieved the best performance for the rainfall forecast task.\nSubsequently, the resulting model and the hyperparameter values\nwere used to train an independent model for each of the five datasets.\nNo hyperparameter search was carried out for this model.\n5.6. LSTM and Stacked-LSTM models from the literature\nThree models from the literature reviewed in Section 2 were\nadapted and implemented using TensorFlow (Abadi et al., 2015) and\nKeras (Charles, 2013).\nThe first adapted model (Model 1) is a Staked-LSTM Network intro-\nduced in Kim and Bae (2017). The second (Model 2) and third (Model\n3) adapted models are based on LSTM-Networks presented in Kumar\net al. (2019) and Aswin et al. (2018), respectively. All three models\npresent a fully connected layer structure. The general architecture of\nthe implemented Neural Networks is shown in Fig. 6, where \ud835\udc65\ud835\udc56is a\npredictor in the feature vector of the dataset \ud835\udc4b(Table 3), \u210e\ud835\udc5a\n\ud835\udc5bis a neuron\n\ud835\udc5bin a hidden layer \ud835\udc5a, and \ud835\udc53\ud835\udc5cis the output value.\nAll the LSTM-Networks and Stacked-LSTM Networks models imple-\nmented in this study have an input layer with 11 input neurons that cor-\nrespond to the 11 weather features used as predictors (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc65\ud835\udc5a)11\n\ud835\udc5a=1),\nand an output layer with one neuron corresponding to the forecasted\nrainfall value (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc6512)). The specific number of hidden layers, hidden\nneurons, and the rest of the parameters and hyperparameters values\nused for Model 1, Model 2, and Model 3 are the same as described\nin Kim and Bae (2017), Kumar et al. (2019) and Aswin et al. (2018),\nrespectively. The values of the hyperparameters not described in their\noriginal articles were proposed following common heuristics in the field\nof Deep Learning.\nA non-exhaustive hyperparameter grid search was performed inde-\npendently for each of the five datasets and for each of the three adapted\nmodels. The non-exhaustive hyperparameter grid search focused on\nfinding the best values for the optimiser and the Learning Rate. The\n16\n", []], "Preparation for building the training, validation, and testing sets": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nperform a multiple output forecast with a single input. Suppose \ud835\udc4bis\nan input dataset with \ud835\udc5c1, \ud835\udc5c2, \u2026 , \ud835\udc5c\ud835\udc5bobservations where \ud835\udc5c\ud835\udc56is a record of\n\ud835\udc651, \ud835\udc652, \u2026 , \ud835\udc65\ud835\udc5afeatures registered in a time \ud835\udc61(\ud835\udc61= 1, 2, \u2026 , \ud835\udc57). Thus, \ud835\udc4b(\ud835\udc5c\ud835\udc56)(\ud835\udc61\ud835\udc57)\nwill be used to predict the volume of rainfall \ud835\udc53\ud835\udc58in \ud835\udc61\ud835\udc57+8.\nModels based on LSTM architectures can perform a multiple-output\nforecast for each entry point in an straightforward manner. On the other\nhand, the current implementation of XGBoost, as well as most AutoML\ntools, do not incorporate this capability in a direct way. Consequently,\neven though the LSTM-based prediction models will be built with\na multiple-output forecast strategy and the rest of the models with\na single-output forecast strategy, the comparisons of the predictions\nof the models will be made under the single-input single-output ba-\nsis. That is, \ud835\udc4b(\ud835\udc53\ud835\udc56)(\ud835\udc61\ud835\udc57)\ud835\udc5b\n\ud835\udc57=0 will be compared with \ud835\udc4b(\ud835\udc5c\ud835\udc56)(\ud835\udc65\ud835\udc5a)(\ud835\udc61\ud835\udc57)\ud835\udc5b\n\ud835\udc57=0. The\nmethodology used in the experimentation process is illustrated in Fig. 4.\nExperiments were performed in a MacBook Pro with a 2.9 GHz\nIntel Core i9 processor, and 32 GB DDR4 RAM. The prediction models\nwere implemented using Python (van Rossum, 1995) 3.6.10, Ten-\nsorflow (Abadi et al., 2015) 2.0, Keras (Charles, 2013) 2.2.4, Scikit\nLearn (Pedregosa et al., 2011) library version 0.22.1, TPOT (Le, Fu\net al., 2020) tool version 0.11.2, and XGBoost (Chen & Guestrin, 2016)\nlibrary version 0.90.\n5.2. Structure of datasets for rainfall forecasting\nIn order to train the rainfall prediction models, the steps described\nin Section 4.1 were carried out in each of the five weather datasets.\nThe result of the pre-processing procedure delivers a \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc65\ud835\udc5a)(\ud835\udc5a=\n1, 2, \u2026 , 11). Table 2 shows the features comprehended in each of the\nfive datasets.\nFrom Table 2 it can be noticed that feature 11, \u2018\u2018Rain 1h\u2019\u2019\n(\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc5a11)), is the actual volume of rain observed in a previous hour.\nThat is, for each record (row) in the dataset, the weather conditions\nassociated with the actual amount of rainfall are out of phase. There-\nfore, to train the rainfall prediction models, a vector containing the\nshifted value of \u2018\u2018Rain 1h\u2019\u2019 was computed. This results in \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc65\ud835\udc5a)(\ud835\udc5a=\n1, 2, \u2026 , 12) where \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc6512) is the actual value of rainfall amount for\nthat \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57). The shifted feature (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc6512)) is used only as the target\nfeature to predict by the models; that is, it is not used as a learnable\npredictor. Table 3 shows the structure of the weather dataset vectors\nused in the training process of the rainfall prediction models.\nFig. 5 shows the volume of rainfall recorded each hour in the period\nfrom 2000 to 2020 for each of the five datasets processed. In the Figure,\nthe horizontal red lines denote the average value of rainfall throughout\nthe period.\n5.3. Preparation for building the training, validation, and testing sets\nEach of the five datasets built in Section 5.2 is used to train and test\nindependent models for the task of predicting rainfall. This approach\nwill allow each model to learn the singularities of each city.\nIn the rainfall forecasting field, there is no established heuristic\nto divide the dataset into training, validation, and testing subsets.\nNotwithstanding, the historical weather datasets for the five major\nUK cities were built under the nature of time-series data for regres-\nsion problems. Consequently, the weather data was sorted in ascend-\ning order. That is, \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc5a\n\ud835\udc57=0 where \ud835\udc610 = 00:00:00 January-01-2000\nand \ud835\udc61\ud835\udc5a\n= 23:00:00 December-31-2020. Maintaining this order, the\ndatasets were divided into training (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc5b\ud835\udc54\ud835\udc49\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\n\ud835\udc57=0\n), validation\n(\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc63\ud835\udc4e\ud835\udc59\ud835\udc56\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc49\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\n\ud835\udc57=0\n), and test (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61\ud835\udc56\ud835\udc5b\ud835\udc54\ud835\udc49\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\n\ud835\udc57=0\n) sets. It is notewor-\nthy to mention, that data shuffle approaches were not carried out\nduring the partitioning of the datasets and during the training process\nof the rainfall prediction models.\nThe percentages used to build the training and test sets for the\nXGBoost and AutoML models were 85% and 15%, respectively. Due to\nthe experimental methodology involves testing the LSTM and Stacked-\nLSTM approaches from the literature reviewed, the percentages used to\nconstruct the corresponding sets for the LSTM-Networks based models\nare specified in Subsection 2 5.6.\n5.4. XGBoost model\nThe XGBoost regression model was selected as the baseline for this\ncomparison. An individual model was built for each of the five datasets.\nThe models were developed using the Python library provided in Chen\nand Guestrin (2016).\nIn this research study, a non-exhaustive hyperparameter grid search\nwas implemented for each dataset with the aim of minimising the RMSE\nvalues. The hyperparameters and their contemplated search ranges\nwere: an early stop of 20 iterations, a search for the best number of\nestimators, a subsample ratio of features and subsample ratio of the\ntraining instances within 0.5 to 1.0, values between six to 13 for the\nminimum sum of instance weight in a child and in the maximum depth\nof a tree, and Learning Rate values of 0.3, 0.1, 0.05, 0.01, and 0.007.\nAfter the non-exhaustive hyperparameter search, the best values ob-\ntained for each dataset were used to train the corresponding individual\nXGBoost regression model. The default values of gamma, alpha, and\nlambda were used in all the models.\n5.5. Automated machine learning\nThe TPOT tool (Le, Fu et al., 2020) was used to perform the AutoML\nexperiment. The default TPOT configuration for regression problems\nwas used in conjunction with the default values of generations and\npopulation size of 100.\nThe TPOT tool tests various regression models and techniques that\nfollow the scikit-learn API. Moreover, it performs a search over the\nhyperparameters of these models and techniques. Therefore, experi-\nmenting with each of the five datasets would be time-consuming and\ncomputationally expensive. For this reason, due to time and computa-\ntional resource constraints, the Bristol dataset was used to carry out\nthe AutoML experiment with this tool. As a result, the TPOT tool\nwill deliver a regression model with the corresponding hyperparameter\nvalues that achieved the best performance for the rainfall forecast task.\nSubsequently, the resulting model and the hyperparameter values\nwere used to train an independent model for each of the five datasets.\nNo hyperparameter search was carried out for this model.\n5.6. LSTM and Stacked-LSTM models from the literature\nThree models from the literature reviewed in Section 2 were\nadapted and implemented using TensorFlow (Abadi et al., 2015) and\nKeras (Charles, 2013).\nThe first adapted model (Model 1) is a Staked-LSTM Network intro-\nduced in Kim and Bae (2017). The second (Model 2) and third (Model\n3) adapted models are based on LSTM-Networks presented in Kumar\net al. (2019) and Aswin et al. (2018), respectively. All three models\npresent a fully connected layer structure. The general architecture of\nthe implemented Neural Networks is shown in Fig. 6, where \ud835\udc65\ud835\udc56is a\npredictor in the feature vector of the dataset \ud835\udc4b(Table 3), \u210e\ud835\udc5a\n\ud835\udc5bis a neuron\n\ud835\udc5bin a hidden layer \ud835\udc5a, and \ud835\udc53\ud835\udc5cis the output value.\nAll the LSTM-Networks and Stacked-LSTM Networks models imple-\nmented in this study have an input layer with 11 input neurons that cor-\nrespond to the 11 weather features used as predictors (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc65\ud835\udc5a)11\n\ud835\udc5a=1),\nand an output layer with one neuron corresponding to the forecasted\nrainfall value (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc6512)). The specific number of hidden layers, hidden\nneurons, and the rest of the parameters and hyperparameters values\nused for Model 1, Model 2, and Model 3 are the same as described\nin Kim and Bae (2017), Kumar et al. (2019) and Aswin et al. (2018),\nrespectively. The values of the hyperparameters not described in their\noriginal articles were proposed following common heuristics in the field\nof Deep Learning.\nA non-exhaustive hyperparameter grid search was performed inde-\npendently for each of the five datasets and for each of the three adapted\nmodels. The non-exhaustive hyperparameter grid search focused on\nfinding the best values for the optimiser and the Learning Rate. The\n16\n", []], "Structure of datasets for rainfall forecasting": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nperform a multiple output forecast with a single input. Suppose \ud835\udc4bis\nan input dataset with \ud835\udc5c1, \ud835\udc5c2, \u2026 , \ud835\udc5c\ud835\udc5bobservations where \ud835\udc5c\ud835\udc56is a record of\n\ud835\udc651, \ud835\udc652, \u2026 , \ud835\udc65\ud835\udc5afeatures registered in a time \ud835\udc61(\ud835\udc61= 1, 2, \u2026 , \ud835\udc57). Thus, \ud835\udc4b(\ud835\udc5c\ud835\udc56)(\ud835\udc61\ud835\udc57)\nwill be used to predict the volume of rainfall \ud835\udc53\ud835\udc58in \ud835\udc61\ud835\udc57+8.\nModels based on LSTM architectures can perform a multiple-output\nforecast for each entry point in an straightforward manner. On the other\nhand, the current implementation of XGBoost, as well as most AutoML\ntools, do not incorporate this capability in a direct way. Consequently,\neven though the LSTM-based prediction models will be built with\na multiple-output forecast strategy and the rest of the models with\na single-output forecast strategy, the comparisons of the predictions\nof the models will be made under the single-input single-output ba-\nsis. That is, \ud835\udc4b(\ud835\udc53\ud835\udc56)(\ud835\udc61\ud835\udc57)\ud835\udc5b\n\ud835\udc57=0 will be compared with \ud835\udc4b(\ud835\udc5c\ud835\udc56)(\ud835\udc65\ud835\udc5a)(\ud835\udc61\ud835\udc57)\ud835\udc5b\n\ud835\udc57=0. The\nmethodology used in the experimentation process is illustrated in Fig. 4.\nExperiments were performed in a MacBook Pro with a 2.9 GHz\nIntel Core i9 processor, and 32 GB DDR4 RAM. The prediction models\nwere implemented using Python (van Rossum, 1995) 3.6.10, Ten-\nsorflow (Abadi et al., 2015) 2.0, Keras (Charles, 2013) 2.2.4, Scikit\nLearn (Pedregosa et al., 2011) library version 0.22.1, TPOT (Le, Fu\net al., 2020) tool version 0.11.2, and XGBoost (Chen & Guestrin, 2016)\nlibrary version 0.90.\n5.2. Structure of datasets for rainfall forecasting\nIn order to train the rainfall prediction models, the steps described\nin Section 4.1 were carried out in each of the five weather datasets.\nThe result of the pre-processing procedure delivers a \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc65\ud835\udc5a)(\ud835\udc5a=\n1, 2, \u2026 , 11). Table 2 shows the features comprehended in each of the\nfive datasets.\nFrom Table 2 it can be noticed that feature 11, \u2018\u2018Rain 1h\u2019\u2019\n(\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc5a11)), is the actual volume of rain observed in a previous hour.\nThat is, for each record (row) in the dataset, the weather conditions\nassociated with the actual amount of rainfall are out of phase. There-\nfore, to train the rainfall prediction models, a vector containing the\nshifted value of \u2018\u2018Rain 1h\u2019\u2019 was computed. This results in \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc65\ud835\udc5a)(\ud835\udc5a=\n1, 2, \u2026 , 12) where \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc6512) is the actual value of rainfall amount for\nthat \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57). The shifted feature (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc6512)) is used only as the target\nfeature to predict by the models; that is, it is not used as a learnable\npredictor. Table 3 shows the structure of the weather dataset vectors\nused in the training process of the rainfall prediction models.\nFig. 5 shows the volume of rainfall recorded each hour in the period\nfrom 2000 to 2020 for each of the five datasets processed. In the Figure,\nthe horizontal red lines denote the average value of rainfall throughout\nthe period.\n5.3. Preparation for building the training, validation, and testing sets\nEach of the five datasets built in Section 5.2 is used to train and test\nindependent models for the task of predicting rainfall. This approach\nwill allow each model to learn the singularities of each city.\nIn the rainfall forecasting field, there is no established heuristic\nto divide the dataset into training, validation, and testing subsets.\nNotwithstanding, the historical weather datasets for the five major\nUK cities were built under the nature of time-series data for regres-\nsion problems. Consequently, the weather data was sorted in ascend-\ning order. That is, \ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc5a\n\ud835\udc57=0 where \ud835\udc610 = 00:00:00 January-01-2000\nand \ud835\udc61\ud835\udc5a\n= 23:00:00 December-31-2020. Maintaining this order, the\ndatasets were divided into training (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc5b\ud835\udc54\ud835\udc49\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\n\ud835\udc57=0\n), validation\n(\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc63\ud835\udc4e\ud835\udc59\ud835\udc56\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b\ud835\udc49\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\n\ud835\udc57=0\n), and test (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc61\ud835\udc57)\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc61\ud835\udc56\ud835\udc5b\ud835\udc54\ud835\udc49\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\n\ud835\udc57=0\n) sets. It is notewor-\nthy to mention, that data shuffle approaches were not carried out\nduring the partitioning of the datasets and during the training process\nof the rainfall prediction models.\nThe percentages used to build the training and test sets for the\nXGBoost and AutoML models were 85% and 15%, respectively. Due to\nthe experimental methodology involves testing the LSTM and Stacked-\nLSTM approaches from the literature reviewed, the percentages used to\nconstruct the corresponding sets for the LSTM-Networks based models\nare specified in Subsection 2 5.6.\n5.4. XGBoost model\nThe XGBoost regression model was selected as the baseline for this\ncomparison. An individual model was built for each of the five datasets.\nThe models were developed using the Python library provided in Chen\nand Guestrin (2016).\nIn this research study, a non-exhaustive hyperparameter grid search\nwas implemented for each dataset with the aim of minimising the RMSE\nvalues. The hyperparameters and their contemplated search ranges\nwere: an early stop of 20 iterations, a search for the best number of\nestimators, a subsample ratio of features and subsample ratio of the\ntraining instances within 0.5 to 1.0, values between six to 13 for the\nminimum sum of instance weight in a child and in the maximum depth\nof a tree, and Learning Rate values of 0.3, 0.1, 0.05, 0.01, and 0.007.\nAfter the non-exhaustive hyperparameter search, the best values ob-\ntained for each dataset were used to train the corresponding individual\nXGBoost regression model. The default values of gamma, alpha, and\nlambda were used in all the models.\n5.5. Automated machine learning\nThe TPOT tool (Le, Fu et al., 2020) was used to perform the AutoML\nexperiment. The default TPOT configuration for regression problems\nwas used in conjunction with the default values of generations and\npopulation size of 100.\nThe TPOT tool tests various regression models and techniques that\nfollow the scikit-learn API. Moreover, it performs a search over the\nhyperparameters of these models and techniques. Therefore, experi-\nmenting with each of the five datasets would be time-consuming and\ncomputationally expensive. For this reason, due to time and computa-\ntional resource constraints, the Bristol dataset was used to carry out\nthe AutoML experiment with this tool. As a result, the TPOT tool\nwill deliver a regression model with the corresponding hyperparameter\nvalues that achieved the best performance for the rainfall forecast task.\nSubsequently, the resulting model and the hyperparameter values\nwere used to train an independent model for each of the five datasets.\nNo hyperparameter search was carried out for this model.\n5.6. LSTM and Stacked-LSTM models from the literature\nThree models from the literature reviewed in Section 2 were\nadapted and implemented using TensorFlow (Abadi et al., 2015) and\nKeras (Charles, 2013).\nThe first adapted model (Model 1) is a Staked-LSTM Network intro-\nduced in Kim and Bae (2017). The second (Model 2) and third (Model\n3) adapted models are based on LSTM-Networks presented in Kumar\net al. (2019) and Aswin et al. (2018), respectively. All three models\npresent a fully connected layer structure. The general architecture of\nthe implemented Neural Networks is shown in Fig. 6, where \ud835\udc65\ud835\udc56is a\npredictor in the feature vector of the dataset \ud835\udc4b(Table 3), \u210e\ud835\udc5a\n\ud835\udc5bis a neuron\n\ud835\udc5bin a hidden layer \ud835\udc5a, and \ud835\udc53\ud835\udc5cis the output value.\nAll the LSTM-Networks and Stacked-LSTM Networks models imple-\nmented in this study have an input layer with 11 input neurons that cor-\nrespond to the 11 weather features used as predictors (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc65\ud835\udc5a)11\n\ud835\udc5a=1),\nand an output layer with one neuron corresponding to the forecasted\nrainfall value (\ud835\udc4b(\ud835\udc5c\ud835\udc5b)(\ud835\udc6512)). The specific number of hidden layers, hidden\nneurons, and the rest of the parameters and hyperparameters values\nused for Model 1, Model 2, and Model 3 are the same as described\nin Kim and Bae (2017), Kumar et al. (2019) and Aswin et al. (2018),\nrespectively. The values of the hyperparameters not described in their\noriginal articles were proposed following common heuristics in the field\nof Deep Learning.\nA non-exhaustive hyperparameter grid search was performed inde-\npendently for each of the five datasets and for each of the three adapted\nmodels. The non-exhaustive hyperparameter grid search focused on\nfinding the best values for the optimiser and the Learning Rate. The\n16\n", []], "Rainfall prediction approach": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nFig. 15. Nullness of features in the cities of Newport and Swindon.\nmain weather feature is Snow 1 h and the Snow ID 601 feature\nrepresents an internal code used by the OpenWeather services.\nConsequently, the feature Snow ID 601 is removed.\nTaking into account the last consideration of removing the feature\nthat represents an internal ID code for the use of OpenWeather services,\nit was decided to remove the rest of the features that contain ID codes\nfrom the five datasets.\nThis study does not consider time and date values as features that\nmodels can learn. The rationale is to avoid restricting the learning\nprocess of the models to possible time hidden patterns. Therefore,\nthe date-time feature was removed from all five datasets. After this\nprocess, the dimensionality of the datasets was downsized from 43 to\n11 features.\nFinally, dataset normalisation is a common approach performed in\nMachine Learning problems when its features have a different range\nof values between them (Kim & Bae, 2017; Shanker, Hu, & Hung,\n1996). Implementing this process could produce better results and\nminimise the time required to train a model (Shanker et al., 1996).\nHence, the MinMaxScaler normalisation function from the Scikit Learn\nlibrary (Pedregosa et al., 2011) was used to re-scale the features of the\nfive datasets in the range between zero and one.\nThe final structure of the datasets that resulted from this preprocess-\ning procedure, and used to train and test the rainfall prediction models,\nare described in Section 5.2.\n5. Methods\nThis section provides a detailed description of the experiments\nperformed to develop and test different rainfall prediction models. This\ndescription includes the structure of the feature vector rows of the\ndatasets, the procedure for building the training, validation and testing\nsubsets of each of the five datasets, the implementation of the non-\nexhaustive hyperparameter search for the rainfall forecasting models\nbased on XGBoost and LSTM-Networks, the fixed values for the rest of\nthe parameters of the models, and the implementation and adaptations\nmade to the tested models.\n5.1. Rainfall prediction approach\nThis\nstudy\nseeks\nto\ninvestigate\nthe\nsuitability\nof\nthree\nLSTM-Networks architectures in the task of predicting 8-hours of rain-\nfall volume using time-series data from five major UK cities. In partic-\nular, this study makes a comparison between forecast models based\non LSTM-Networks, Stacked-LSTM Networks and Bidirectional-LSTM\nNetworks against an XGBoost decision tree algorithm and an algorithm\nresulting from the use of AutoML.\nTherefore, in order to achieve a broad, non-exhaustive, comparison\nthe following experimental procedure was followed:\n1. Build an XGBoost model for each of the five datasets as a\nbaseline. Perform a non-exhaustive hyperparameter grid search\nto obtain the best hyperparameter values to train each model.\n2. Use an AutoML tool to explore the performance of different well-\nknown regression algorithms in the literature. For each of the\nfive datasets, train a model recommended by the AutoML tool.\n3. From the literature review, build two models based on LSTM-\nNetworks and one model based on Stacked-LSTM Networks. For\neach of the five datasets, train an individual version of the\nthree models built. During the training process of each indi-\nvidual model, perform a non-exhaustive hyperparameter grid\nsearch to obtain the best hyperparameter values that boost its\nperformance.\n4. From the previous models based on LSTM-Networks and\nStacked-LSTM Networks, identify the model that achieves the\nbest performance and accuracy across all five datasets. Based\non the architecture of this model, build two different model\nversions of Stacked-LSTM Networks and one Bidirectional-LSTM\nNetworks model.\nAs mentioned earlier, the performance of algorithms is directly\naffected by a plethora of design decisions. These design decisions\ninclude the choice of the values of the different parameters and hyper-\nparameters involved in each algorithm. Therefore, it is good practice to\nsearch for the values of the parameters and hyperparameters (Poornima\n& Pushpalatha, 2019) that optimise the performance of an algorithm.\nEven though a non-exhaustive hyperparameter tuning process was\nperformed for each dataset, it is out of the scope of this research to\n14\n", [65]], "Methods": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nFig. 15. Nullness of features in the cities of Newport and Swindon.\nmain weather feature is Snow 1 h and the Snow ID 601 feature\nrepresents an internal code used by the OpenWeather services.\nConsequently, the feature Snow ID 601 is removed.\nTaking into account the last consideration of removing the feature\nthat represents an internal ID code for the use of OpenWeather services,\nit was decided to remove the rest of the features that contain ID codes\nfrom the five datasets.\nThis study does not consider time and date values as features that\nmodels can learn. The rationale is to avoid restricting the learning\nprocess of the models to possible time hidden patterns. Therefore,\nthe date-time feature was removed from all five datasets. After this\nprocess, the dimensionality of the datasets was downsized from 43 to\n11 features.\nFinally, dataset normalisation is a common approach performed in\nMachine Learning problems when its features have a different range\nof values between them (Kim & Bae, 2017; Shanker, Hu, & Hung,\n1996). Implementing this process could produce better results and\nminimise the time required to train a model (Shanker et al., 1996).\nHence, the MinMaxScaler normalisation function from the Scikit Learn\nlibrary (Pedregosa et al., 2011) was used to re-scale the features of the\nfive datasets in the range between zero and one.\nThe final structure of the datasets that resulted from this preprocess-\ning procedure, and used to train and test the rainfall prediction models,\nare described in Section 5.2.\n5. Methods\nThis section provides a detailed description of the experiments\nperformed to develop and test different rainfall prediction models. This\ndescription includes the structure of the feature vector rows of the\ndatasets, the procedure for building the training, validation and testing\nsubsets of each of the five datasets, the implementation of the non-\nexhaustive hyperparameter search for the rainfall forecasting models\nbased on XGBoost and LSTM-Networks, the fixed values for the rest of\nthe parameters of the models, and the implementation and adaptations\nmade to the tested models.\n5.1. Rainfall prediction approach\nThis\nstudy\nseeks\nto\ninvestigate\nthe\nsuitability\nof\nthree\nLSTM-Networks architectures in the task of predicting 8-hours of rain-\nfall volume using time-series data from five major UK cities. In partic-\nular, this study makes a comparison between forecast models based\non LSTM-Networks, Stacked-LSTM Networks and Bidirectional-LSTM\nNetworks against an XGBoost decision tree algorithm and an algorithm\nresulting from the use of AutoML.\nTherefore, in order to achieve a broad, non-exhaustive, comparison\nthe following experimental procedure was followed:\n1. Build an XGBoost model for each of the five datasets as a\nbaseline. Perform a non-exhaustive hyperparameter grid search\nto obtain the best hyperparameter values to train each model.\n2. Use an AutoML tool to explore the performance of different well-\nknown regression algorithms in the literature. For each of the\nfive datasets, train a model recommended by the AutoML tool.\n3. From the literature review, build two models based on LSTM-\nNetworks and one model based on Stacked-LSTM Networks. For\neach of the five datasets, train an individual version of the\nthree models built. During the training process of each indi-\nvidual model, perform a non-exhaustive hyperparameter grid\nsearch to obtain the best hyperparameter values that boost its\nperformance.\n4. From the previous models based on LSTM-Networks and\nStacked-LSTM Networks, identify the model that achieves the\nbest performance and accuracy across all five datasets. Based\non the architecture of this model, build two different model\nversions of Stacked-LSTM Networks and one Bidirectional-LSTM\nNetworks model.\nAs mentioned earlier, the performance of algorithms is directly\naffected by a plethora of design decisions. These design decisions\ninclude the choice of the values of the different parameters and hyper-\nparameters involved in each algorithm. Therefore, it is good practice to\nsearch for the values of the parameters and hyperparameters (Poornima\n& Pushpalatha, 2019) that optimise the performance of an algorithm.\nEven though a non-exhaustive hyperparameter tuning process was\nperformed for each dataset, it is out of the scope of this research to\n14\n", []], "Correlation Matrix and feature selection": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nFig. 13. Examples of rainfall predictions and true observed rainfall.\n\u2022 Replenish the missing values of rain 1 h, rain 3 h, snow 1 h, and\nsnow 3 h features. These features refer to the volume of rain and\nsnow that fell during one and three hours. Consequently, missing\nvalues of these features were filled in with zeros. This approach\nfollows the rationale that for any hour that any of these values\nare missing, there was no precipitation.\n\u2022 Separate weather condition codes. The weather condition codes\ncomprehend the weather id, weather main, weather description,\nand weather icon sub-features. These sub-features include one to\nseveral records depending on the types of weather recorded in an\nhour. The objective of the separation process is to help in the task\nof building vector rows of invariant length.\n\u2022 Standardise the number of weather condition codes. A recorded\nhour can contain zero or multiple weather conditions. Two steps\nwere implemented to obtain a dataset integrated by feature vec-\ntors of the same length. First, the weather description, weather\nmain, and weather icon features were removed because they are\nrepresented by the weather id feature. Secondly, the weather id\nvalues that were not present in the five data sets, corresponding\nto the five UK cities, were removed. This step also allows the\nbuilding of all five datasets with the same feature-length.\n\u2022 Compute one-hot encoding for the weather id codes. This step\ndownsizes the range of id code values of 300\u2013900 to values of zero\nor one. Values of zero denote the absence of a particular weather\ncondition and values of one denote its presence.\n\u2022 Structure the feature vectors rows. One feature vector concen-\ntrates the described weather measurements observed in one hour.\nThe weather datasets of the five major UK cities were built with\nthis structure.\nThe pre-processing process of the weather dataset results in five\ndatasets with a 43-dimensional feature vector structure. Each dataset\nis integrated by all previously described weather measurements, the\ngeographical coordinates, and by common weather codes across the\nfive datasets such as Rain ID 500, Drizzle ID 300, and Mist ID 701.\n4.1.1. Correlation Matrix and feature selection\nThe next step involved in preparing the data that will be used to\ntrain the rainfall forecasting models is the selection and retention of\n12\n", [54]], "Dataset pre-processing": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nFig. 12. Training and validation loss - Model 6.\nof the pre-processing procedure to prepare the time-series data for use\nin the training of the rainfall forecast models is given.\nThe rationale for developing a prediction model that forecasts 8-\nhours of rainfall lies not only in the impact of precipitation on washing\nand deposition of different air pollutants but in providing prompt\nestimates to support decision making to diminish eventualities in sev-\neral human-related activities. Therefore, the acquisition of historical\nweather data that includes the climatic measurements recorded every\nhour is imperative.\nConsequently, OpenWeather1 data from five major UK cities were\nselected to test the proposed models. Specifically, historical data from\nJanuary 1, 2000, to April 21, 2020, from the cities of Bath, Bristol,\nCardiff, Newport, and Swindon were used.\nThe complete dataset comprises hourly recorded weather measure-\nments of temperature, pressure, humidity, wind speed and direction,\npercentage of clouds, the volume of rain, and volume of snow. More-\nover, the dataset provides records of the city name, latitude and\nlongitude coordinates, timezone code, the date the observation was\nrecorded, and a set of codes that OpenWeather uses on its platform\nto label various weather conditions such as mist, thunderstorm, smoke,\netc.\n1 https://openweathermap.org.\n4.1. Dataset pre-processing\nAs with any Machine Learning approach, a processing procedure\nis required to prepare raw data for use in model training and testing\nprocesses. The pre-processing procedure carried out had as its objective\nthe elimination of categorical data, the deletion or replenishment of\nincomplete data, and the structuring of one hour of observations in\none vector row. Specifically, the pre-processing procedure performed\nis described below:\n\u2022 Separate weather data by city. This step aims to preserve the\nweather singularities of each city during the training process.\n\u2022 Obtain the nullness percentage of each feature. This step help\nin the decision of removing or filling up missing values of each\ncolumn vector. The nullness percentage values of each feature in\nthe five major UK cities are concentrated in Appendix A.\n\u2022 Remove the sea and ground-level measurements. Both features\npresent 100% of nullness; therefore, these features cannot be used\nin the experimental phase.\n\u2022 Remove the city name and date-time iso features. The city name is\nno longer required due to the process of dividing the data for each\ncity. The date and time values of the records are duplicated in the\ndate-time feature; then, the date-time iso column is removed.\n11\n", [50, 54]], "Weather datasets": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nFig. 11. Training and validation loss - Model 5.\nthe amount of information of the internal state that passes to the next\nlayer. Eq. (2) cover the basic definitions of LSTM-Networks (Akbari\nAsanjan et al., 2018; Aswin et al., 2018; Chao et al., 2018; Cui, Ke,\nPu, & Wang, 2018; Goodfellow et al., 2016; Gulli et al., 2019; Kim &\nBae, 2017; Kumar et al., 2019; Poornima & Pushpalatha, 2019; Salman\net al., 2018; Singh et al., 2015; Zhang et al., 2018; Zou et al., 2019).\n\ud835\udc56\ud835\udc5b\ud835\udc5d\ud835\udc62\ud835\udc61\ud835\udc54\ud835\udc4e\ud835\udc61\ud835\udc52(\ud835\udc56) = \ud835\udf0e(\ud835\udc4a\ud835\udc56\u210e\ud835\udc61\u22121 + \ud835\udc48\ud835\udc56\ud835\udc4b\ud835\udc61+ \ud835\udc49\ud835\udc56\ud835\udc36\ud835\udc61\u22121)\n\ud835\udc5c\ud835\udc62\ud835\udc61\ud835\udc5d\ud835\udc62\ud835\udc61\ud835\udc54\ud835\udc4e\ud835\udc61\ud835\udc52(\ud835\udc5c) = \ud835\udf0e(\ud835\udc4a\ud835\udc5c\u210e\ud835\udc61\u22121 + \ud835\udc48\ud835\udc5c\ud835\udc4b\ud835\udc61+ \ud835\udc49\ud835\udc5c\ud835\udc36\ud835\udc61\u22121)\n\ud835\udc53\ud835\udc5c\ud835\udc5f\ud835\udc54\ud835\udc52\ud835\udc61\ud835\udc54\ud835\udc4e\ud835\udc61\ud835\udc52(\ud835\udc53) = \ud835\udf0e(\ud835\udc4a\ud835\udc53\u210e\ud835\udc61\u22121 + \ud835\udc48\ud835\udc53\ud835\udc4b\ud835\udc61+ \ud835\udc49\ud835\udc53\ud835\udc36\ud835\udc61\u22121)\n\ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc5b\ud835\udc4e\ud835\udc59\u210e\ud835\udc56\ud835\udc51\ud835\udc51\ud835\udc52\ud835\udc5b\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc61\ud835\udc52(\ud835\udc54) = \ud835\udc61\ud835\udc4e\ud835\udc5b\u210e(\ud835\udc4a\ud835\udc54\u210e\ud835\udc61\u22121 + \ud835\udc48\ud835\udc54\ud835\udc4b\ud835\udc61)\n\ud835\udc50\ud835\udc62\ud835\udc5f\ud835\udc5f\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc50\ud835\udc52\ud835\udc59\ud835\udc59\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc50\ud835\udc61= (\ud835\udc53\u2217\ud835\udc50\ud835\udc61\u22121) + (\ud835\udc54\u2217\ud835\udc56)\n\ud835\udc50\ud835\udc62\ud835\udc5f\ud835\udc5f\ud835\udc52\ud835\udc5b\ud835\udc61\u210e\ud835\udc56\ud835\udc51\ud835\udc51\ud835\udc52\ud835\udc5b\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc61\ud835\udc52\u210e\ud835\udc61= \ud835\udc61\ud835\udc4e\ud835\udc5b\u210e(\ud835\udc50\ud835\udc61) \u2217\ud835\udc5c\n(2)\nwhere W,U,V are different weight matrices, current time \ud835\udc61and previous\ntime \ud835\udc61\u22121. Stacked-LSTM Networks are composed of two or more LSTM\nNetworks linked successively as hidden layers. This stacked architec-\nture can provide, in some applications, a higher level of representation\nof time-series data than LSTM-Networks (Cui et al., 2018). Fig. 1 shows\nthe architecture of a simple LSTM-Network.\n3.3. Bidirectional RNN networks\nBidirectional RNN is a variation of RNNs that are capable of learning\ndependencies of previous and future states. This type of architecture\nhas shown good results in domains such as natural language processing\nfor speech and handwriting recognition. Bidirectional RNN involves the\nimplementation of RNN cells that capture time-series data from left to\nright (standard RNN cells) and RNN cells that capture data in a reverse\nmanner (Cui et al., 2018; Goodfellow et al., 2016; Gulli et al., 2019;\nSingh et al., 2015; Zou et al., 2019). Fig. 2 shows the architecture\nof a Bidirectional-LSTM Network with two hidden layers. Replacing\nthe RNN cells with LSTM cells of the Bidirectional RNN results in a\nBidirectional-LSTM Networks.\n4. Weather datasets\nIn this section, the climatic features included in the weather datasets\nare first described. Subsequently, the description of the Correlation\nMatrix analysis and the feature selection process carried out as part\n10\n", [46, 50]], "Bidirectional RNN networks": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nFig. 11. Training and validation loss - Model 5.\nthe amount of information of the internal state that passes to the next\nlayer. Eq. (2) cover the basic definitions of LSTM-Networks (Akbari\nAsanjan et al., 2018; Aswin et al., 2018; Chao et al., 2018; Cui, Ke,\nPu, & Wang, 2018; Goodfellow et al., 2016; Gulli et al., 2019; Kim &\nBae, 2017; Kumar et al., 2019; Poornima & Pushpalatha, 2019; Salman\net al., 2018; Singh et al., 2015; Zhang et al., 2018; Zou et al., 2019).\n\ud835\udc56\ud835\udc5b\ud835\udc5d\ud835\udc62\ud835\udc61\ud835\udc54\ud835\udc4e\ud835\udc61\ud835\udc52(\ud835\udc56) = \ud835\udf0e(\ud835\udc4a\ud835\udc56\u210e\ud835\udc61\u22121 + \ud835\udc48\ud835\udc56\ud835\udc4b\ud835\udc61+ \ud835\udc49\ud835\udc56\ud835\udc36\ud835\udc61\u22121)\n\ud835\udc5c\ud835\udc62\ud835\udc61\ud835\udc5d\ud835\udc62\ud835\udc61\ud835\udc54\ud835\udc4e\ud835\udc61\ud835\udc52(\ud835\udc5c) = \ud835\udf0e(\ud835\udc4a\ud835\udc5c\u210e\ud835\udc61\u22121 + \ud835\udc48\ud835\udc5c\ud835\udc4b\ud835\udc61+ \ud835\udc49\ud835\udc5c\ud835\udc36\ud835\udc61\u22121)\n\ud835\udc53\ud835\udc5c\ud835\udc5f\ud835\udc54\ud835\udc52\ud835\udc61\ud835\udc54\ud835\udc4e\ud835\udc61\ud835\udc52(\ud835\udc53) = \ud835\udf0e(\ud835\udc4a\ud835\udc53\u210e\ud835\udc61\u22121 + \ud835\udc48\ud835\udc53\ud835\udc4b\ud835\udc61+ \ud835\udc49\ud835\udc53\ud835\udc36\ud835\udc61\u22121)\n\ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc5b\ud835\udc4e\ud835\udc59\u210e\ud835\udc56\ud835\udc51\ud835\udc51\ud835\udc52\ud835\udc5b\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc61\ud835\udc52(\ud835\udc54) = \ud835\udc61\ud835\udc4e\ud835\udc5b\u210e(\ud835\udc4a\ud835\udc54\u210e\ud835\udc61\u22121 + \ud835\udc48\ud835\udc54\ud835\udc4b\ud835\udc61)\n\ud835\udc50\ud835\udc62\ud835\udc5f\ud835\udc5f\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc50\ud835\udc52\ud835\udc59\ud835\udc59\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc50\ud835\udc61= (\ud835\udc53\u2217\ud835\udc50\ud835\udc61\u22121) + (\ud835\udc54\u2217\ud835\udc56)\n\ud835\udc50\ud835\udc62\ud835\udc5f\ud835\udc5f\ud835\udc52\ud835\udc5b\ud835\udc61\u210e\ud835\udc56\ud835\udc51\ud835\udc51\ud835\udc52\ud835\udc5b\ud835\udc60\ud835\udc61\ud835\udc4e\ud835\udc61\ud835\udc52\u210e\ud835\udc61= \ud835\udc61\ud835\udc4e\ud835\udc5b\u210e(\ud835\udc50\ud835\udc61) \u2217\ud835\udc5c\n(2)\nwhere W,U,V are different weight matrices, current time \ud835\udc61and previous\ntime \ud835\udc61\u22121. Stacked-LSTM Networks are composed of two or more LSTM\nNetworks linked successively as hidden layers. This stacked architec-\nture can provide, in some applications, a higher level of representation\nof time-series data than LSTM-Networks (Cui et al., 2018). Fig. 1 shows\nthe architecture of a simple LSTM-Network.\n3.3. Bidirectional RNN networks\nBidirectional RNN is a variation of RNNs that are capable of learning\ndependencies of previous and future states. This type of architecture\nhas shown good results in domains such as natural language processing\nfor speech and handwriting recognition. Bidirectional RNN involves the\nimplementation of RNN cells that capture time-series data from left to\nright (standard RNN cells) and RNN cells that capture data in a reverse\nmanner (Cui et al., 2018; Goodfellow et al., 2016; Gulli et al., 2019;\nSingh et al., 2015; Zou et al., 2019). Fig. 2 shows the architecture\nof a Bidirectional-LSTM Network with two hidden layers. Replacing\nthe RNN cells with LSTM cells of the Bidirectional RNN results in a\nBidirectional-LSTM Networks.\n4. Weather datasets\nIn this section, the climatic features included in the weather datasets\nare first described. Subsequently, the description of the Correlation\nMatrix analysis and the feature selection process carried out as part\n10\n", [46]], "(Stacked) Long-short term memory networks": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nFig. 10. Training and validation loss - Model 4.\nthat inform precipitation forecast in the next eight hours into\nthe future. This formulation turns the problem into multi-target\nregression model.\n3.1. Recurrent neural networks\nA Recurrent Neural Network (RNN) is a class of NN that, due\nto its flexibility to exploit time-series data, has been widely used in\nresearch areas such as machine translation, sentiment analysis, speech\nrecognition, and weather forecast, among others. RNN cells capture\nthe dependencies that exist in the elements of data that are been\nstored in sequence by incorporating a hidden state. This state is what\nallows maintaining the relationship between the previous and current\nobserved data. Eq. (1) shows how RNNs can preserve dependencies\nwithin time-series sequences (Akbari Asanjan et al., 2018; Goodfellow,\nBengio, & Courville, 2016; Gulli, Kapoor, & Pal, 2019; Kim & Bae, 2017;\nKumar et al., 2019; Poornima & Pushpalatha, 2019; Salman et al., 2018;\nZhang et al., 2018; Zou, Fang, Harrison, & Djokic, 2019).\n\u210e\ud835\udc61= \ud835\udf19(\u210e\ud835\udc61\u22121, \ud835\udc4b\ud835\udc61)\n(1)\nwhere \u210e\ud835\udc61and \u210e\ud835\udc61\u22121 are hidden states at a current time (\ud835\udc61) and previous\ntime (\ud835\udc61\u22121), respectively. \ud835\udc4b\ud835\udc61is the current input value at time \ud835\udc61.\nThis equation is used recursively to allow the network to learn the\ndependencies of the data.\nThe RNNs are sensitive to the effects of vanishing gradients when\nlearning long-range dependencies is pursued. LSTM-Networks is an\nRNN cell variant that reduces this limitation (Akbari Asanjan et al.,\n2018; Chao et al., 2018; Goodfellow et al., 2016; Gulli et al., 2019;\nKumar et al., 2019; Poornima & Pushpalatha, 2019; Singh et al., 2015;\nXingjian et al., 2015; Zhang et al., 2018; Zou et al., 2019).\n3.2. (Stacked) Long-short term memory networks\nThe Long-short Term Memory (LSTM) Networks are the most widely\nused RNN cell variant due to their ability to learning long dependencies\nwithin sequential data. Successful applications of LSTM-Networks can\nbe found in research fields such as human trajectory prediction, traffic\nforecasting, speech recognition, and weather prediction. This type of\nRNN cell is capable of learning the dependencies of at least two\nprevious states and the current state. The vanishing gradient effect is\nminimised by implementing three gates along with the hidden state.\nThe three implemented gates are commonly referred to as input, out-\nput, and forget gates. The input gate defines the amount of information\nof the new state that is used. The output gate determines the amount of\ninformation that is used from previous states. The forget gate conditions\n9\n", [42, 46]], "Recurrent neural networks": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nFig. 10. Training and validation loss - Model 4.\nthat inform precipitation forecast in the next eight hours into\nthe future. This formulation turns the problem into multi-target\nregression model.\n3.1. Recurrent neural networks\nA Recurrent Neural Network (RNN) is a class of NN that, due\nto its flexibility to exploit time-series data, has been widely used in\nresearch areas such as machine translation, sentiment analysis, speech\nrecognition, and weather forecast, among others. RNN cells capture\nthe dependencies that exist in the elements of data that are been\nstored in sequence by incorporating a hidden state. This state is what\nallows maintaining the relationship between the previous and current\nobserved data. Eq. (1) shows how RNNs can preserve dependencies\nwithin time-series sequences (Akbari Asanjan et al., 2018; Goodfellow,\nBengio, & Courville, 2016; Gulli, Kapoor, & Pal, 2019; Kim & Bae, 2017;\nKumar et al., 2019; Poornima & Pushpalatha, 2019; Salman et al., 2018;\nZhang et al., 2018; Zou, Fang, Harrison, & Djokic, 2019).\n\u210e\ud835\udc61= \ud835\udf19(\u210e\ud835\udc61\u22121, \ud835\udc4b\ud835\udc61)\n(1)\nwhere \u210e\ud835\udc61and \u210e\ud835\udc61\u22121 are hidden states at a current time (\ud835\udc61) and previous\ntime (\ud835\udc61\u22121), respectively. \ud835\udc4b\ud835\udc61is the current input value at time \ud835\udc61.\nThis equation is used recursively to allow the network to learn the\ndependencies of the data.\nThe RNNs are sensitive to the effects of vanishing gradients when\nlearning long-range dependencies is pursued. LSTM-Networks is an\nRNN cell variant that reduces this limitation (Akbari Asanjan et al.,\n2018; Chao et al., 2018; Goodfellow et al., 2016; Gulli et al., 2019;\nKumar et al., 2019; Poornima & Pushpalatha, 2019; Singh et al., 2015;\nXingjian et al., 2015; Zhang et al., 2018; Zou et al., 2019).\n3.2. (Stacked) Long-short term memory networks\nThe Long-short Term Memory (LSTM) Networks are the most widely\nused RNN cell variant due to their ability to learning long dependencies\nwithin sequential data. Successful applications of LSTM-Networks can\nbe found in research fields such as human trajectory prediction, traffic\nforecasting, speech recognition, and weather prediction. This type of\nRNN cell is capable of learning the dependencies of at least two\nprevious states and the current state. The vanishing gradient effect is\nminimised by implementing three gates along with the hidden state.\nThe three implemented gates are commonly referred to as input, out-\nput, and forget gates. The input gate defines the amount of information\nof the new state that is used. The output gate determines the amount of\ninformation that is used from previous states. The forget gate conditions\n9\n", [42]], "Theoretical background": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nFig. 9. Training and validation loss - Model 3.\ntime-lapse and precipitation amount, between observed and forecasted\nvalues remain as one of the major drawbacks in the complex task of\nrainfall forecasting.\nMoreover, and as previously mentioned, the performance of rainfall\nforecasting models depends on the parameters and architecture of the\nmodels, as well as the characteristics of the data used for their training.\nTherefore, a comparative analysis of the performance of rainfall fore-\ncasting models using meteorological time series data from five major\nUK cities would benefit the development of budgeting applications\naimed at improving quality of life and decreasing the socio-economic\nimpacts caused by rains in the country.\n3. Theoretical background\nThis section provides a brief introduction to the concepts of Neural\nNetworks, LSTM-networks, Stacked-LSTM Networks, and Bidirectional-\nLSTM Networks.\nAs shown in Section 2, several studies highlight the performance\nof models based on Neural Networks (NNs) in the rainfall forecast\ntask (Aswin et al., 2018; Balluff et al., 2020; Chao et al., 2018; Kim &\nBae, 2017; Kratzert et al., 2018; Kumar et al., 2019; Poornima & Push-\npalatha, 2019; Ramos et al., 2019; Yunpeng et al., 2017). The following\nthree major aspects summarise the rationale for the suitability of NNs\nin the problem of weather forecasting:\n\u2022 Probabilistic models: Weather forecasting is a non-trivial problem\ndue to humungous uncertainty underlying the question. This\nuncertainty shall be inherent in the underlying ML approach. The\nNeural Network (NN) algorithm supports this uncertainty by engi-\nneering the last layer of the model to yield a probabilistic output.\nIt is usually achieved by applying the Softmax activation to the\noutput in the last layer, which scales these outputs between zero\nand one. This scaling makes the uncertainty an inherent feature\nof the network and allows learning humungous uncertainty in a\nnovel fashion.\n\u2022 Spatiotemporal dependencies: The weather forecast of a geo-\ngraphical location is highly dependent on the state and context\nof the area at that point as well as points in the past. This fact\nhighlights the importance of spatiotemporal features and their\ninevitable role in the right determination of the weather. NNs\nare a great tool to harness spatiotemporal dependencies from the\ndata and learn latent features that relate the input to target with\ngreater accuracy.\n\u2022 Discrete distributions: Discretisation of output is also crucial for\nthe weather prediction tasks like precipitation modelling that\nis inherent to the NNs algorithm. Unlike continuous outputs,\nthe output of the model is designed to be split across buckets\nwhich, in this approach, is the hourly window. To avoid recursive\ninvocations, the problem is formulated to generate eight buckets\n8\n", [38, 42]], "Related work": ["A.Y. Barrera-Animas, L.O. Oyedele, M. Bilal et al.\nMachine Learning with Applications 7 (2022) 100204\nFig. 7. Training and validation loss - Model 1.\ndescription includes both the structure of the datasets used in the train-\ning and testing processes to forecast hourly rainfall values, as well as\nthe architectures and parameters of the different implemented models\nbased on XGBoost, AutoML, LSTM, Stacked-LSTM, and Bidirectional-\nLSTM networks. Later on, results obtained are presented and discussed\nin Section 6. Finally, in Section 7, conclusions and further research\nsteps are highlighted.\n2. Related work\nThis section gives an introduction to research works that use time-\nseries data to train rainfall forecast models based on Feed-forward Back-\npropagation Neural Networks, LSTM-Networks, and Stacked-LSTM Net-\nworks.\nSingh and Borah (2013), trained five architectures of a Feed-forward\nBack-propagation Neural Network algorithm containing only three lay-\ners (1 input, 1 hidden, and 1 output layer) to forecast the mean rainfall\nof the summer monsoon in India on a monthly and seasonal basis.\nThe authors provide the prediction of rainfall amounts by combining\nthe results given by the five trained Neural Networks. Only monthly\nvalues of rainfall and seasonal rainfall were used from two sources\nfrom the period 1871 to 2010, a dataset from a literature reviewed\nwork and a dataset from the Indian Institute of Tropical Meteorology.\nResults showed that their ensemble approach performed better on the\nevaluation metrics of Means, Standard Deviations, Correlation Coeffi-\ncient, Root Mean Square Error (RMSE), and Performance Parameter\ncompared to a related work that uses a more complex Feed-forward\nBack-propagation Neural Network.\nKim and Bae proposed an LSTM-Networks model to forecast one\nhour of rainfall into the future (Kim & Bae, 2017). To train and\nvalidate the forecast model, weather data from 2012 from Gangneung,\nGangwon-do region (Korea) was used. The climatic features that inte-\ngrate the weather dataset were temperature, wind speed, humidity, and\nsea surface pressure. Moreover, the lag characteristics of the amount of\nrainfall in the current and past hours of observation were considered.\nIn the first phase of experimentation, the proposed LSTM-Networks\nmodel was compared with an Artificial Neural Network (ANN) model.\nThe results of this experiment showed that the LSTM-Networks model\nachieves better values for the RMSE evaluation metric. A second phase\nof experimentation was carried out including the measurement of water\nvapour as a feature. However, the RMSE plotted values throughout the\ntraining epochs showed an over-fitting behaviour for the training data.\nLater, Chao et al. (2018) compared five models based on Auto-\nregressive and Moving Average, Random Forest, Back-propagation Neu-\nral Networks, Support Vector Machines, and LSTM-Networks in the\n6\n", [30, 34, 38]], "Introduction": ["Machine Learning with Applications 7 (2022) 100204\nContents lists available at ScienceDirect\nMachine Learning with Applications\njournal homepage: www.elsevier.com/locate/mlwa\nRainfall prediction: A comparative analysis of modern machine learning\nalgorithms for time-series forecasting\nAri Yair Barrera-Animas, Lukumon O. Oyedele \u2217, Muhammad Bilal,\nTaofeek Dolapo Akinosho, Juan Manuel Davila Delgado, Lukman Adewale Akanbi\nBig Data Enterprise and Artificial Intelligent Lab (Big-DEAL), Bristol Business School, University of the West of England Bristol, United Kingdom\nA R T I C L E\nI N F O\nKeywords:\nRainfall prediction\nLSTM Networks\nMultivariate time-series\nMulti-step forecast\nTime-series data\nA B S T R A C T\nRainfall forecasting has gained utmost research relevance in recent times due to its complexities and persistent\napplications such as flood forecasting and monitoring of pollutant concentration levels, among others. Existing\nmodels use complex statistical models that are often too costly, both computationally and budgetary, or\nare not applied to downstream applications. Therefore, approaches that use Machine Learning algorithms\nin conjunction with time-series data are being explored as an alternative to overcome these drawbacks.\nTo this end, this study presents a comparative analysis using simplified rainfall estimation models based\non conventional Machine Learning algorithms and Deep Learning architectures that are efficient for these\ndownstream applications. Models based on LSTM, Stacked-LSTM, Bidirectional-LSTM Networks, XGBoost, and\nan ensemble of Gradient Boosting Regressor, Linear Support Vector Regression, and an Extra-trees Regressor\nwere compared in the task of forecasting hourly rainfall volumes using time-series data. Climate data from\n2000 to 2020 from five major cities in the United Kingdom were used. The evaluation metrics of Loss, Root\nMean Squared Error, Mean Absolute Error, and Root Mean Squared Logarithmic Error were used to evaluate\nthe models\u2019 performance. Results show that a Bidirectional-LSTM Network can be used as a rainfall forecast\nmodel with comparable performance to Stacked-LSTM Networks. Among all the models tested, the Stacked-\nLSTM Network with two hidden layers and the Bidirectional-LSTM Network performed best. This suggests\nthat models based on LSTM-Networks with fewer hidden layers perform better for this approach; denoting its\nability to be applied as an approach for budget-wise rainfall forecast applications.\n1. Introduction\nRainfall remains one of the most influential meteorological param-\neters in many aspects of our daily lives. With effects ranging from\ndamage to infrastructure in the event of a flood to disruptions in the\ntransport network, the socio-economic impacts of rainfall are notewor-\nthy (Le, Pham, Ly, Shirzadi and Le, 2020). Floods and similar extreme\nevents are consequences of climate change that are expected to occur\nmore frequently and have catastrophic effects in years to come (Yucel,\nOnen, Yilmaz, & Gochis, 2015). More interestingly, recent studies\nhave highlighted that weather conditions can potentially increase air\npollution (another major topic of discourse alongside climate change\nin recent times) in winter and summer periods (Czarnecka, Nidzgorska-\nLencewicz, et al., 2011). It is pertinent to reiterate that increased\nair pollution results in health conditions such as asthma and similar\nproblems related to the lungs (Mokrani, Lounas, Bennai, Salhi, & Djerbi,\n2019; Zadtootaghaj, Mohammadian, Mahbanooei, & Ghasemi, 2019).\nTherefore, as a mitigation approach, many studies have investigated\n\u2217Corresponding author.\nE-mail addresses: ari.barreraanimas@uwe.ac.uk (A.Y. Barrera-Animas), l.oyedele@uwe.ac.uk (L.O. Oyedele), muhammad.bilal@uwe.ac.uk (M. Bilal),\ntaofeek.akinosho@uwe.ac.uk (T.D. Akinosho), manuel.daviladelgado@uwe.ac.uk (J.M.D. Delgado), lukman.akanbi@uwe.ac.uk (L.A. Akanbi).\nand proposed rainfall forecasting techniques in preparation for any\neventuality. However, in order to enhance human mobility activi-\nties (Salman, Heryadi, Abdurahman, & Suparta, 2018; Xingjian et al.,\n2015) and enhance agriculture and industrial development (Aguasca-\nColomo, Castellanos-Nieves, & M\u00e9ndez, 2019; Chao, Pu, Yin, Han, &\nChen, 2018; Kim, Hong, Joh, & Song, 2017; Kumar, Singh, Samui, &\nJha, 2019; Poornima & Pushpalatha, 2019; Zhang, Zhu, Zhang, Ye,\n& Yang, 2018), these approaches must provide efficient and timely\npredictions.\nRainfall forecasting has been around for years using traditional\nmethods that employ statistical techniques to assess the correlation be-\ntween rainfall, geographic coordinates (such as latitude and longitude),\nand other atmospheric factors (like pressure, temperature, wind speed,\nand humidity). However, the complexity of rainfall such as its non-\nlinearity makes it difficult to predict (Wu & Chau, 2013). Consequently,\nattempts have been made to reduce this non-linearity by using Singular\nSpectrum Analysis, Empirical Mode Decomposition, Wavelet analysis,\nhttps://doi.org/10.1016/j.mlwa.2021.100204\nReceived 23 August 2021; Received in revised form 14 October 2021; Accepted 28 October 2021\nAvailable online 11 November 2021\n2666-8270/\u00a9 2022 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license\n(http://creativecommons.org/licenses/by/4.0/).\n", [304, 306, 5, 7, 16, 17, 30]], "Rainfall prediction: A comparative analysis of modern machine learning algorithms for time-series forecasting": ["Machine Learning with Applications 7 (2022) 100204\nContents lists available at ScienceDirect\nMachine Learning with Applications\njournal homepage: www.elsevier.com/locate/mlwa\nRainfall prediction: A comparative analysis of modern machine learning\nalgorithms for time-series forecasting\nAri Yair Barrera-Animas, Lukumon O. Oyedele \u2217, Muhammad Bilal,\nTaofeek Dolapo Akinosho, Juan Manuel Davila Delgado, Lukman Adewale Akanbi\nBig Data Enterprise and Artificial Intelligent Lab (Big-DEAL), Bristol Business School, University of the West of England Bristol, United Kingdom\nA R T I C L E\nI N F O\nKeywords:\nRainfall prediction\nLSTM Networks\nMultivariate time-series\nMulti-step forecast\nTime-series data\nA B S T R A C T\nRainfall forecasting has gained utmost research relevance in recent times due to its complexities and persistent\napplications such as flood forecasting and monitoring of pollutant concentration levels, among others. Existing\nmodels use complex statistical models that are often too costly, both computationally and budgetary, or\nare not applied to downstream applications. Therefore, approaches that use Machine Learning algorithms\nin conjunction with time-series data are being explored as an alternative to overcome these drawbacks.\nTo this end, this study presents a comparative analysis using simplified rainfall estimation models based\non conventional Machine Learning algorithms and Deep Learning architectures that are efficient for these\ndownstream applications. Models based on LSTM, Stacked-LSTM, Bidirectional-LSTM Networks, XGBoost, and\nan ensemble of Gradient Boosting Regressor, Linear Support Vector Regression, and an Extra-trees Regressor\nwere compared in the task of forecasting hourly rainfall volumes using time-series data. Climate data from\n2000 to 2020 from five major cities in the United Kingdom were used. The evaluation metrics of Loss, Root\nMean Squared Error, Mean Absolute Error, and Root Mean Squared Logarithmic Error were used to evaluate\nthe models\u2019 performance. Results show that a Bidirectional-LSTM Network can be used as a rainfall forecast\nmodel with comparable performance to Stacked-LSTM Networks. Among all the models tested, the Stacked-\nLSTM Network with two hidden layers and the Bidirectional-LSTM Network performed best. This suggests\nthat models based on LSTM-Networks with fewer hidden layers perform better for this approach; denoting its\nability to be applied as an approach for budget-wise rainfall forecast applications.\n1. Introduction\nRainfall remains one of the most influential meteorological param-\neters in many aspects of our daily lives. With effects ranging from\ndamage to infrastructure in the event of a flood to disruptions in the\ntransport network, the socio-economic impacts of rainfall are notewor-\nthy (Le, Pham, Ly, Shirzadi and Le, 2020). Floods and similar extreme\nevents are consequences of climate change that are expected to occur\nmore frequently and have catastrophic effects in years to come (Yucel,\nOnen, Yilmaz, & Gochis, 2015). More interestingly, recent studies\nhave highlighted that weather conditions can potentially increase air\npollution (another major topic of discourse alongside climate change\nin recent times) in winter and summer periods (Czarnecka, Nidzgorska-\nLencewicz, et al., 2011). It is pertinent to reiterate that increased\nair pollution results in health conditions such as asthma and similar\nproblems related to the lungs (Mokrani, Lounas, Bennai, Salhi, & Djerbi,\n2019; Zadtootaghaj, Mohammadian, Mahbanooei, & Ghasemi, 2019).\nTherefore, as a mitigation approach, many studies have investigated\n\u2217Corresponding author.\nE-mail addresses: ari.barreraanimas@uwe.ac.uk (A.Y. Barrera-Animas), l.oyedele@uwe.ac.uk (L.O. Oyedele), muhammad.bilal@uwe.ac.uk (M. Bilal),\ntaofeek.akinosho@uwe.ac.uk (T.D. Akinosho), manuel.daviladelgado@uwe.ac.uk (J.M.D. Delgado), lukman.akanbi@uwe.ac.uk (L.A. Akanbi).\nand proposed rainfall forecasting techniques in preparation for any\neventuality. However, in order to enhance human mobility activi-\nties (Salman, Heryadi, Abdurahman, & Suparta, 2018; Xingjian et al.,\n2015) and enhance agriculture and industrial development (Aguasca-\nColomo, Castellanos-Nieves, & M\u00e9ndez, 2019; Chao, Pu, Yin, Han, &\nChen, 2018; Kim, Hong, Joh, & Song, 2017; Kumar, Singh, Samui, &\nJha, 2019; Poornima & Pushpalatha, 2019; Zhang, Zhu, Zhang, Ye,\n& Yang, 2018), these approaches must provide efficient and timely\npredictions.\nRainfall forecasting has been around for years using traditional\nmethods that employ statistical techniques to assess the correlation be-\ntween rainfall, geographic coordinates (such as latitude and longitude),\nand other atmospheric factors (like pressure, temperature, wind speed,\nand humidity). However, the complexity of rainfall such as its non-\nlinearity makes it difficult to predict (Wu & Chau, 2013). Consequently,\nattempts have been made to reduce this non-linearity by using Singular\nSpectrum Analysis, Empirical Mode Decomposition, Wavelet analysis,\nhttps://doi.org/10.1016/j.mlwa.2021.100204\nReceived 23 August 2021; Received in revised form 14 October 2021; Accepted 28 October 2021\nAvailable online 11 November 2021\n2666-8270/\u00a9 2022 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license\n(http://creativecommons.org/licenses/by/4.0/).\n", [304, 306]]}