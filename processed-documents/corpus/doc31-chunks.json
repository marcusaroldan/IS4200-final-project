{"Abstract": ["Intelligible and Explainable Machine Learning: Best Practices\nand Practical Challenges\nRich Caruana\nrcaruana@microsoft.com\nMicrosoft Research\nRedmond, WA\nScott Lundberg\nscott.lundberg@microsoft.com\nMicrosoft Research\nRedmond, WA\nMarco Tulio Ribeiro\nmarco.correia@microsoft.com\nMicrosoft Research\nRedmond, WA\nHarsha Nori\nhanori@microsoft.com\nMicrosoft Corporation\nRedmond, WA\nSamuel Jenkins\nsajenkin@microsoft.com\nMicrosoft Corporation\nRedmond, WA\nABSTRACT\nLearning methods such as boosting and deep learning have made\nML models harder to understand and interpret. This puts data\nscientists and ML developers in the position of often having to\nmake a tradeoff between accuracy and intelligibility. Research in\nIML (Interpretable Machine Learning) and XAI (Explainable AI)\nfocus on minimizing this trade-off by developing more accurate\ninterpretable models and by developing new techniques to explain\nblack-box models. Such models and techniques make it easier for\ndata scientists, engineers and model users to debug models and\nachieve important objectives such as ensuring the fairness of ML\ndecisions and the reliability and safety of AI systems. In this tutorial,\nwe present an overview of various interpretability methods and\nprovide a framework for thinking about how to choose the right\nexplanation method for different real-world scenarios. We will\nfocus on the application of XAI in practice through a variety of\ncase studies from domains such as healthcare, finance, and bias\nand fairness. Finally, we will present open problems and research\ndirections for the data mining and machine learning community.\nWhat audience will learn:\n\u2022 When and how to use a variety of machine learning in-\nterpretability methods through case studies of real-world\nsituations.\n\u2022 The difference between glass-box and black-box explanation\nmethods and when to use them.\n\u2022 How to use open source interpretability toolkits that are now\navailable\nKEYWORDS\ninterpretability, intelligibility, responsible AI\nACM Reference Format:\nRich Caruana, Scott Lundberg, Marco Tulio Ribeiro, Harsha Nori, and Samuel\nJenkins. 2020. Intelligible and Explainable Machine Learning: Best Practices\nand Practical Challenges. In 26th ACM SIGKDD Conference on Knowledge\nPermission to make digital or hard copies of part or all of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for third-party components of this work must be honored.\nFor all other uses, contact the owner/author(s).\nKDD \u201920, August 23\u201327, 2020, Virtual Event, USA\n\u00a9 2020 Copyright held by the owner/author(s).\nACM ISBN 978-1-4503-7998-4/20/08.\nhttps://doi.org/10.1145/3394486.3406707\nDiscovery and Data Mining (KDD \u201920), August 23\u201327, 2020, Virtual Event, USA.\nACM, New York, NY, USA, 2 pages. https://doi.org/10.1145/3394486.3406707\nBIO\nRich Caruana is a senior principal researcher at Microsoft Re-\nsearch. Previously, he was on the faculty in the Computer Science\nDepartment at Cornell University, at UCLA\u2019s Medical School, and\nat Carnegie Mellon University\u2019s Center for Learning and Discovery.\nRich received an NSF CAREER Award in 2004 (for meta cluster-\ning); best paper awards in 2005 (with Alex Niculescu-Mizil), 2007\n(with Daria Sorokina), and 2014 (with Todd Kulesza, Saleema Amer-\nshi, Danyel Fisher, and Denis Charles); co-chaired KDD in 2007\n(with Xindong Wu); and serves as area chair for Neural Information\nProcessing Systems (NIPS), International Conference on Machine\nLearning (ICML), and KDD. His research focus is on learning for\nmedical decision making, transparent modeling, deep learning, and\ncomputational ecology. He holds a PhD from Carnegie Mellon Uni-\nversity, where he worked with Tom Mitchell and Herb Simon. His\nthesis on multi-task learning helped create interest in a new subfield\nof machine learning called transfer learning.\nMarco Tulio Ribeiro is a researcher at Microsoft Research, in\nthe Adaptive Systems and Interaction group. He is also an Affiliate\nAssistant Professor at the University of Washington, where he was\npreviously a Ph.D student advised by Carlos Guestrin and Sameer\nTutorial Abstract\nKDD \u201820, August 23\u201327, 2020, Virtual Event, USA\n3511\n", [1, 2, 45]]}