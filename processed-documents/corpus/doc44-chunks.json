{"REFERENCES": ["LIMITATIONS\nThe purpose of this study is to provide a brief overview\nof big data analytics. This study has provided a com-\nprehensive literature review of data-intensive parallel\nmachine-learning algorithms for big data analytics. A\nnumber of important limitations of the study are:\n(a) The study has not considered parallel algo-\nrithms employing vertical scaling, such as\nGPUs, due to their limited scalability. The\nstudy has also not addressed parallel algo-\nrithms employing MPI.\n(b) The study has not covered graph-based analyt-\nical algorithms as they best suit the BSP (Bulk\nSynchronous\nParallel)\nmodel\nrather\nthan\nMapReduce or RDD.\n(c) The study has provided just a brief overview\nof various techniques and algorithms. How-\never, in order to see the full details regarding\nparticular techniques or algorithms, the corre-\nsponding paper may be referred.\n(d) The study is limited to only data-intensive\nbatch algorithms and does not consider online\nstreaming algorithms.\nRESEARCH IMPLICATIONS\nBig data analytics is evolving in nature, and its poten-\ntial has been exploited in almost every area and\nindustry, such as telecom, \ufb01nance, medicine, and gov-\nernment agencies, to produce better outcomes, lead-\ning to improved growth and success. Big data\nanalytics has been found to be signi\ufb01cant in various\nareas\nsuch\nas\nnational\ndevelopment,\nindustrial\nupgrade,\nscienti\ufb01c\nresearch,\ninterdisciplinary\nresearch, and better prediction.62 It has been used to\nsolve complex problems such as recommendation,\ncontent \ufb01ltering, fraud detection, and terrorist track-\ning. A typical example of big data analytics demon-\nstrating its power is an image recognition system,\nwhich took only 5 min to study 60,000 handwritten\ndigits on a Spark cluster running multiple deep learn-\ning jobs.63\nThis research would help the researchers work-\ning in the area of big data analytics to choose the\nright computational framework based on their under-\nlying\ncontext.\nThis\nresearch\nwould\nhelp\nother\nresearchers in understanding which machine-learning\ntechniques have been adapted to MapReduce, mak-\ning them scalable in prior studies. This would also\nhelp researchers in developing a new framework or\nhybrid model for big data analytics. Furthermore, the\nvarious evaluation metrics could be used as a bench-\nmark in evaluating any new technique for big data.\nCONCLUSION AND FUTURE WORK\nThe paper presents an overview of big data analytics,\nwith a special focus on data-intensive distributed\nmachine-learning algorithms for big data. The pres-\nent paper also performs a comparative analysis of the\nparallel data-intensive machine-learning algorithm on\noptimization and performance metrics. The design of\nscalable and fault tolerant learning systems have\nenabled us to address larger problems easily due to\nwhich big data analytics has drawn attention of\nmany researchers. This study would provide a base\nfor the researchers in this area as it provides a wide\ncollection of previous research.\nThis review is theoretical in nature. However,\nin the future, we would also like to implement scala-\nble machine-learning algorithms on real-world pro-\nblems, such as log analysis and social media analysis.\nBased on our survey, most of the previous studies\nhave focused on making traditional serial techniques\nscalable. A new technique built from scratch for big\ndata is missing in the literature, which could be con-\nsidered in future work. Designing a hybrid technique\nbased on MapReduce and MPI, utilizing the merits\nof both, is also worth researching in future. Visuali-\nzation plays an important role in big data analytics\nand has not been explored and is, therefore, also an\nimportant topic of exploration.\nREFERENCES\n1. Owais SS, Hussein NS. Extract \ufb01ve categories CPIVW\nfrom the 9V characteristics of the big data. Int J Adv\nComput Sci Appl 2016, 7:254\u2013258.\n2. Wu X, Zhu X, Wu GQ, Ding W. Data mining with\nbig\ndata.\nIEEE\nTrans\nKnowl\nData\nEng\n2014,\n26:97\u2013107.\n3. Chen H, Chiang RHL, Storey VC. Business intelligence\nand analytics: from big data to big impact. MIS Q\n2012, 36:1165\u20131188.\n4. Singh D, Reddy CK. A survey on platforms for big\ndata analytics. J Big Data 2014, 2:1\u201320. doi:10.1186/\ns40537.014.0008.6.\nWIREs Data Mining and Knowledge Discovery\nScalable machine-learning algorithms for big data analytics\nVolume 6, November/December 2016\n\u00a9 2016 John Wiley & Sons, Ltd\n211\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68]], "CONCLUSION AND FUTURE WORK": ["LIMITATIONS\nThe purpose of this study is to provide a brief overview\nof big data analytics. This study has provided a com-\nprehensive literature review of data-intensive parallel\nmachine-learning algorithms for big data analytics. A\nnumber of important limitations of the study are:\n(a) The study has not considered parallel algo-\nrithms employing vertical scaling, such as\nGPUs, due to their limited scalability. The\nstudy has also not addressed parallel algo-\nrithms employing MPI.\n(b) The study has not covered graph-based analyt-\nical algorithms as they best suit the BSP (Bulk\nSynchronous\nParallel)\nmodel\nrather\nthan\nMapReduce or RDD.\n(c) The study has provided just a brief overview\nof various techniques and algorithms. How-\never, in order to see the full details regarding\nparticular techniques or algorithms, the corre-\nsponding paper may be referred.\n(d) The study is limited to only data-intensive\nbatch algorithms and does not consider online\nstreaming algorithms.\nRESEARCH IMPLICATIONS\nBig data analytics is evolving in nature, and its poten-\ntial has been exploited in almost every area and\nindustry, such as telecom, \ufb01nance, medicine, and gov-\nernment agencies, to produce better outcomes, lead-\ning to improved growth and success. Big data\nanalytics has been found to be signi\ufb01cant in various\nareas\nsuch\nas\nnational\ndevelopment,\nindustrial\nupgrade,\nscienti\ufb01c\nresearch,\ninterdisciplinary\nresearch, and better prediction.62 It has been used to\nsolve complex problems such as recommendation,\ncontent \ufb01ltering, fraud detection, and terrorist track-\ning. A typical example of big data analytics demon-\nstrating its power is an image recognition system,\nwhich took only 5 min to study 60,000 handwritten\ndigits on a Spark cluster running multiple deep learn-\ning jobs.63\nThis research would help the researchers work-\ning in the area of big data analytics to choose the\nright computational framework based on their under-\nlying\ncontext.\nThis\nresearch\nwould\nhelp\nother\nresearchers in understanding which machine-learning\ntechniques have been adapted to MapReduce, mak-\ning them scalable in prior studies. This would also\nhelp researchers in developing a new framework or\nhybrid model for big data analytics. Furthermore, the\nvarious evaluation metrics could be used as a bench-\nmark in evaluating any new technique for big data.\nCONCLUSION AND FUTURE WORK\nThe paper presents an overview of big data analytics,\nwith a special focus on data-intensive distributed\nmachine-learning algorithms for big data. The pres-\nent paper also performs a comparative analysis of the\nparallel data-intensive machine-learning algorithm on\noptimization and performance metrics. The design of\nscalable and fault tolerant learning systems have\nenabled us to address larger problems easily due to\nwhich big data analytics has drawn attention of\nmany researchers. This study would provide a base\nfor the researchers in this area as it provides a wide\ncollection of previous research.\nThis review is theoretical in nature. However,\nin the future, we would also like to implement scala-\nble machine-learning algorithms on real-world pro-\nblems, such as log analysis and social media analysis.\nBased on our survey, most of the previous studies\nhave focused on making traditional serial techniques\nscalable. A new technique built from scratch for big\ndata is missing in the literature, which could be con-\nsidered in future work. Designing a hybrid technique\nbased on MapReduce and MPI, utilizing the merits\nof both, is also worth researching in future. Visuali-\nzation plays an important role in big data analytics\nand has not been explored and is, therefore, also an\nimportant topic of exploration.\nREFERENCES\n1. Owais SS, Hussein NS. Extract \ufb01ve categories CPIVW\nfrom the 9V characteristics of the big data. Int J Adv\nComput Sci Appl 2016, 7:254\u2013258.\n2. Wu X, Zhu X, Wu GQ, Ding W. Data mining with\nbig\ndata.\nIEEE\nTrans\nKnowl\nData\nEng\n2014,\n26:97\u2013107.\n3. Chen H, Chiang RHL, Storey VC. Business intelligence\nand analytics: from big data to big impact. MIS Q\n2012, 36:1165\u20131188.\n4. Singh D, Reddy CK. A survey on platforms for big\ndata analytics. J Big Data 2014, 2:1\u201320. doi:10.1186/\ns40537.014.0008.6.\nWIREs Data Mining and Knowledge Discovery\nScalable machine-learning algorithms for big data analytics\nVolume 6, November/December 2016\n\u00a9 2016 John Wiley & Sons, Ltd\n211\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68]], "RESEARCH IMPLICATIONS": ["LIMITATIONS\nThe purpose of this study is to provide a brief overview\nof big data analytics. This study has provided a com-\nprehensive literature review of data-intensive parallel\nmachine-learning algorithms for big data analytics. A\nnumber of important limitations of the study are:\n(a) The study has not considered parallel algo-\nrithms employing vertical scaling, such as\nGPUs, due to their limited scalability. The\nstudy has also not addressed parallel algo-\nrithms employing MPI.\n(b) The study has not covered graph-based analyt-\nical algorithms as they best suit the BSP (Bulk\nSynchronous\nParallel)\nmodel\nrather\nthan\nMapReduce or RDD.\n(c) The study has provided just a brief overview\nof various techniques and algorithms. How-\never, in order to see the full details regarding\nparticular techniques or algorithms, the corre-\nsponding paper may be referred.\n(d) The study is limited to only data-intensive\nbatch algorithms and does not consider online\nstreaming algorithms.\nRESEARCH IMPLICATIONS\nBig data analytics is evolving in nature, and its poten-\ntial has been exploited in almost every area and\nindustry, such as telecom, \ufb01nance, medicine, and gov-\nernment agencies, to produce better outcomes, lead-\ning to improved growth and success. Big data\nanalytics has been found to be signi\ufb01cant in various\nareas\nsuch\nas\nnational\ndevelopment,\nindustrial\nupgrade,\nscienti\ufb01c\nresearch,\ninterdisciplinary\nresearch, and better prediction.62 It has been used to\nsolve complex problems such as recommendation,\ncontent \ufb01ltering, fraud detection, and terrorist track-\ning. A typical example of big data analytics demon-\nstrating its power is an image recognition system,\nwhich took only 5 min to study 60,000 handwritten\ndigits on a Spark cluster running multiple deep learn-\ning jobs.63\nThis research would help the researchers work-\ning in the area of big data analytics to choose the\nright computational framework based on their under-\nlying\ncontext.\nThis\nresearch\nwould\nhelp\nother\nresearchers in understanding which machine-learning\ntechniques have been adapted to MapReduce, mak-\ning them scalable in prior studies. This would also\nhelp researchers in developing a new framework or\nhybrid model for big data analytics. Furthermore, the\nvarious evaluation metrics could be used as a bench-\nmark in evaluating any new technique for big data.\nCONCLUSION AND FUTURE WORK\nThe paper presents an overview of big data analytics,\nwith a special focus on data-intensive distributed\nmachine-learning algorithms for big data. The pres-\nent paper also performs a comparative analysis of the\nparallel data-intensive machine-learning algorithm on\noptimization and performance metrics. The design of\nscalable and fault tolerant learning systems have\nenabled us to address larger problems easily due to\nwhich big data analytics has drawn attention of\nmany researchers. This study would provide a base\nfor the researchers in this area as it provides a wide\ncollection of previous research.\nThis review is theoretical in nature. However,\nin the future, we would also like to implement scala-\nble machine-learning algorithms on real-world pro-\nblems, such as log analysis and social media analysis.\nBased on our survey, most of the previous studies\nhave focused on making traditional serial techniques\nscalable. A new technique built from scratch for big\ndata is missing in the literature, which could be con-\nsidered in future work. Designing a hybrid technique\nbased on MapReduce and MPI, utilizing the merits\nof both, is also worth researching in future. Visuali-\nzation plays an important role in big data analytics\nand has not been explored and is, therefore, also an\nimportant topic of exploration.\nREFERENCES\n1. Owais SS, Hussein NS. Extract \ufb01ve categories CPIVW\nfrom the 9V characteristics of the big data. Int J Adv\nComput Sci Appl 2016, 7:254\u2013258.\n2. Wu X, Zhu X, Wu GQ, Ding W. Data mining with\nbig\ndata.\nIEEE\nTrans\nKnowl\nData\nEng\n2014,\n26:97\u2013107.\n3. Chen H, Chiang RHL, Storey VC. Business intelligence\nand analytics: from big data to big impact. MIS Q\n2012, 36:1165\u20131188.\n4. Singh D, Reddy CK. A survey on platforms for big\ndata analytics. J Big Data 2014, 2:1\u201320. doi:10.1186/\ns40537.014.0008.6.\nWIREs Data Mining and Knowledge Discovery\nScalable machine-learning algorithms for big data analytics\nVolume 6, November/December 2016\n\u00a9 2016 John Wiley & Sons, Ltd\n211\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68]], "LIMITATIONS": ["LIMITATIONS\nThe purpose of this study is to provide a brief overview\nof big data analytics. This study has provided a com-\nprehensive literature review of data-intensive parallel\nmachine-learning algorithms for big data analytics. A\nnumber of important limitations of the study are:\n(a) The study has not considered parallel algo-\nrithms employing vertical scaling, such as\nGPUs, due to their limited scalability. The\nstudy has also not addressed parallel algo-\nrithms employing MPI.\n(b) The study has not covered graph-based analyt-\nical algorithms as they best suit the BSP (Bulk\nSynchronous\nParallel)\nmodel\nrather\nthan\nMapReduce or RDD.\n(c) The study has provided just a brief overview\nof various techniques and algorithms. How-\never, in order to see the full details regarding\nparticular techniques or algorithms, the corre-\nsponding paper may be referred.\n(d) The study is limited to only data-intensive\nbatch algorithms and does not consider online\nstreaming algorithms.\nRESEARCH IMPLICATIONS\nBig data analytics is evolving in nature, and its poten-\ntial has been exploited in almost every area and\nindustry, such as telecom, \ufb01nance, medicine, and gov-\nernment agencies, to produce better outcomes, lead-\ning to improved growth and success. Big data\nanalytics has been found to be signi\ufb01cant in various\nareas\nsuch\nas\nnational\ndevelopment,\nindustrial\nupgrade,\nscienti\ufb01c\nresearch,\ninterdisciplinary\nresearch, and better prediction.62 It has been used to\nsolve complex problems such as recommendation,\ncontent \ufb01ltering, fraud detection, and terrorist track-\ning. A typical example of big data analytics demon-\nstrating its power is an image recognition system,\nwhich took only 5 min to study 60,000 handwritten\ndigits on a Spark cluster running multiple deep learn-\ning jobs.63\nThis research would help the researchers work-\ning in the area of big data analytics to choose the\nright computational framework based on their under-\nlying\ncontext.\nThis\nresearch\nwould\nhelp\nother\nresearchers in understanding which machine-learning\ntechniques have been adapted to MapReduce, mak-\ning them scalable in prior studies. This would also\nhelp researchers in developing a new framework or\nhybrid model for big data analytics. Furthermore, the\nvarious evaluation metrics could be used as a bench-\nmark in evaluating any new technique for big data.\nCONCLUSION AND FUTURE WORK\nThe paper presents an overview of big data analytics,\nwith a special focus on data-intensive distributed\nmachine-learning algorithms for big data. The pres-\nent paper also performs a comparative analysis of the\nparallel data-intensive machine-learning algorithm on\noptimization and performance metrics. The design of\nscalable and fault tolerant learning systems have\nenabled us to address larger problems easily due to\nwhich big data analytics has drawn attention of\nmany researchers. This study would provide a base\nfor the researchers in this area as it provides a wide\ncollection of previous research.\nThis review is theoretical in nature. However,\nin the future, we would also like to implement scala-\nble machine-learning algorithms on real-world pro-\nblems, such as log analysis and social media analysis.\nBased on our survey, most of the previous studies\nhave focused on making traditional serial techniques\nscalable. A new technique built from scratch for big\ndata is missing in the literature, which could be con-\nsidered in future work. Designing a hybrid technique\nbased on MapReduce and MPI, utilizing the merits\nof both, is also worth researching in future. Visuali-\nzation plays an important role in big data analytics\nand has not been explored and is, therefore, also an\nimportant topic of exploration.\nREFERENCES\n1. Owais SS, Hussein NS. Extract \ufb01ve categories CPIVW\nfrom the 9V characteristics of the big data. Int J Adv\nComput Sci Appl 2016, 7:254\u2013258.\n2. Wu X, Zhu X, Wu GQ, Ding W. Data mining with\nbig\ndata.\nIEEE\nTrans\nKnowl\nData\nEng\n2014,\n26:97\u2013107.\n3. Chen H, Chiang RHL, Storey VC. Business intelligence\nand analytics: from big data to big impact. MIS Q\n2012, 36:1165\u20131188.\n4. Singh D, Reddy CK. A survey on platforms for big\ndata analytics. J Big Data 2014, 2:1\u201320. doi:10.1186/\ns40537.014.0008.6.\nWIREs Data Mining and Knowledge Discovery\nScalable machine-learning algorithms for big data analytics\nVolume 6, November/December 2016\n\u00a9 2016 John Wiley & Sons, Ltd\n211\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68]], "DISCUSSION": ["between output accuracy and speed. The\nvalues assigned are as follows:\nData Source\nValue Assigned\nNot measured\n0\nApproximate match\n1\nPerfect match\n2\n(f) Scalability: MapReduce or RDD have the\nbasic aim of providing scalability, which\nmeans that the system would be able to\ngracefully handle the growth in data or\nnumber of nodes. Accuracy may be reduced\nfor small datasets or for a large number of\ndata nodes due to network overhead and\ndata distribution. Thus, an optimal number\nof data nodes may be required. The values\nassigned are as follows:\nScalability\nValue Assigned\nAlmost linear scale-up with increase in the\nnumber of nodes and datasets\n0\nAlmost linear scale-up with a\nconsideration of imbalanced/skewed\ndata\n1\nSystem is scalable and detects lower\nand/or upper bound for parallelism\ndegree\n2\nA comparative analysis of the parallel data-\nintensive machine-learning algorithm based on the\nabove metrics is presented below in Table 2. There\nare various machine-learning toolkits such as MLib,\nMahout, scikiy-learn, MLpack, Flink, and Amazon\nMachine Learning available for various big data\ncomputational frameworks.61 These toolkits imple-\nment some of the machine-learning algorithms that\ncould also be initially leveraged by the researchers\nfor conducting their research.\nDISCUSSION\nMapReduce or RDD have been adopted by many\nresearchers due to its \ufb02exibility, scalability, and easi-\nness in handling data-intensive tasks. They help in\nachieving data parallelism on a large volume of data\nand may result in good speedup.\nA number of scalable machine-learning algo-\nrithms for big data have been discussed in this arti-\ncle. In general, a big data-learning algorithm, as\nprevalent from the literature review, executes a\nserial algorithm for local computation at various\nnodes/partitions in parallel, with the help of map-\npers, the results of which are aggregated by the\nreducer/s. This task is often known as an MR job.\nDepending on the learning technique or \ufb01ne tuning\nrequired. a single or multiple MR jobs can be exe-\ncuted before achieving a global view. The goal of all\nthe abovementioned algorithms is to make a serial\nalgorithm scalable by adapting it to run parallel on\ndistributed platforms.\nThe various algorithms presented take less time\nthan their serial counterparts. However, choosing the\ncomputational framework to employ may be decided\nby the context of problems. MapReduce is the best\n\ufb01t where the number of MR jobs is low, i.e., 1 or\n2. However, in case of an iterative task, a large num-\nber of MR jobs may be required, for which MapRe-\nduce may not be the best computational framework.\nIt has been found that for such cases, the Spark\nframework helps in achieving excellent speedup and\nbetter scalability due to in-memory computation and\nless overhead in setting up jobs for every iteration. It\nis further found that Spark performs better than\nMapReduce in almost all the cases due to its in-\nmemory computation, which reduces the network\nI/O cost. Nonetheless, Spark performs better until the\ntime it has enough memory to cache data.\nThis paper has also evaluated the various algo-\nrithms on optimization metrics such as sampling,\nintelligent partitioning, indexing, and special user-\nde\ufb01ned data structure that reduces the number of\nMR jobs or data shuf\ufb02ing, resulting in lower I/O\ncosts and better speedup. Another factor of impor-\ntance is imbalanced or skewed datasets, which may\ncause uneven loads on the data nodes. The considera-\ntion of imbalanced data results in load balancing and\nimproved scalability.\nThe various algorithms are further evaluated on\nvarious performance metrics. It was found that the\naccuracy of parallel data-intensive algorithms may be\nreduced due to small datasets or a large number of\ndata nodes. The advantage of parallelism may be\ndiminished due to network and data distribution\noverhead. A balance is needed between speed and\naccuracy, which could be achieved by selecting an\noptimal number of data nodes.\nThe power and value of big data analytics pro-\nvides a wealth of information. However, while\ndesigning or selecting a scalable machine-learning\nalgorithms for big data, measures should be taken to\nreduce the I/O and network communication cost.\nAnother issue that should also be considered is the\nhandling of false positives or output validation.\nOverview\nwires.wiley.com/dmkd\n208\n\u00a9 2016 John Wiley & Sons, Ltd\nVolume 6, November/December 2016\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68]], "Performance Metrics": ["the varying size of data for each iteration, pro-\nviding load balancing.34 Thus, an optimal par-\ntitioning may help in handling imbalanced\ndata skew and load balancing.\n(d) Special Data Structure: Big data implies a huge\ndataset. Learning or overall computation of a\nmachine-learning algorithm for big data may\nrequire multiple MR jobs, resulting in increased\nI/O costs. It may also be required to share infor-\nmation among nodes, entailing a high commu-\nnication cost. Designing a special data structure\nto hold speci\ufb01c information may reduce the\ncomputational cost and would help in some\nform of data caching or data aggregation.\n(e) In-memory computation: In-memory computa-\ntion helps to cache intermediate data in main\nmemory\nand\nperform\ncomputation.\nThis\nreduces the number of disk I/O required after\nevery step of a typical MR job.\n(f) Asynchronous execution: A typical MR job is\nsynchronous in nature, which implies that all\nthe reducers must \ufb01nish before a new map\ncould be started. This results in the ineffective\nutilization of resources.\nPapers were evaluated for the abovementioned optimi-\nzation metrics, as presented in Table 2. Papers are\nassigned a value 1 in case the metric is used and a value\n0 in case the metric is not used in the algorithm.\nPerformance Metrics\nPerformance metrics are used to compare the perfor-\nmance of the algorithm against its serial counterpart.\nPapers were evaluated on the following mentioned\nperformance metrics and is presented in Table 2.\n(a) Data source validation: The data are used to\nvalidate the algorithm. A synthetic dataset may\nresult in poor validation but may help in case\nno real dataset is available or to test for speci\ufb01c\ntest cases. The values assigned are as follows:\nData Source\nValue Assigned\nSynthetic datasets\n0\nReal-world datasets\n1\nBoth (Synthetic datasets + Real-world\ndatasets)\n2\n(b) Comparative analysis: It is used to check\nwhether\nthe\nresults\nobtained\nhave\nbeen\ncompared with other techniques. The values\nassigned are as follows:\nComparative Analysis\nValue Assigned\nNo comparison\n0\nComparison with the base technique or\nsimilar serial technique\n1\nComparison among parallel techniques\n(MapReduce vs Spark)\n2\n(c) Number of MR jobs: It is a measure of the\nnumber of MR jobs required to complete\nthe algorithm. The number of MR jobs\ndetermines the amount of I/O cost as every\ntime data needs to be written to disk and\nread from disk. More number of MR jobs\nmay also result in increased network com-\nmunication costs. Spark would help to\nachieve better performance in case of multi-\nple MR jobs due to in-memory computa-\ntion. The values assigned are as follows:\nNo. of MR Jobs\nValue Assigned\nLow\n0\nHigh\n1\n(d) Speedup: Speedup determines the reduction\nin time to compute or train by parallel algo-\nrithm as compared to its serial counterpart.\nParallelism may result in increased speed,\nwhich may not be always linear due to high\nnetwork\ncommunication\ncosts\namong\nnodes. The values assigned are as follows:\nSpeedup\nValue Assigned\nGood speedup due to MapReduce\n0\nExcellent speedup in case of MapReduce\ndue to optimizations metric employed\n1\nExcellent speedup due to in-memory\ncomputation such as Spark\n2\n(e) Accuracy: Accuracy determines the quality\nof data output as compared to its serial\ncounterpart. The parallel and distributed\nbig\ndata\nalgorithms\nmay\nresult\nin\nthe\ndecrease of output accuracy due to data dis-\ntribution.\nA\nbalance\nmay\nbe\nneeded\nWIREs Data Mining and Knowledge Discovery\nScalable machine-learning algorithms for big data analytics\nVolume 6, November/December 2016\n\u00a9 2016 John Wiley & Sons, Ltd\n207\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68]], "Optimization Metrics": ["\ufb01le directly. Classi\ufb01ers on multiple views are learnt\nlocally using the mappers on each node individually,\nand the results are combined to generate a global\nmodel using a bidirectional reducer.\nActive learning is another semisupervised learn-\ning technique in which learning algorithms interac-\ntively query the source for a certain type of instance\nto obtain output, reducing learning effort. Zhao\net al.54 have proposed a Punishing-Characterized\nActive Learning Back-Propagation (PCAL-BP) neural\nnetwork algorithm for big data to improve the learn-\ning ef\ufb01ciency of the BP model.\nReinforcement Learning\nReinforcement learning continuously learns in an\nenvironment by trial and error. It discovers the actions\nthat yield the greatest rewards to make better deci-\nsions. The Markov Decision Process and Q-Learning\nare two well-known examples of reinforcement learn-\ning. Reinforcement learning has been employed in\napplications such as gaming and robotics.\nLi and Schuurmans55 applied the MapReduce\nframework for methods such as policy evaluation, pol-\nicy iteration, and value iteration by distributing the\ncomputation involved in large matrix multiplications.\nParallelism was used to speedup large matrix opera-\ntions but not to parallelize the learning. To the best of\nour knowledge, the work of Li and Schuurmans55 is\nthe only paper that has used MapReduce for reinforce-\nment learning of linear representations. Parallel rein-\nforcement learning in which agents learn in parallel to\nachieve speedup convergence such as Bayesian Rein-\nforcement Learning56 are being proposed in literature.\nDeep Learning\nDeep learning refers to machine-learning techniques\nthat use supervised and/or unsupervised strategies to\nautomatically learn hierarchical representations in\ndeep architectures for classi\ufb01cation.57 Deep learning\nhas been employed in a number of applications such\nas image search, threat detection, fraud detection,\nsentiment analysis, and log analysis. A Deep Belief\nNetwork (DBN) with Restricted Boltzman Machine\n(RBM) is one of the most widely used frameworks\nfor deep learning. RBMs are used to generate a train-\ning model in an unsupervised manner, which is used\nby DBN subsequently for supervised classi\ufb01cation or\n\ufb01ne tuning. Zhang and Chen58 have proposed a dis-\ntributed learning paradigm using MapReduce. Pre-\ntraining is achieved by distributed learning, which\ninvolves stacking a series of distributions of RBMs\nfollowed by distributed BP for \ufb01ne tuning using the\nMapReduce framework.\nMetrics Evaluation\nThe design of scalable learning systems has enabled\nus to address larger problems easily. Algorithms\nemploying MapReduce or RDD may take less train-\ning time and may result in an increase of speed on a\nhuge dataset compared to its serial counterpart.\nDesigning a big data algorithm entails two main\nchallenges, which are also pointed out by Cordeiro\net al.35 in his research. The two main challenges are\nto minimize the I/O cost and network communica-\ntion cost. Researchers have employed various ways\nto overcome these challenges and to achieve high per-\nformance. The parallel data-intensive machine algo-\nrithm covered in previous section could be thus\ncompared on various evaluation metrics. The evalua-\ntion metrics could be divided in two categories,\nnamely, optimization metrics and performance met-\nrics. The brief description of each is as follows:\nOptimization Metrics\nOptimization metrics refers to the measures that can be\nused to improve the overall performance by reducing\nI/O cost or network communication cost or both. They\nhelp in achieving objective such as load balancing,\nresource utilization, and dimensionality reduction. The\nvarious optimization criteria that could be employed\nby distributed big data algorithms are:-\n(a) Sampling: Sampling refers to selecting a subset\nof data from the entire dataset. This helps to\nachieve similar accuracy with reduced network\ncommunication\ncosts and\nprocessing\ntime.\nSampling also helps to handle data skewness.\n(b) Indexing: Indexing data may help in selecting\nspeci\ufb01c data or removing unnecessary data\nfrom processing, resulting in reduced I/O cost.\n(c) Intelligent partitioning: Data among different\nnodes should not be partitioned randomly as it\nmay lead to increased data shuf\ufb02ing among\nnodes. In order to reduce the communication\ncost, an intelligent data partitioning strategy\nmay be adopted. Mappers distribute the out-\nput to reducers using hashing. Data skewness\ncan happen at a reducer when one reducer is\nheavily loaded or is taking more time to com-\npute compared to others. A new job cannot\nstart until all reducers have \ufb01nished, resulting\nin the improper utilization of resources. This\ncan be reduced by exploiting data locality and\nusing\na\nload-aware\npartitioning\nstrategy,\ninstead\nof\nblind\nhashing\nfor\ndistribution\namong reducers.59,60 A dynamic data parti-\ntioning method can also continuously optimize\nOverview\nwires.wiley.com/dmkd\n206\n\u00a9 2016 John Wiley & Sons, Ltd\nVolume 6, November/December 2016\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68]], "Metrics Evaluation": ["\ufb01le directly. Classi\ufb01ers on multiple views are learnt\nlocally using the mappers on each node individually,\nand the results are combined to generate a global\nmodel using a bidirectional reducer.\nActive learning is another semisupervised learn-\ning technique in which learning algorithms interac-\ntively query the source for a certain type of instance\nto obtain output, reducing learning effort. Zhao\net al.54 have proposed a Punishing-Characterized\nActive Learning Back-Propagation (PCAL-BP) neural\nnetwork algorithm for big data to improve the learn-\ning ef\ufb01ciency of the BP model.\nReinforcement Learning\nReinforcement learning continuously learns in an\nenvironment by trial and error. It discovers the actions\nthat yield the greatest rewards to make better deci-\nsions. The Markov Decision Process and Q-Learning\nare two well-known examples of reinforcement learn-\ning. Reinforcement learning has been employed in\napplications such as gaming and robotics.\nLi and Schuurmans55 applied the MapReduce\nframework for methods such as policy evaluation, pol-\nicy iteration, and value iteration by distributing the\ncomputation involved in large matrix multiplications.\nParallelism was used to speedup large matrix opera-\ntions but not to parallelize the learning. To the best of\nour knowledge, the work of Li and Schuurmans55 is\nthe only paper that has used MapReduce for reinforce-\nment learning of linear representations. Parallel rein-\nforcement learning in which agents learn in parallel to\nachieve speedup convergence such as Bayesian Rein-\nforcement Learning56 are being proposed in literature.\nDeep Learning\nDeep learning refers to machine-learning techniques\nthat use supervised and/or unsupervised strategies to\nautomatically learn hierarchical representations in\ndeep architectures for classi\ufb01cation.57 Deep learning\nhas been employed in a number of applications such\nas image search, threat detection, fraud detection,\nsentiment analysis, and log analysis. A Deep Belief\nNetwork (DBN) with Restricted Boltzman Machine\n(RBM) is one of the most widely used frameworks\nfor deep learning. RBMs are used to generate a train-\ning model in an unsupervised manner, which is used\nby DBN subsequently for supervised classi\ufb01cation or\n\ufb01ne tuning. Zhang and Chen58 have proposed a dis-\ntributed learning paradigm using MapReduce. Pre-\ntraining is achieved by distributed learning, which\ninvolves stacking a series of distributions of RBMs\nfollowed by distributed BP for \ufb01ne tuning using the\nMapReduce framework.\nMetrics Evaluation\nThe design of scalable learning systems has enabled\nus to address larger problems easily. Algorithms\nemploying MapReduce or RDD may take less train-\ning time and may result in an increase of speed on a\nhuge dataset compared to its serial counterpart.\nDesigning a big data algorithm entails two main\nchallenges, which are also pointed out by Cordeiro\net al.35 in his research. The two main challenges are\nto minimize the I/O cost and network communica-\ntion cost. Researchers have employed various ways\nto overcome these challenges and to achieve high per-\nformance. The parallel data-intensive machine algo-\nrithm covered in previous section could be thus\ncompared on various evaluation metrics. The evalua-\ntion metrics could be divided in two categories,\nnamely, optimization metrics and performance met-\nrics. The brief description of each is as follows:\nOptimization Metrics\nOptimization metrics refers to the measures that can be\nused to improve the overall performance by reducing\nI/O cost or network communication cost or both. They\nhelp in achieving objective such as load balancing,\nresource utilization, and dimensionality reduction. The\nvarious optimization criteria that could be employed\nby distributed big data algorithms are:-\n(a) Sampling: Sampling refers to selecting a subset\nof data from the entire dataset. This helps to\nachieve similar accuracy with reduced network\ncommunication\ncosts and\nprocessing\ntime.\nSampling also helps to handle data skewness.\n(b) Indexing: Indexing data may help in selecting\nspeci\ufb01c data or removing unnecessary data\nfrom processing, resulting in reduced I/O cost.\n(c) Intelligent partitioning: Data among different\nnodes should not be partitioned randomly as it\nmay lead to increased data shuf\ufb02ing among\nnodes. In order to reduce the communication\ncost, an intelligent data partitioning strategy\nmay be adopted. Mappers distribute the out-\nput to reducers using hashing. Data skewness\ncan happen at a reducer when one reducer is\nheavily loaded or is taking more time to com-\npute compared to others. A new job cannot\nstart until all reducers have \ufb01nished, resulting\nin the improper utilization of resources. This\ncan be reduced by exploiting data locality and\nusing\na\nload-aware\npartitioning\nstrategy,\ninstead\nof\nblind\nhashing\nfor\ndistribution\namong reducers.59,60 A dynamic data parti-\ntioning method can also continuously optimize\nOverview\nwires.wiley.com/dmkd\n206\n\u00a9 2016 John Wiley & Sons, Ltd\nVolume 6, November/December 2016\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", []], "Deep Learning": ["\ufb01le directly. Classi\ufb01ers on multiple views are learnt\nlocally using the mappers on each node individually,\nand the results are combined to generate a global\nmodel using a bidirectional reducer.\nActive learning is another semisupervised learn-\ning technique in which learning algorithms interac-\ntively query the source for a certain type of instance\nto obtain output, reducing learning effort. Zhao\net al.54 have proposed a Punishing-Characterized\nActive Learning Back-Propagation (PCAL-BP) neural\nnetwork algorithm for big data to improve the learn-\ning ef\ufb01ciency of the BP model.\nReinforcement Learning\nReinforcement learning continuously learns in an\nenvironment by trial and error. It discovers the actions\nthat yield the greatest rewards to make better deci-\nsions. The Markov Decision Process and Q-Learning\nare two well-known examples of reinforcement learn-\ning. Reinforcement learning has been employed in\napplications such as gaming and robotics.\nLi and Schuurmans55 applied the MapReduce\nframework for methods such as policy evaluation, pol-\nicy iteration, and value iteration by distributing the\ncomputation involved in large matrix multiplications.\nParallelism was used to speedup large matrix opera-\ntions but not to parallelize the learning. To the best of\nour knowledge, the work of Li and Schuurmans55 is\nthe only paper that has used MapReduce for reinforce-\nment learning of linear representations. Parallel rein-\nforcement learning in which agents learn in parallel to\nachieve speedup convergence such as Bayesian Rein-\nforcement Learning56 are being proposed in literature.\nDeep Learning\nDeep learning refers to machine-learning techniques\nthat use supervised and/or unsupervised strategies to\nautomatically learn hierarchical representations in\ndeep architectures for classi\ufb01cation.57 Deep learning\nhas been employed in a number of applications such\nas image search, threat detection, fraud detection,\nsentiment analysis, and log analysis. A Deep Belief\nNetwork (DBN) with Restricted Boltzman Machine\n(RBM) is one of the most widely used frameworks\nfor deep learning. RBMs are used to generate a train-\ning model in an unsupervised manner, which is used\nby DBN subsequently for supervised classi\ufb01cation or\n\ufb01ne tuning. Zhang and Chen58 have proposed a dis-\ntributed learning paradigm using MapReduce. Pre-\ntraining is achieved by distributed learning, which\ninvolves stacking a series of distributions of RBMs\nfollowed by distributed BP for \ufb01ne tuning using the\nMapReduce framework.\nMetrics Evaluation\nThe design of scalable learning systems has enabled\nus to address larger problems easily. Algorithms\nemploying MapReduce or RDD may take less train-\ning time and may result in an increase of speed on a\nhuge dataset compared to its serial counterpart.\nDesigning a big data algorithm entails two main\nchallenges, which are also pointed out by Cordeiro\net al.35 in his research. The two main challenges are\nto minimize the I/O cost and network communica-\ntion cost. Researchers have employed various ways\nto overcome these challenges and to achieve high per-\nformance. The parallel data-intensive machine algo-\nrithm covered in previous section could be thus\ncompared on various evaluation metrics. The evalua-\ntion metrics could be divided in two categories,\nnamely, optimization metrics and performance met-\nrics. The brief description of each is as follows:\nOptimization Metrics\nOptimization metrics refers to the measures that can be\nused to improve the overall performance by reducing\nI/O cost or network communication cost or both. They\nhelp in achieving objective such as load balancing,\nresource utilization, and dimensionality reduction. The\nvarious optimization criteria that could be employed\nby distributed big data algorithms are:-\n(a) Sampling: Sampling refers to selecting a subset\nof data from the entire dataset. This helps to\nachieve similar accuracy with reduced network\ncommunication\ncosts and\nprocessing\ntime.\nSampling also helps to handle data skewness.\n(b) Indexing: Indexing data may help in selecting\nspeci\ufb01c data or removing unnecessary data\nfrom processing, resulting in reduced I/O cost.\n(c) Intelligent partitioning: Data among different\nnodes should not be partitioned randomly as it\nmay lead to increased data shuf\ufb02ing among\nnodes. In order to reduce the communication\ncost, an intelligent data partitioning strategy\nmay be adopted. Mappers distribute the out-\nput to reducers using hashing. Data skewness\ncan happen at a reducer when one reducer is\nheavily loaded or is taking more time to com-\npute compared to others. A new job cannot\nstart until all reducers have \ufb01nished, resulting\nin the improper utilization of resources. This\ncan be reduced by exploiting data locality and\nusing\na\nload-aware\npartitioning\nstrategy,\ninstead\nof\nblind\nhashing\nfor\ndistribution\namong reducers.59,60 A dynamic data parti-\ntioning method can also continuously optimize\nOverview\nwires.wiley.com/dmkd\n206\n\u00a9 2016 John Wiley & Sons, Ltd\nVolume 6, November/December 2016\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", []], "Reinforcement Learning": ["\ufb01le directly. Classi\ufb01ers on multiple views are learnt\nlocally using the mappers on each node individually,\nand the results are combined to generate a global\nmodel using a bidirectional reducer.\nActive learning is another semisupervised learn-\ning technique in which learning algorithms interac-\ntively query the source for a certain type of instance\nto obtain output, reducing learning effort. Zhao\net al.54 have proposed a Punishing-Characterized\nActive Learning Back-Propagation (PCAL-BP) neural\nnetwork algorithm for big data to improve the learn-\ning ef\ufb01ciency of the BP model.\nReinforcement Learning\nReinforcement learning continuously learns in an\nenvironment by trial and error. It discovers the actions\nthat yield the greatest rewards to make better deci-\nsions. The Markov Decision Process and Q-Learning\nare two well-known examples of reinforcement learn-\ning. Reinforcement learning has been employed in\napplications such as gaming and robotics.\nLi and Schuurmans55 applied the MapReduce\nframework for methods such as policy evaluation, pol-\nicy iteration, and value iteration by distributing the\ncomputation involved in large matrix multiplications.\nParallelism was used to speedup large matrix opera-\ntions but not to parallelize the learning. To the best of\nour knowledge, the work of Li and Schuurmans55 is\nthe only paper that has used MapReduce for reinforce-\nment learning of linear representations. Parallel rein-\nforcement learning in which agents learn in parallel to\nachieve speedup convergence such as Bayesian Rein-\nforcement Learning56 are being proposed in literature.\nDeep Learning\nDeep learning refers to machine-learning techniques\nthat use supervised and/or unsupervised strategies to\nautomatically learn hierarchical representations in\ndeep architectures for classi\ufb01cation.57 Deep learning\nhas been employed in a number of applications such\nas image search, threat detection, fraud detection,\nsentiment analysis, and log analysis. A Deep Belief\nNetwork (DBN) with Restricted Boltzman Machine\n(RBM) is one of the most widely used frameworks\nfor deep learning. RBMs are used to generate a train-\ning model in an unsupervised manner, which is used\nby DBN subsequently for supervised classi\ufb01cation or\n\ufb01ne tuning. Zhang and Chen58 have proposed a dis-\ntributed learning paradigm using MapReduce. Pre-\ntraining is achieved by distributed learning, which\ninvolves stacking a series of distributions of RBMs\nfollowed by distributed BP for \ufb01ne tuning using the\nMapReduce framework.\nMetrics Evaluation\nThe design of scalable learning systems has enabled\nus to address larger problems easily. Algorithms\nemploying MapReduce or RDD may take less train-\ning time and may result in an increase of speed on a\nhuge dataset compared to its serial counterpart.\nDesigning a big data algorithm entails two main\nchallenges, which are also pointed out by Cordeiro\net al.35 in his research. The two main challenges are\nto minimize the I/O cost and network communica-\ntion cost. Researchers have employed various ways\nto overcome these challenges and to achieve high per-\nformance. The parallel data-intensive machine algo-\nrithm covered in previous section could be thus\ncompared on various evaluation metrics. The evalua-\ntion metrics could be divided in two categories,\nnamely, optimization metrics and performance met-\nrics. The brief description of each is as follows:\nOptimization Metrics\nOptimization metrics refers to the measures that can be\nused to improve the overall performance by reducing\nI/O cost or network communication cost or both. They\nhelp in achieving objective such as load balancing,\nresource utilization, and dimensionality reduction. The\nvarious optimization criteria that could be employed\nby distributed big data algorithms are:-\n(a) Sampling: Sampling refers to selecting a subset\nof data from the entire dataset. This helps to\nachieve similar accuracy with reduced network\ncommunication\ncosts and\nprocessing\ntime.\nSampling also helps to handle data skewness.\n(b) Indexing: Indexing data may help in selecting\nspeci\ufb01c data or removing unnecessary data\nfrom processing, resulting in reduced I/O cost.\n(c) Intelligent partitioning: Data among different\nnodes should not be partitioned randomly as it\nmay lead to increased data shuf\ufb02ing among\nnodes. In order to reduce the communication\ncost, an intelligent data partitioning strategy\nmay be adopted. Mappers distribute the out-\nput to reducers using hashing. Data skewness\ncan happen at a reducer when one reducer is\nheavily loaded or is taking more time to com-\npute compared to others. A new job cannot\nstart until all reducers have \ufb01nished, resulting\nin the improper utilization of resources. This\ncan be reduced by exploiting data locality and\nusing\na\nload-aware\npartitioning\nstrategy,\ninstead\nof\nblind\nhashing\nfor\ndistribution\namong reducers.59,60 A dynamic data parti-\ntioning method can also continuously optimize\nOverview\nwires.wiley.com/dmkd\n206\n\u00a9 2016 John Wiley & Sons, Ltd\nVolume 6, November/December 2016\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", []], "Semisupervised Learning": ["Bayes approach uses joint probability to estimate the\nprobabilities\nover\na\nset\nof classes. It has been\nemployed in applications such as text classi\ufb01cation,\nspam \ufb01ltering, and sentiment analysis. Dai and Sun45\nhave implemented the Naive Bayes text classi\ufb01cation\nalgorithm based on a rough set using MapReduce.\nThe authors have combined a rough set theory in soft\ncomputing with Naive Bayes to improve its limit of\nindependence, reducing bias. It selects a closet approx-\nimate independent attributes subset. In the training\nphase, an MR job is used to normalize the weighted\nfrequency of each key. The testing phase is used to\npredict the output of test records. Liu et al.46 have also\nimplemented a MapReduce version of the Naive Bayes\nclassi\ufb01er for sentiment analysis.\nSupport vector machines (SVM) are a classi\ufb01ca-\ntion and regression model that attempts to \ufb01nd the\nbest possible surface to separate classes in training\nsamples. The learning ability of SVM is independent\nof the dimensionality of feature space, which makes\nthem a suitable candidate for achieving parallelism\nwith MapReduce. LibSVM is one of the most widely\nadopted SVMs. Sun and Fox47 have proposed a Par-\nallel LibSVM on MapReduce to improve the training\ntime. In this model, training samples are distributed\ninto subsections, which are trained in parallel by\nmappers using LibSVM. Support vectors from the\nmap jobs are collected by the reducer and fed back\nas input until all sub-SVMs are combined into one\nSVM. Based on the parallel SVM model on MapRe-\nduce (PSMR), Xu et al.48 have proposed an e-mail\nclassi\ufb01cation model using the Enron dataset. Simi-\nlarly, Khairnar and Kinikar49 have proposed senti-\nment analysis-based mining and summarizing using\nparallel SVM using MapReduce (MRSVM).\nArti\ufb01cal neural networks (ANNs) are widely\nadopted for classi\ufb01cation and regression tasks. The\nback-propagation neural network (BPNN) is the most\ncommonly encountered ANN. BPNN is a multilayer\nfeed-forward network. It adjusts the classi\ufb01cation para-\nmeters\nby\nemploying\nan\nerror\nback-propagation\n(BP) technique until its parameters are attuned to all\ninput instances.50 The PBPNN proposed by Liu et al.50\npresents a parallel version of BPNN using MapReduce\nand Spark, which distributed the iterations and compu-\ntation of BPNN in parallel to achieve speedup. PBPNN\ndistributes the data to mappers for parallel processing.\nEach mapper locally tunes subsets of data using BPNN\niteratively. The outputs of all mappers are then ensem-\nble by the reducer or joiner to generate classi\ufb01cation\nrules. Classi\ufb01cation accuracy is maintained by merging\nweak classi\ufb01ers into a strong classi\ufb01er with the help of\nensemble techniques such as bootstrapping and major-\nity voting. Bootstrapping helps in maintaining original\ndata information in data subsets, and major voting\nhelps in generating a strong classi\ufb01er. The authors have\nperformed the experiment on MapReduce, Haloop,\nand Spark computing frameworks. It was found that\namong all, MapReduce performs the worst, with a\nslight improvement in the case of Haloop, and Spark\nperforms the best due to in-memory computation. Sim-\nilarly, Zhang and Xiao51 have implemented a parallel\nmultilayered neural network employing a BP training\nalgorithm on MapReduce (MRBP) on cloud comput-\ning clusters for speedup.\nMultiple linear regression is a widely adopted\nregression technique that has a very high training\ntime and may fail in case of a large dataset. Rehab\nand Boufar\u00e8s52 have proposed multiple linear regres-\nsion on MapReduce (MLR-MR) for speedup and\nscalability over a large dataset. MLR-MR distributes\nthe QR decomposition and ordinary least squares\ncomputation in parallel using MapReduce to estimate\nthe relationship between the predictor and the target\nvariables. MLR-MR has three steps. In the \ufb01rst step,\nthe matrix is divided into small blocks. In the second\nstep, mappers compute a local QR factorization for\neach such block, and in the third step, the results of\nall mappers (Qi results) are aggregated to have \ufb01nal\ncoef\ufb01cient results. Authors have showed that MLR-\nMR is able to train large data and effectively solves\nthe out-of-memory problem.\nSemisupervised Learning\nSemisupervised learning is used where the data con-\ntains small labeled data and large amount of unla-\nbeled data. It uses labeled data and unlabeled data\nfor training. Semisupervised learning is well suited to\nbig data in which majority of data may be unlabeled,\nand the cost of labeling all data may be too high.\nCotraining and active learning are the two important\ntechniques employed for semisupervised learning.\nCotraining is a semisupervised learning tech-\nnique in which each example is partitioned into two\ndistinct views and where two views are independently\nsuf\ufb01cient. It learns to separate classi\ufb01ers for each\nview, and then, the most con\ufb01dent prediction of each\nclassi\ufb01er on unlabeled data is used for labeled trained\ndata. Hariharan and Shivshankar53 have presented a\ncotraining-based multiview learning algorithm under\nsemisupervised\nconditions\non\nMapReduce.\nThe\nauthors have also proposed the use of data structures\nsuch as mapping table, label \ufb01le, and bidirectional\nreducers in order to avoid broadcasting of new labels\nto all nodes in the MapReduce computation. A map-\nping table contains partition details, and a label \ufb01le\ncontains the labels of data points in each partition.\nBidirectional reducers update the labels in the label\nWIREs Data Mining and Knowledge Discovery\nScalable machine-learning algorithms for big data analytics\nVolume 6, November/December 2016\n\u00a9 2016 John Wiley & Sons, Ltd\n205\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68]], "Supervised Learning": ["overhead in setting and tearing of jobs for each\niteration.\nSpectral clustering relies on Eigen decomposi-\ntions of af\ufb01nity, dissimilarity, or kernel matrices to\npartition data into clusters.32 It has been employed in\nvarious applications, such as speech recognition and\nimage processing. Power iteration clustering (PIC)\nreduces the computational complexity of spectral\nclustering.32 PIC replaces the Eigen decomposition of\nthe similarity matrix required by spectral clustering\ninto a small number of iterative matrix\u2013vector multi-\nplications. Yan et al.32 have proposed a parallel\npower iteration clustering (p-PIC) using MPI for\nhandling large data, which was further implemented\nby Jayalatchumy and Thambidurai33 on MapReduce\ndue to its better fault tolerance ability. MapReduce is\nused for af\ufb01nity matrix calculations in parallel with\nthe help of mappers, the results of which are globally\naggregated by the reducer. Authors have showed that\nthe accuracy in producing the clusters is almost the\nsame as using a MapReduce framework.\nSUB-CLU is a subspace clustering algorithm\nthat aims to \ufb01nds clusters hidden in subsets of the\noriginal feature space by using the DBSCAN algo-\nrithm and is employed in high-dimensional datasets.\nSubspace clustering has been employed in a number\nof applications, such as sensor network, bioinformat-\nics, network traf\ufb01c, image processing, and compres-\nsion. Zhu et al.34 have proposed CLUS, which has\nimplemented a subspace clustering algorithm on top\nof Spark to achieve scalability and parallelism. CLUS\nspeeds up the SUB-CLU algorithm by executing mul-\ntiple density-based clustering (DBSCAN) tasks in par-\nallel.\nDBSCAN\nis\nperformed\ninitially\non\none-\ndimensional\nsubspace\nfollowed\nby\nhigher-\ndimensional subspaces, excluding noise from lower\nsubspaces.\nThe\nprocess\nends\nwhen\nno\nhigher-\ndimensional subspace could be generated. It also\nemploys a data partitioning to induce data locality.\nCordeiro et al.35 have proposed another subcluster-\ning algorithm on MapReduce, BoW (Best of both\nWorlds), that automatically spots bottlenecks and\npicks a good strategy to balance the I/O and network\ncost. It can employ most of the serial clustering\nmethod as a plug-in. Authors have proposed two\nmethods, ParC (Parallel Clustering) and SnI (Sample\nand Ignore). ParC performs data partitioning and\nthen \ufb01nds clusters using MapReduce by employing\nany serial clustering algorithm. SnI performs sam-\npling \ufb01rst to get rough clusters and then clusters the\nremaining points using ParC. ParC is executed on the\nwhole dataset only once, minimizing disk access. SnI\nperforms two MR jobs to reduce communication cost\nat the expense of higher I/O cost. ParC and SnI have\ntheir own merits, the selection of which is determined\nby a cost-based optimization technique. BoW calcu-\nlated the cost of both algorithms on the basis of\nparameters such as \ufb01le size, network speed, disk\nspeed, start-up cost, and plug-in cost. The calculated\ncost is then used to select the best algorithm among\nthe two. However, BoW is a hard clustering method,\nwhich may not work well for overlapping clusters.\nCoclustering, or bi-clustering, or simultaneous\nclustering is an unsupervised learning technique that\nsimultaneously clusters objects and features, or in\nother words, it allows parallel clustering of the rows\nand columns of a matrix. In this case, clustering is per-\nformed row-wise, keeping column assignments \ufb01xed\nto \ufb01nd the best group. The same process is executed,\nin parallel, column-wise, keeping row assignments\n\ufb01xed. It has been employed in a number of applica-\ntions, such as text mining, collaborative \ufb01ltering, bio-\ninformatics, and graph mining. Papadimitriou and\nSun36 have proposed a distributed coclustering model,\nDisCo, with MapReduce. In MapReduce distributed\nprocessing, initially, global parameters consisting of\nadjacency matrix, row vector, and column vector are\nformed and broadcasted. Then, mappers perform the\nlocal clustering by reading rows, which are fed to the\nreducer to perform global clustering. The process is\nrepeated till the cost function stops decreasing (the\nsame process is also followed for column-wise).\nSupervised Learning\nSupervised learning infers a function from labeled\ntrained data, which are used further for veri\ufb01cation\nand classi\ufb01cation. The two broad subcategories in\nsupervised learning are classi\ufb01cation and regression.\n(a) Classi\ufb01cation: Classi\ufb01cation is a supervised\nlearning technique that is used to determine\nthe class of variables or to predict future\ntrends. The classi\ufb01cation algorithm usually\nconsists of a training phase to construct a\ntraining model and a testing phase for the veri-\n\ufb01cation. Classi\ufb01cation has a number of appli-\ncations,\nsuch\nas\nspam\n\ufb01ltering,\nimage\nrecognition, speech recognition, text categori-\nzation, and fraud detection.\n(b) Regression: Regression is also a supervised\nlearning technique used for prediction. Regres-\nsion predicts a value from a continuous data-\nset, whereas classi\ufb01cation is used with a\ncategorical dataset. The variable to be pre-\ndicted is known as the dependent variable.\nThere is only one dependent variable in regres-\nsion. The variables used for modeling or\nWIREs Data Mining and Knowledge Discovery\nScalable machine-learning algorithms for big data analytics\nVolume 6, November/December 2016\n\u00a9 2016 John Wiley & Sons, Ltd\n203\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68]], "Unsupervised Learning": ["other variants of MapReduce. This section presents a\nliterature review of data-intensive parallel machine-\nlearning algorithms to see how they are using\nMapReduce or Spark to achieve the desired objec-\ntive. Several articles have also achieved data parallel-\nism\nwith\nthe\nhelp\nof\nMapReduce\nand\nGPUs.\nHowever, the use of GPUs may not be fully scalable\nto big data, due to which they are not considered in\nthe literature review.\nThe algorithms are categorized into various\nmachine-learning classes, which include unsupervised\nlearning, supervised learning, semi-supervised learning,\nand reinforcement learning, including deep learning.\nUnsupervised Learning\nUnsupervised learning \ufb01nds hidden structure in unla-\nbeled data. Clustering is one of the important forms\nof unsupervised learning. Clustering partitions the\ndatasets into clusters or groups such that intracluster\nsimilarity between the data points is maximum, and\nintercluster similarity is minimum. Clustering has a\nnumber of applications, such as customer segmenta-\ntion, document retrieval, image segmentation, and\npattern classi\ufb01cation. Several clustering algorithms\nhave been proposed for the MapReduce framework.\nA brief description of some of them is presented\nbelow.\nK-means clustering has been one of the most\npopular clustering algorithms. Zhao et al.25 proposed\na parallel version of the k-means (PK-means) algorithm\nbased on MapReduce. Distance calculation is the most\nexpensive task in the k-means algorithm and could be\nexecuted independently for various data points in par-\nallel. Authors have achieved speedup by employing\nMapReduce for parallelism. PK-means uses three func-\ntions, map, combine, and reduce. The map function\nassigns each data point to its closest center. The com-\nbine function then aggregates the intermediate results\nof the map function and passes it to the reducer. The\nreduce function updates the centroids. This MR cycle\nis performed iteratively until termination condition has\nbeen met. A number of MapReduce (MR) jobs would\ninvolve immense I/O activity, which could be an issue\nfor large datasets. Thomas and Annappa26 have also\nemployed parallel k-means MapReduce clustering\nalgorithms for the prediction of optimal paths in self-\naware Mobile Ad-Hoc Networks.\nThe biggest drawback in k-means is the selec-\ntion of initial centroids. K-means++27 is a modi\ufb01ca-\ntion of k-means that selects subsequent centroids\n(after the \ufb01rst centroid, which is selected at random)\nbased on probability proportional to overall error.\nBahmani et al.28 have proposed a scalable k-means++\n(K-means||) on MapReduce. K-means|| samples k\npoints per iteration with the help of mappers in par-\nallel, which are sent to reducers. The process is\nrepeated for O(log n) iterations, resulting in O(klogn)\npoints as candidates. These candidates\u2019 points are\nused to form k clusters using k-means++. Authors\nhave showed that k-means|| leads to faster conver-\ngence time for iteration.\nDensity-based\nclustering\nalgorithms\n\ufb01nd\nthe\nclusters based on the region of density. It identi\ufb01es\ndense clusters of points, allowing it to learn clusters of\narbitrary shapes, and helps in identifying the outliers.\nUnlike k-means, they do not need to know the num-\nber of clusters in advance. DBSCAN is a well-known\ndensity-based\nclustering\nalgorithm\nand\nhas\nbeen\nemployed in a number of applications, such as image\nprocessing pattern recognition and location-based\nservice. He et al.29 have proposed MR-DBSCAN, a\nMapReduce version of DBSCAN. MR-DBSCAN con-\nsists of three stages. In the \ufb01rst stage, the dataset is\npartitioned based on computational cost estimation to\nachieve load balancing for heavily skewed data. In the\nsecond stage, local clustering, i.e., sequential DBSCAN\nis performed in parallel by mappers on all partitions.\nIn the third stage, the partial results generated are\naggregated by reducers to generate global clusters.\nCludoop is also a density-based clustering algorithm\nproposed by Yu et al.30 that incorporates CluC as the\nserial clustering algorithm utilized by parallel map-\npers. CluC utilizes the relationships of connected cells\naround points, instead of an expensive completed\nneighbor query, signi\ufb01cantly reducing the number of\ndistance calculations.\nHierarchical clustering aims to make a hierar-\nchy of clusters either using divisive clustering, which\nis a top\u2013down approach, or agglomerative clustering,\nwhich is a bottom\u2013up approach. Single-linkage hier-\narchical clustering (SHC) is an example of agglomer-\native clustering. Achieving parallelism for such an\nalgorithm is tricky due to inherent data dependency.\nJin et al.31 have proposed a Spark-based parallel\nSHC algorithm, SHAS, which obtains a Minimum\nSpanning Tree (MST) for achieving clustering. The\nDivide and Conquer strategy is adopted by SHAS,\nwhich divides the original dataset into subsets. MSTs\nare calculated locally for each of these subsets. These\nintermediate MSTs are combined by employing the\nK-way merge until a single MST is left. SHAS uses a\nspecial data structure(union-\ufb01nd), which records the\ninformation about each vertex and is used to ef\ufb01-\nciently combine these partial MSTs. Authors have\ncompared the performance of the SHAS with its\nMapReduce version. They have \ufb01gured out that\nSpark performs better than MapReduce for all kinds\nof datasets due to in-memory computation and no\nOverview\nwires.wiley.com/dmkd\n202\n\u00a9 2016 John Wiley & Sons, Ltd\nVolume 6, November/December 2016\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68]], "Scalable Machine-learning Algorithms for Big Data": ["has pointed out that Spark has almost replaced\nMapReduce and has become the default standard.\nBIG DATA INFERENCE ENGINE\nBig data scalable infrastructure needs to be aug-\nmented with machine-learning tools in order to\nextract inference and insights from the data sea. The\nmachine-learning\nalgorithms\nfor\nbig\ndata\nare\nrequired to \ufb01t into the distributed parallel program-\nming paradigms for handling the inherent scalability\nof big data. Parallel and distributed techniques have\nbeen used for a long time for scalability and speedup.\nHowever, they all suffer from memory and processor\ndistribution\nchallenges.\nMapReduce\nprovides\nthe\nautomatic handling of data distribution, load balan-\ncing, and fault tolerance, allowing easier and faster\nscalability of parallel systems.\nScalable Machine-learning Algorithms\nfor Big Data\nSeveral parallel machine-learning algorithms are pro-\nposed for big data, which employs MapReduce or\nTABLE 1 | Comparison of Big Data Computation Models\nBatch Processing\nReal Time\nHybrid (Batch + Real time)\nPopular big data parallel\nmodel/framework\nMapReduce\nStorm\nSpark\nData processing model\nData parallel batch processing\nmodel\nReal-time task parallel\ncomputation model\nData parallel generalized batch\nprocessing model with\nmicrobatch streaming\nBig data data structure\nKey-value pairs having functions\nTopology consisting of spouts\nand bolts\nRDD, data frames\nBig data dimensions\nVolume\nVelocity\nVolume, velocity\nCharacteristics\nFault tolerant, scalable, latency\nof few minutes\nFault tolerant, scalable, latency\nfor few subseconds, suitable\nfor real-time processing\nFault tolerant, scalable, in-\nmemory computation,\nlatency of seconds, suitable\nfor near real-time task, RDD\nmakes them suitable for\niterative tasks\nLimitations\nSelective access to data, high\ncommunication cost, lack of\niteration, lack of interactive, or\nreal-time processing\nLack of iteration and graph\nprocessing support\nSelective access to data, Lack\nof interactive or real-time\nprocessing, Insuf\ufb01cient main\nmemory may result in\nreduced performance\nApplications\nForensics, log analysis, indexing\nOnline machine learning, e-\ncommerce, Security event\nmonitoring\nRecommendation\n(Ad Placement), Fraud\nDetection\nRDD, resilient distributed dataset.\nBatch layer\nfor batch analytics\n(Hadoop, Spark)\nSpeed layer for real\ntime analytics\n(Storm, Spark)\nNew\ndata\nService layer\nFederated view\nReal time view\nBatch view\nFIGURE 3 | Lambda architecture.\nWIREs Data Mining and Knowledge Discovery\nScalable machine-learning algorithms for big data analytics\nVolume 6, November/December 2016\n\u00a9 2016 John Wiley & Sons, Ltd\n201\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68, 107]], "BIG DATA INFERENCE ENGINE": ["has pointed out that Spark has almost replaced\nMapReduce and has become the default standard.\nBIG DATA INFERENCE ENGINE\nBig data scalable infrastructure needs to be aug-\nmented with machine-learning tools in order to\nextract inference and insights from the data sea. The\nmachine-learning\nalgorithms\nfor\nbig\ndata\nare\nrequired to \ufb01t into the distributed parallel program-\nming paradigms for handling the inherent scalability\nof big data. Parallel and distributed techniques have\nbeen used for a long time for scalability and speedup.\nHowever, they all suffer from memory and processor\ndistribution\nchallenges.\nMapReduce\nprovides\nthe\nautomatic handling of data distribution, load balan-\ncing, and fault tolerance, allowing easier and faster\nscalability of parallel systems.\nScalable Machine-learning Algorithms\nfor Big Data\nSeveral parallel machine-learning algorithms are pro-\nposed for big data, which employs MapReduce or\nTABLE 1 | Comparison of Big Data Computation Models\nBatch Processing\nReal Time\nHybrid (Batch + Real time)\nPopular big data parallel\nmodel/framework\nMapReduce\nStorm\nSpark\nData processing model\nData parallel batch processing\nmodel\nReal-time task parallel\ncomputation model\nData parallel generalized batch\nprocessing model with\nmicrobatch streaming\nBig data data structure\nKey-value pairs having functions\nTopology consisting of spouts\nand bolts\nRDD, data frames\nBig data dimensions\nVolume\nVelocity\nVolume, velocity\nCharacteristics\nFault tolerant, scalable, latency\nof few minutes\nFault tolerant, scalable, latency\nfor few subseconds, suitable\nfor real-time processing\nFault tolerant, scalable, in-\nmemory computation,\nlatency of seconds, suitable\nfor near real-time task, RDD\nmakes them suitable for\niterative tasks\nLimitations\nSelective access to data, high\ncommunication cost, lack of\niteration, lack of interactive, or\nreal-time processing\nLack of iteration and graph\nprocessing support\nSelective access to data, Lack\nof interactive or real-time\nprocessing, Insuf\ufb01cient main\nmemory may result in\nreduced performance\nApplications\nForensics, log analysis, indexing\nOnline machine learning, e-\ncommerce, Security event\nmonitoring\nRecommendation\n(Ad Placement), Fraud\nDetection\nRDD, resilient distributed dataset.\nBatch layer\nfor batch analytics\n(Hadoop, Spark)\nSpeed layer for real\ntime analytics\n(Storm, Spark)\nNew\ndata\nService layer\nFederated view\nReal time view\nBatch view\nFIGURE 3 | Lambda architecture.\nWIREs Data Mining and Knowledge Discovery\nScalable machine-learning algorithms for big data analytics\nVolume 6, November/December 2016\n\u00a9 2016 John Wiley & Sons, Ltd\n201\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68, 107]], "Hybrid Model": ["models depends mainly on the underlying domain or\napplication. These parallel processing models could\nbe further categorized into batch mode, real time,\nand hybrid mode.17\nBatch Mode\nIn this mode, the data collected are divided into\nbatches and processed in parallel by multiple nodes.\nMapReduce is a distributed framework which pro-\nvides data parallelism for processing large datasets\nand is the best \ufb01t in this category. MapReduce is\nbased on shared nothing architecture where each\nprocessing node is self suf\ufb01cient to carry out its task.\nMap and reduce are its two main operators. The\ninput dataset is divided into data chunks that are\noperated by the mapper to compute intermediate\nvalues. Similar intermediate values are grouped based\non the common key. The reduce function then takes\nthese grouped values to produce an aggregated result.\nMapReduce \ufb01ts into SIMD architecture suitable for\nembarrassingly parallel problems. MapReduce jobs\ntake the input from a disk, and all the results, includ-\ning intermediate results, are written to disk every\ntime, incurring a signi\ufb01cant overhead for iterative\njobs in terms of I/O cost and network bandwidth.18\nMapReduce\u2019s major advantage over other parallel\ndistributed systems is that it relieves the programmer\nfrom the burden of code and data distribution, repli-\ncation, machine failures, and load balancing, which\nis taken care by the underlying runtime system auto-\nmatically. Hadoop is the open-source implementation\nof MapReduce, which also provides its own DFS,\nHDFS. Doulkeridis and N\u00f8rv\u00e5g19 have pointed out\nvarious weaknesses and limitations of MapReduce,\nsuch as high communication cost, lack of iteration,\nand lack of real-time processing. The popularity of\nMapReduce has now faded mainly due to a high\noverhead for iterative tasks in machine learning.20\nSeveral big data projects have been proposed in\nliterature that addresses the shortcomings of MapRe-\nduce while still maintaining scalability and fault tol-\nerance capability, such as Incoop, IncMR, Haloop,\nTwister,\niMapReduce,\nContinous\nMapReduce,\nShark, Dremel, and Scalding.17,19\nReal-Time Processing\nReal-time processing involves processing data or\nstream as it arrives and produces output almost in\nreal time. The programming model thus employed\nfor batch processing is not suitable for real-time pro-\ncessing. Storm is the most deployed computation sys-\ntem\nfor\nthe\nreal-time\nprocessing\nof\nunbounded\nstreams with a very low processing latency.17 Storm\narchitecture\nconsists\nof\ntopologies\nthat\nare\nthe\nnetwork of spouts and bolts. A spout constitutes a\nsource stream, such as input from a Twitter stream,\nwhereas a bolt consists of processing and computa-\ntional logic, such as joins and aggregation.20 The\nmajor\ndifference\nbetween\nstorm\ntopologies\nand\nMapReduce jobs as identi\ufb01ed by Sundaresan and\nKandavel17 is that storm topologies keep on execut-\ning due to real-time date ingestion of stream data,\nwhereas MapReduce jobs eventually \ufb01nish.\nVarious other storm alternatives, such as Tri-\ndent and S4, have also been proposed in literature.17\nHybrid Model\nA hybrid model can handle both batch data and real-\ntime data. Spark is the most deployed big data hybrid\nprocessing model. It does not have its own \ufb01le system\nand usually runs on top of HDFS. It employs in-\nmemory computation, reducing read and write disk\noperations. The main building block in Spark is the\nResilient Distributed Dataset (RDD), which provides\nin-memory data caching of intermediate results and\nfault tolerance without replication.21 Spark also\noffers microbatch streaming in which an incoming\nstream is divided into different chunks to be pro-\ncessed by the batch system.22\nA comparison of these three big data computa-\ntion models is presented below in Table 1.\nAll the computation models mentioned above\nare parallel and have their own pros and cons. The\ndecision to select the best model depends on the\ndomain/application and processing time, i.e., latency.\nAt one end is MapReduce, which is a batch-\nprocessing framework, and on the other end is\nStorm, which is a real-time processing framework.\nMarz and Waren23 have proposed a lambda architec-\nture that combines different technologies. It combines\nthe process of batch analytics and real time stream\nanalytics. Lambda architecture decomposes the prob-\nlem into three layers, as shown in Figure 3. The three\nlayers are batch layer, speed layer, and serving layer.\nThe data are sent both to the batch layer and the\nspeed layer as soon as it arrives. The batch layer\nappends the new data to the already existing dataset\nand performs the computation on it, which is then\npassed to the serving layer for indexing. The speed\nlayer compensates the latency in the output of batch\nlayer by providing real-time updates of the new data.\nThe service layer merges the output of both layers to\nprovide the federated view. Hybrid models such as\nSpark \ufb01t well into lambda architecture, seamlessly\nintegrating both the modes. Stream processing of\nclick streams followed by batch processing for the\ncorrelation of clicks is one such example. Vizard24\nOverview\nwires.wiley.com/dmkd\n200\n\u00a9 2016 John Wiley & Sons, Ltd\nVolume 6, November/December 2016\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68, 107]], "Real-Time Processing": ["models depends mainly on the underlying domain or\napplication. These parallel processing models could\nbe further categorized into batch mode, real time,\nand hybrid mode.17\nBatch Mode\nIn this mode, the data collected are divided into\nbatches and processed in parallel by multiple nodes.\nMapReduce is a distributed framework which pro-\nvides data parallelism for processing large datasets\nand is the best \ufb01t in this category. MapReduce is\nbased on shared nothing architecture where each\nprocessing node is self suf\ufb01cient to carry out its task.\nMap and reduce are its two main operators. The\ninput dataset is divided into data chunks that are\noperated by the mapper to compute intermediate\nvalues. Similar intermediate values are grouped based\non the common key. The reduce function then takes\nthese grouped values to produce an aggregated result.\nMapReduce \ufb01ts into SIMD architecture suitable for\nembarrassingly parallel problems. MapReduce jobs\ntake the input from a disk, and all the results, includ-\ning intermediate results, are written to disk every\ntime, incurring a signi\ufb01cant overhead for iterative\njobs in terms of I/O cost and network bandwidth.18\nMapReduce\u2019s major advantage over other parallel\ndistributed systems is that it relieves the programmer\nfrom the burden of code and data distribution, repli-\ncation, machine failures, and load balancing, which\nis taken care by the underlying runtime system auto-\nmatically. Hadoop is the open-source implementation\nof MapReduce, which also provides its own DFS,\nHDFS. Doulkeridis and N\u00f8rv\u00e5g19 have pointed out\nvarious weaknesses and limitations of MapReduce,\nsuch as high communication cost, lack of iteration,\nand lack of real-time processing. The popularity of\nMapReduce has now faded mainly due to a high\noverhead for iterative tasks in machine learning.20\nSeveral big data projects have been proposed in\nliterature that addresses the shortcomings of MapRe-\nduce while still maintaining scalability and fault tol-\nerance capability, such as Incoop, IncMR, Haloop,\nTwister,\niMapReduce,\nContinous\nMapReduce,\nShark, Dremel, and Scalding.17,19\nReal-Time Processing\nReal-time processing involves processing data or\nstream as it arrives and produces output almost in\nreal time. The programming model thus employed\nfor batch processing is not suitable for real-time pro-\ncessing. Storm is the most deployed computation sys-\ntem\nfor\nthe\nreal-time\nprocessing\nof\nunbounded\nstreams with a very low processing latency.17 Storm\narchitecture\nconsists\nof\ntopologies\nthat\nare\nthe\nnetwork of spouts and bolts. A spout constitutes a\nsource stream, such as input from a Twitter stream,\nwhereas a bolt consists of processing and computa-\ntional logic, such as joins and aggregation.20 The\nmajor\ndifference\nbetween\nstorm\ntopologies\nand\nMapReduce jobs as identi\ufb01ed by Sundaresan and\nKandavel17 is that storm topologies keep on execut-\ning due to real-time date ingestion of stream data,\nwhereas MapReduce jobs eventually \ufb01nish.\nVarious other storm alternatives, such as Tri-\ndent and S4, have also been proposed in literature.17\nHybrid Model\nA hybrid model can handle both batch data and real-\ntime data. Spark is the most deployed big data hybrid\nprocessing model. It does not have its own \ufb01le system\nand usually runs on top of HDFS. It employs in-\nmemory computation, reducing read and write disk\noperations. The main building block in Spark is the\nResilient Distributed Dataset (RDD), which provides\nin-memory data caching of intermediate results and\nfault tolerance without replication.21 Spark also\noffers microbatch streaming in which an incoming\nstream is divided into different chunks to be pro-\ncessed by the batch system.22\nA comparison of these three big data computa-\ntion models is presented below in Table 1.\nAll the computation models mentioned above\nare parallel and have their own pros and cons. The\ndecision to select the best model depends on the\ndomain/application and processing time, i.e., latency.\nAt one end is MapReduce, which is a batch-\nprocessing framework, and on the other end is\nStorm, which is a real-time processing framework.\nMarz and Waren23 have proposed a lambda architec-\nture that combines different technologies. It combines\nthe process of batch analytics and real time stream\nanalytics. Lambda architecture decomposes the prob-\nlem into three layers, as shown in Figure 3. The three\nlayers are batch layer, speed layer, and serving layer.\nThe data are sent both to the batch layer and the\nspeed layer as soon as it arrives. The batch layer\nappends the new data to the already existing dataset\nand performs the computation on it, which is then\npassed to the serving layer for indexing. The speed\nlayer compensates the latency in the output of batch\nlayer by providing real-time updates of the new data.\nThe service layer merges the output of both layers to\nprovide the federated view. Hybrid models such as\nSpark \ufb01t well into lambda architecture, seamlessly\nintegrating both the modes. Stream processing of\nclick streams followed by batch processing for the\ncorrelation of clicks is one such example. Vizard24\nOverview\nwires.wiley.com/dmkd\n200\n\u00a9 2016 John Wiley & Sons, Ltd\nVolume 6, November/December 2016\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", []], "Batch Mode": ["models depends mainly on the underlying domain or\napplication. These parallel processing models could\nbe further categorized into batch mode, real time,\nand hybrid mode.17\nBatch Mode\nIn this mode, the data collected are divided into\nbatches and processed in parallel by multiple nodes.\nMapReduce is a distributed framework which pro-\nvides data parallelism for processing large datasets\nand is the best \ufb01t in this category. MapReduce is\nbased on shared nothing architecture where each\nprocessing node is self suf\ufb01cient to carry out its task.\nMap and reduce are its two main operators. The\ninput dataset is divided into data chunks that are\noperated by the mapper to compute intermediate\nvalues. Similar intermediate values are grouped based\non the common key. The reduce function then takes\nthese grouped values to produce an aggregated result.\nMapReduce \ufb01ts into SIMD architecture suitable for\nembarrassingly parallel problems. MapReduce jobs\ntake the input from a disk, and all the results, includ-\ning intermediate results, are written to disk every\ntime, incurring a signi\ufb01cant overhead for iterative\njobs in terms of I/O cost and network bandwidth.18\nMapReduce\u2019s major advantage over other parallel\ndistributed systems is that it relieves the programmer\nfrom the burden of code and data distribution, repli-\ncation, machine failures, and load balancing, which\nis taken care by the underlying runtime system auto-\nmatically. Hadoop is the open-source implementation\nof MapReduce, which also provides its own DFS,\nHDFS. Doulkeridis and N\u00f8rv\u00e5g19 have pointed out\nvarious weaknesses and limitations of MapReduce,\nsuch as high communication cost, lack of iteration,\nand lack of real-time processing. The popularity of\nMapReduce has now faded mainly due to a high\noverhead for iterative tasks in machine learning.20\nSeveral big data projects have been proposed in\nliterature that addresses the shortcomings of MapRe-\nduce while still maintaining scalability and fault tol-\nerance capability, such as Incoop, IncMR, Haloop,\nTwister,\niMapReduce,\nContinous\nMapReduce,\nShark, Dremel, and Scalding.17,19\nReal-Time Processing\nReal-time processing involves processing data or\nstream as it arrives and produces output almost in\nreal time. The programming model thus employed\nfor batch processing is not suitable for real-time pro-\ncessing. Storm is the most deployed computation sys-\ntem\nfor\nthe\nreal-time\nprocessing\nof\nunbounded\nstreams with a very low processing latency.17 Storm\narchitecture\nconsists\nof\ntopologies\nthat\nare\nthe\nnetwork of spouts and bolts. A spout constitutes a\nsource stream, such as input from a Twitter stream,\nwhereas a bolt consists of processing and computa-\ntional logic, such as joins and aggregation.20 The\nmajor\ndifference\nbetween\nstorm\ntopologies\nand\nMapReduce jobs as identi\ufb01ed by Sundaresan and\nKandavel17 is that storm topologies keep on execut-\ning due to real-time date ingestion of stream data,\nwhereas MapReduce jobs eventually \ufb01nish.\nVarious other storm alternatives, such as Tri-\ndent and S4, have also been proposed in literature.17\nHybrid Model\nA hybrid model can handle both batch data and real-\ntime data. Spark is the most deployed big data hybrid\nprocessing model. It does not have its own \ufb01le system\nand usually runs on top of HDFS. It employs in-\nmemory computation, reducing read and write disk\noperations. The main building block in Spark is the\nResilient Distributed Dataset (RDD), which provides\nin-memory data caching of intermediate results and\nfault tolerance without replication.21 Spark also\noffers microbatch streaming in which an incoming\nstream is divided into different chunks to be pro-\ncessed by the batch system.22\nA comparison of these three big data computa-\ntion models is presented below in Table 1.\nAll the computation models mentioned above\nare parallel and have their own pros and cons. The\ndecision to select the best model depends on the\ndomain/application and processing time, i.e., latency.\nAt one end is MapReduce, which is a batch-\nprocessing framework, and on the other end is\nStorm, which is a real-time processing framework.\nMarz and Waren23 have proposed a lambda architec-\nture that combines different technologies. It combines\nthe process of batch analytics and real time stream\nanalytics. Lambda architecture decomposes the prob-\nlem into three layers, as shown in Figure 3. The three\nlayers are batch layer, speed layer, and serving layer.\nThe data are sent both to the batch layer and the\nspeed layer as soon as it arrives. The batch layer\nappends the new data to the already existing dataset\nand performs the computation on it, which is then\npassed to the serving layer for indexing. The speed\nlayer compensates the latency in the output of batch\nlayer by providing real-time updates of the new data.\nThe service layer merges the output of both layers to\nprovide the federated view. Hybrid models such as\nSpark \ufb01t well into lambda architecture, seamlessly\nintegrating both the modes. Stream processing of\nclick streams followed by batch processing for the\ncorrelation of clicks is one such example. Vizard24\nOverview\nwires.wiley.com/dmkd\n200\n\u00a9 2016 John Wiley & Sons, Ltd\nVolume 6, November/December 2016\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", []], "Big Data Computational Frameworks": ["performance improvements such as support of other\nprocessing models besides MapReduce.11\nA number of other alternatives of HDFS are\nalso available, such as Ceph, Tachyon, GlusterFS,\nQFS, GridGain, and XtreemFS.12\nData Models for Big Data\nBig data has led to an explosion of databases due to\nthe inability of traditional databases to scale-up with\nbig data. The big data models could be categorized into\nNoSQL and NewSQL data models, which could be\nused in place of, or along with, traditional RDBMS.\nCAP theorem states that any networked shared-data\nsystem can have, at most, two of the three desirable\nproperties of consistency, high availability of data, and\ntolerance to network partitions.13 A distributed system\ncannot lose on tolerance to network partitions, leaving\na\nchoice\nbetween\nconsistency\nand\navailability.13\nRDBMS systems are more focused on consistency\nrather than availability and strictly comply with ACID\n(Atomicity, Consistence, Isolation, Durability) proper-\nties. NoSQL, on the other hand, are focused on availa-\nbility rather than consistency and comply with BASE\n(Basically Available, Soft-state, Eventually consistent)\nproperties. RDBMS handles both data storage and\ndata management, whereas NoSQL databases separate\nboth.\nNoSQL\ndatabases\nfocus\nonly\non\nhigh-\nperformance scalable data storage, and data manage-\nment tasks are handled by the application layer.10\nNoSQL supports schema-free storage or dynamic\nchanging schema, enabling applications to upgrade\ntable structure without table rewriting.10\nNoSQL are horizontal scalable databases that\ncan handle a variety of big data and are categorized\ninto four models. They are key-value store, wide-\ncolumn store, document-oriented store, and graph\ndatabase.14,15\n(a) Key-value store: These systems store data in\nkey-value pairs where value contains data that\ncould be retrieved with the help of key. The\nvalue may be a string or complex lists or sets.\nThe search can only be performed against keys\nand is limited to exact matches. The key-value\nstore is suitable for the fast retrieval of values,\nsuch as retrieving product names or user pro-\n\ufb01les. Some of the well-known implementations\nof a key-value store are Dynamo, Voldemort,\nRedis, and Riak.\n(b) Wide-column store: These systems employ a\ndistributed,\ncolumn-oriented\ndata\nstructure\nthat accommodates multiple attributes per\nkey. The wide-column store is suitable for\ndistributed data storage, large-scale batch-\noriented data processing, and exploratory and\npredictive analytics. Some of the well-known\nimplementations of wide-column store are Big-\ntable, Cassandra SimpleDB, and DynamoDB\n(c) Document-oriented store: It stores the data as\nthe collections of the documents. These docu-\nments\nare\nencoded\nin\na\nstandard\ndata\nexchange format such as XML, JSON, or\nBSON. The value column in a document store\ncontains semistructured data and may contain\na large number of attributes. The number and\ntype of these attributes may vary among rows.\nDocument store allows searching through both\nkeys and values, unlike a key-value store,\nwhich allows searching only by key. Document\nstores are good for the storage of literal docu-\nments such as text documents, email messages,\nand XML documents. They are also good for\nstoring sparse data. Some of the well-known\nimplementations of document-oriented store\nare CouchDB(JSON) and MongoDB (BSON).\n(d) Graph data model. These models use struc-\ntured relational graphs of interconnected key-\nvalue pairs. Data is stored in the form of a\ngraph having nodes and links, with attributes\nassociated with them. Graph data models are\nuseful when relationships between data are\nmore important than the data itself, such as\nsocial networks and recommendations. Some\nof the well-known implementations of graph\ndata store are Neo4j, InfoGrid, and GraphDB.\nNewSQL is another type of big data model and is\nknown as the next generation scalable relational data-\nbase management systems.16 NewSQL implements the\nbest of both traditional databases and NoSQL data-\nbases. NewSQL is based on relational model and pro-\nvides scalability of NoSQL while still maintaining\nACID properties.16 NewSQL supports SQL query.\nHowever, the underlying architecture of NewSQL is\ndifferent from RDBMS and supports scaling techni-\nques, such as vertical partitioning, horizontal partition-\ning, or sharding and clustering.16 Some well-known\nimplementations of NewSQL are NuoDB and VoltDB.\nThese data models differ signi\ufb01cantly from each\nother\nand\nmay\nbe\nselected\nbased\non\nthe\nunderlying task.\nBig Data Computational Frameworks\nThere are a number of parallel distributed computa-\ntion models for big data. The choice of these big data\nWIREs Data Mining and Knowledge Discovery\nScalable machine-learning algorithms for big data analytics\nVolume 6, November/December 2016\n\u00a9 2016 John Wiley & Sons, Ltd\n199\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68]], "Data Models for Big Data": ["performance improvements such as support of other\nprocessing models besides MapReduce.11\nA number of other alternatives of HDFS are\nalso available, such as Ceph, Tachyon, GlusterFS,\nQFS, GridGain, and XtreemFS.12\nData Models for Big Data\nBig data has led to an explosion of databases due to\nthe inability of traditional databases to scale-up with\nbig data. The big data models could be categorized into\nNoSQL and NewSQL data models, which could be\nused in place of, or along with, traditional RDBMS.\nCAP theorem states that any networked shared-data\nsystem can have, at most, two of the three desirable\nproperties of consistency, high availability of data, and\ntolerance to network partitions.13 A distributed system\ncannot lose on tolerance to network partitions, leaving\na\nchoice\nbetween\nconsistency\nand\navailability.13\nRDBMS systems are more focused on consistency\nrather than availability and strictly comply with ACID\n(Atomicity, Consistence, Isolation, Durability) proper-\nties. NoSQL, on the other hand, are focused on availa-\nbility rather than consistency and comply with BASE\n(Basically Available, Soft-state, Eventually consistent)\nproperties. RDBMS handles both data storage and\ndata management, whereas NoSQL databases separate\nboth.\nNoSQL\ndatabases\nfocus\nonly\non\nhigh-\nperformance scalable data storage, and data manage-\nment tasks are handled by the application layer.10\nNoSQL supports schema-free storage or dynamic\nchanging schema, enabling applications to upgrade\ntable structure without table rewriting.10\nNoSQL are horizontal scalable databases that\ncan handle a variety of big data and are categorized\ninto four models. They are key-value store, wide-\ncolumn store, document-oriented store, and graph\ndatabase.14,15\n(a) Key-value store: These systems store data in\nkey-value pairs where value contains data that\ncould be retrieved with the help of key. The\nvalue may be a string or complex lists or sets.\nThe search can only be performed against keys\nand is limited to exact matches. The key-value\nstore is suitable for the fast retrieval of values,\nsuch as retrieving product names or user pro-\n\ufb01les. Some of the well-known implementations\nof a key-value store are Dynamo, Voldemort,\nRedis, and Riak.\n(b) Wide-column store: These systems employ a\ndistributed,\ncolumn-oriented\ndata\nstructure\nthat accommodates multiple attributes per\nkey. The wide-column store is suitable for\ndistributed data storage, large-scale batch-\noriented data processing, and exploratory and\npredictive analytics. Some of the well-known\nimplementations of wide-column store are Big-\ntable, Cassandra SimpleDB, and DynamoDB\n(c) Document-oriented store: It stores the data as\nthe collections of the documents. These docu-\nments\nare\nencoded\nin\na\nstandard\ndata\nexchange format such as XML, JSON, or\nBSON. The value column in a document store\ncontains semistructured data and may contain\na large number of attributes. The number and\ntype of these attributes may vary among rows.\nDocument store allows searching through both\nkeys and values, unlike a key-value store,\nwhich allows searching only by key. Document\nstores are good for the storage of literal docu-\nments such as text documents, email messages,\nand XML documents. They are also good for\nstoring sparse data. Some of the well-known\nimplementations of document-oriented store\nare CouchDB(JSON) and MongoDB (BSON).\n(d) Graph data model. These models use struc-\ntured relational graphs of interconnected key-\nvalue pairs. Data is stored in the form of a\ngraph having nodes and links, with attributes\nassociated with them. Graph data models are\nuseful when relationships between data are\nmore important than the data itself, such as\nsocial networks and recommendations. Some\nof the well-known implementations of graph\ndata store are Neo4j, InfoGrid, and GraphDB.\nNewSQL is another type of big data model and is\nknown as the next generation scalable relational data-\nbase management systems.16 NewSQL implements the\nbest of both traditional databases and NoSQL data-\nbases. NewSQL is based on relational model and pro-\nvides scalability of NoSQL while still maintaining\nACID properties.16 NewSQL supports SQL query.\nHowever, the underlying architecture of NewSQL is\ndifferent from RDBMS and supports scaling techni-\nques, such as vertical partitioning, horizontal partition-\ning, or sharding and clustering.16 Some well-known\nimplementations of NewSQL are NuoDB and VoltDB.\nThese data models differ signi\ufb01cantly from each\nother\nand\nmay\nbe\nselected\nbased\non\nthe\nunderlying task.\nBig Data Computational Frameworks\nThere are a number of parallel distributed computa-\ntion models for big data. The choice of these big data\nWIREs Data Mining and Knowledge Discovery\nScalable machine-learning algorithms for big data analytics\nVolume 6, November/December 2016\n\u00a9 2016 John Wiley & Sons, Ltd\n199\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68]], "Distributed File System": ["raises more privacy concerns for the people\ninvolved in the data. The traditional methods\nfor protecting data privacy will not work on\ndynamic and huge big data.\nIn order to handle these challenges, the realm of big\ndata analytics in this paper has been divided into two\nphases, big data infrastructure and big data inference\nengine, as shown in Figure 2. The \ufb01rst phase involves\nsetting the stage for big data processing and involves\nthe selection of big data storage and big data compu-\ntational frameworks, which have been discussed in\ndetail in the fourth section. The second phase\ninvolves\nthe\ndesigning\nand\nimplementation\nof\nmachine-learning tools in order to extract insights\nfrom the data sea, which have been discussed in\ndetail in the \ufb01fth section.\nBIG DATA INFRASTRUCTURE\nBig data collection, storage, and analysis demand\ndata decentralization and provide a new strategy for\nthe traditional data warehousing approach. It \ufb01ts\ninto the MAD model.7 MAD refers to the Magnetic,\nAgile, and Deep analysis of data. Big data allows the\ncapture and storage of anything as is, without any\ntransformation, acting as a magnet attracting any\nkind of data. It needs agile infrastructure that is fully\nscalable to handle data evolution of a varied nature.\nIt needs to provide a deep data repository with deep\nanalytical capabilities. It has not replaced Data Ware-\nhouse; instead, it has provided an edge to the overall\nstrategy by offering schema on query rather than\nschema on design.8 The Extract, Transform, and\nLoad (ETL) approach has been transformed into\nELT, i.e., Extract, Load, and Transform.7\nConsequently, a big data infrastructure needs\ndistributed\n\ufb01le\nsystem\n(DFS),\nNot\nOnly\nSQL\n(NoSQL) databases, computational frameworks pro-\nviding storage, and analytical scalability.\nDistributed File System\nDFS provides scalable data storage and access for\nhandling big data. DFS enables parallel processing\non a large amount of data. HDFS has become the\ndefault choice for big data tasks due to its fault toler-\nance\nand\nits\nability\nto\nbe\ndeployed\non\nlow-\ncommodity hardware.9 HDFS allows users to store\ndata in \ufb01les supporting a wide variety of data. The\n\ufb01les are further split into blocks. The data blocks are\ndistributed and replicated across nodes, providing\nfault tolerance.10 HDFS supports write-once-read-\nmany semantics on \ufb01les.9 The data block size is usu-\nally 64 MB and is replicated into three copies by\ndefault.11 A HDFS cluster operates in a master\u2013slave\narchitecture.9 It consists of one master NameNode\nand a number of DataNodes. NameNode manages\nthe \ufb01lesystem namespace and controls access to the\n\ufb01les. NameNode also maps the data blocks to Data-\nNodes. DataNode creates stores and retrieves data\nblocks as per the NameNode\u2019s direction.11\nHDFS is not a database; it is just a \ufb01lesystem.\nHDFS is provided as a part of the Hadoop frame-\nwork. Hadoop is a library of tools for big data. It\nconsists of Hadoop Common Utilities, HDFS, and\nMapReduce. After the introduction of Hadoop 2.0,\nYARN (Yet Another Resource Negotiator) has been\nadded to the Hadoop framework.11 YARN has sepa-\nrated the resource management functions from the\nprogramming mode, which has brought signi\ufb01cant\nDistributed\nFile System\nPhase 1: Big Data Infrastructure\nPhase 1: Big Data Infrastructure\nPhase 1: Big Data Infrastructure\nPhase 2: Big Data Inference Engine\nPhase 2: Big Data Inference Engine\nPhase 2: Big Data Inference Engine\nBig Data\nModels\nBig Data\nComputational\nFramework\nBig Data\nScalable\nMachine\nLearning\nAlgorithms\nFIGURE 2 | Big data analytics.\nOverview\nwires.wiley.com/dmkd\n198\n\u00a9 2016 John Wiley & Sons, Ltd\nVolume 6, November/December 2016\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68, 94]], "BIG DATA INFRASTRUCTURE": ["raises more privacy concerns for the people\ninvolved in the data. The traditional methods\nfor protecting data privacy will not work on\ndynamic and huge big data.\nIn order to handle these challenges, the realm of big\ndata analytics in this paper has been divided into two\nphases, big data infrastructure and big data inference\nengine, as shown in Figure 2. The \ufb01rst phase involves\nsetting the stage for big data processing and involves\nthe selection of big data storage and big data compu-\ntational frameworks, which have been discussed in\ndetail in the fourth section. The second phase\ninvolves\nthe\ndesigning\nand\nimplementation\nof\nmachine-learning tools in order to extract insights\nfrom the data sea, which have been discussed in\ndetail in the \ufb01fth section.\nBIG DATA INFRASTRUCTURE\nBig data collection, storage, and analysis demand\ndata decentralization and provide a new strategy for\nthe traditional data warehousing approach. It \ufb01ts\ninto the MAD model.7 MAD refers to the Magnetic,\nAgile, and Deep analysis of data. Big data allows the\ncapture and storage of anything as is, without any\ntransformation, acting as a magnet attracting any\nkind of data. It needs agile infrastructure that is fully\nscalable to handle data evolution of a varied nature.\nIt needs to provide a deep data repository with deep\nanalytical capabilities. It has not replaced Data Ware-\nhouse; instead, it has provided an edge to the overall\nstrategy by offering schema on query rather than\nschema on design.8 The Extract, Transform, and\nLoad (ETL) approach has been transformed into\nELT, i.e., Extract, Load, and Transform.7\nConsequently, a big data infrastructure needs\ndistributed\n\ufb01le\nsystem\n(DFS),\nNot\nOnly\nSQL\n(NoSQL) databases, computational frameworks pro-\nviding storage, and analytical scalability.\nDistributed File System\nDFS provides scalable data storage and access for\nhandling big data. DFS enables parallel processing\non a large amount of data. HDFS has become the\ndefault choice for big data tasks due to its fault toler-\nance\nand\nits\nability\nto\nbe\ndeployed\non\nlow-\ncommodity hardware.9 HDFS allows users to store\ndata in \ufb01les supporting a wide variety of data. The\n\ufb01les are further split into blocks. The data blocks are\ndistributed and replicated across nodes, providing\nfault tolerance.10 HDFS supports write-once-read-\nmany semantics on \ufb01les.9 The data block size is usu-\nally 64 MB and is replicated into three copies by\ndefault.11 A HDFS cluster operates in a master\u2013slave\narchitecture.9 It consists of one master NameNode\nand a number of DataNodes. NameNode manages\nthe \ufb01lesystem namespace and controls access to the\n\ufb01les. NameNode also maps the data blocks to Data-\nNodes. DataNode creates stores and retrieves data\nblocks as per the NameNode\u2019s direction.11\nHDFS is not a database; it is just a \ufb01lesystem.\nHDFS is provided as a part of the Hadoop frame-\nwork. Hadoop is a library of tools for big data. It\nconsists of Hadoop Common Utilities, HDFS, and\nMapReduce. After the introduction of Hadoop 2.0,\nYARN (Yet Another Resource Negotiator) has been\nadded to the Hadoop framework.11 YARN has sepa-\nrated the resource management functions from the\nprogramming mode, which has brought signi\ufb01cant\nDistributed\nFile System\nPhase 1: Big Data Infrastructure\nPhase 1: Big Data Infrastructure\nPhase 1: Big Data Infrastructure\nPhase 2: Big Data Inference Engine\nPhase 2: Big Data Inference Engine\nPhase 2: Big Data Inference Engine\nBig Data\nModels\nBig Data\nComputational\nFramework\nBig Data\nScalable\nMachine\nLearning\nAlgorithms\nFIGURE 2 | Big data analytics.\nOverview\nwires.wiley.com/dmkd\n198\n\u00a9 2016 John Wiley & Sons, Ltd\nVolume 6, November/December 2016\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [94]], "BIG DATA ANALYTICS AND ITS CHALLENGES": ["paper, an overview of big data analytics is provided.\nThe task of big data analytics is divided into two\nphases. The \ufb01rst phase involves setting the stage for big\ndata processing and includes the selection of big data\nstorage and big data computational framework. The\nsecond phase involves the designing and implementa-\ntion of machine-learning tools for extracting insights\nfrom the data. The paper is divided into seven sections.\nThe \ufb01rst section starts with the general introduction of\nthe topic. The second section outlines the employed\nresearch methodology, highlighting the basis on which\nwe selected the research papers for study and the cri-\nteria for their inclusion in our work. The third\nsection provides an introduction to big data and big\ndata analytics along with various challenges of big data\nanalytics. The fourth section covers details regarding\nbig data infrastructure. The \ufb01fth section provides\ndetails and a comparative analysis of the various\ndistributed data-intensive parallel machine-learning\nalgorithms for big data. The sixth section provides\nsome\nlimitations\nof\nour\nresearch.\nThe\nseventh\nsection\npresents\nthe\nresearch\nimplication\nof\nour\nresearch. The \ufb01nal section contains concluding remarks\nand the future scope of our work.\nRESEARCH METHODOLOGY\nObjective\nThe strong need of extracting relevant information\nfrom a data heap containing humungous and heteroge-\nneous data demands scalable and decentralized analy-\nsis techniques. This is where big data analytics steps\nin. It helps researchers and data scientists in extracting\nuseful insights from the data deluge. Traditional\nmachine-learning algorithms need to be adapted to the\nbig data realm for handling big data scalability. The\nobjective of this paper is to provide a solid base for\nscalable machine-learning algorithms for big data ana-\nlytics. The study covers an overview regarding big data\nstorage and big data computational frameworks along\nwith a survey of distributed parallel data-intensive\nalgorithms for big data. Although this search may not\nbe completely exhaustive, it provides a good compre-\nhensive base for understanding distributed scalable\nmachine-learning algorithms in the emergent and pro-\nfound \ufb01eld of big data analytics. The paper also pro-\nvides a comparative analysis of scalable machine-\nlearning algorithms on various metrics.\nSearch Process\nThis paper is a qualitative review study based on the\nauthors\u2019 perception from the study of various papers\nrelated to big data analytics. Literature selection\ncriteria employed by authors for deciding on research\npaper inclusions are represented diagrammatically in\nFigure 1. The relevant material was scattered across\nvarious journals, conferences, and book chapters.\nThe online databases that were referred for extract-\ning relevant literature were IEEE, Science Direct,\nHindawi ACM Digital Library, Springer, IGI global,\nand Taylor & Francis Online. The online databases\nwere searched based on descriptors such as \u2018big\ndata,\u2019 \u2018big data analytics,\u2019 \u2018big data challenges,\u2019 \u2018big\ndata\nstorage,\u2019\n\u2018big data\nand\nmachine\nlearning,\u2019\n\u2018machine\nlearning\nalgorithms\nemploying\nMapReduce,\u2019\n\u2018distributed\nparallel\nalgorithm\n&\nMapReduce,\u2019 and \u2018parallel machine learning algo-\nrithms employing Spark,\u2019 which produced various\njournal and conference papers from the year 2008\nto 2016.\nThe literature selection was divided into two\ncategories. One category included the papers related\nto big data infrastructure, and the other included\nscalable machine-learning algorithms for big data.\nThe full text of each article was reviewed to examine\nthe applicability of the article for the review, and\nonly the relevant articles were included. The papers\nthat have achieved parallelism using vertical scaling\nwere rejected. Papers that included distributed paral-\nlel programming without MapReduce or Spark were\nalso rejected.\nKey Factors for Evaluation\nOn the basis of the selected papers, several optimiza-\ntion and evaluation metrics are used to perform a\ncomparative analysis of scalable machine-learning\nalgorithms for big data. The optimization metrics\nused are sampling, indexing, intelligent partitioning,\nspecial data structure, in-memory computation, and\nasynchronous execution. The performance metrics\nused are number of MapReduce jobs, speedup, accu-\nracy, and scalability. The performance metrics also\ninclude the data source validation check and the\ncomparative analysis of the algorithm with the base\ntechnique, which are the effectiveness indicators of\nthe assumption and results made in the algorithm.\nScalable machine-learning algorithms were evaluated\non these metrics to perform a comparative analysis.\nBIG DATA ANALYTICS\nAND ITS CHALLENGES\nBig data analytics has led to data explosion where\ndata from sensors, devices, and networks are col-\nlected and stored without discarding anything from\nit. The data are \ufb02owing at very high rate, and the\nWIREs Data Mining and Knowledge Discovery\nScalable machine-learning algorithms for big data analytics\nVolume 6, November/December 2016\n\u00a9 2016 John Wiley & Sons, Ltd\n195\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68, 78, 94]], "Key Factors for Evaluation": ["paper, an overview of big data analytics is provided.\nThe task of big data analytics is divided into two\nphases. The \ufb01rst phase involves setting the stage for big\ndata processing and includes the selection of big data\nstorage and big data computational framework. The\nsecond phase involves the designing and implementa-\ntion of machine-learning tools for extracting insights\nfrom the data. The paper is divided into seven sections.\nThe \ufb01rst section starts with the general introduction of\nthe topic. The second section outlines the employed\nresearch methodology, highlighting the basis on which\nwe selected the research papers for study and the cri-\nteria for their inclusion in our work. The third\nsection provides an introduction to big data and big\ndata analytics along with various challenges of big data\nanalytics. The fourth section covers details regarding\nbig data infrastructure. The \ufb01fth section provides\ndetails and a comparative analysis of the various\ndistributed data-intensive parallel machine-learning\nalgorithms for big data. The sixth section provides\nsome\nlimitations\nof\nour\nresearch.\nThe\nseventh\nsection\npresents\nthe\nresearch\nimplication\nof\nour\nresearch. The \ufb01nal section contains concluding remarks\nand the future scope of our work.\nRESEARCH METHODOLOGY\nObjective\nThe strong need of extracting relevant information\nfrom a data heap containing humungous and heteroge-\nneous data demands scalable and decentralized analy-\nsis techniques. This is where big data analytics steps\nin. It helps researchers and data scientists in extracting\nuseful insights from the data deluge. Traditional\nmachine-learning algorithms need to be adapted to the\nbig data realm for handling big data scalability. The\nobjective of this paper is to provide a solid base for\nscalable machine-learning algorithms for big data ana-\nlytics. The study covers an overview regarding big data\nstorage and big data computational frameworks along\nwith a survey of distributed parallel data-intensive\nalgorithms for big data. Although this search may not\nbe completely exhaustive, it provides a good compre-\nhensive base for understanding distributed scalable\nmachine-learning algorithms in the emergent and pro-\nfound \ufb01eld of big data analytics. The paper also pro-\nvides a comparative analysis of scalable machine-\nlearning algorithms on various metrics.\nSearch Process\nThis paper is a qualitative review study based on the\nauthors\u2019 perception from the study of various papers\nrelated to big data analytics. Literature selection\ncriteria employed by authors for deciding on research\npaper inclusions are represented diagrammatically in\nFigure 1. The relevant material was scattered across\nvarious journals, conferences, and book chapters.\nThe online databases that were referred for extract-\ning relevant literature were IEEE, Science Direct,\nHindawi ACM Digital Library, Springer, IGI global,\nand Taylor & Francis Online. The online databases\nwere searched based on descriptors such as \u2018big\ndata,\u2019 \u2018big data analytics,\u2019 \u2018big data challenges,\u2019 \u2018big\ndata\nstorage,\u2019\n\u2018big data\nand\nmachine\nlearning,\u2019\n\u2018machine\nlearning\nalgorithms\nemploying\nMapReduce,\u2019\n\u2018distributed\nparallel\nalgorithm\n&\nMapReduce,\u2019 and \u2018parallel machine learning algo-\nrithms employing Spark,\u2019 which produced various\njournal and conference papers from the year 2008\nto 2016.\nThe literature selection was divided into two\ncategories. One category included the papers related\nto big data infrastructure, and the other included\nscalable machine-learning algorithms for big data.\nThe full text of each article was reviewed to examine\nthe applicability of the article for the review, and\nonly the relevant articles were included. The papers\nthat have achieved parallelism using vertical scaling\nwere rejected. Papers that included distributed paral-\nlel programming without MapReduce or Spark were\nalso rejected.\nKey Factors for Evaluation\nOn the basis of the selected papers, several optimiza-\ntion and evaluation metrics are used to perform a\ncomparative analysis of scalable machine-learning\nalgorithms for big data. The optimization metrics\nused are sampling, indexing, intelligent partitioning,\nspecial data structure, in-memory computation, and\nasynchronous execution. The performance metrics\nused are number of MapReduce jobs, speedup, accu-\nracy, and scalability. The performance metrics also\ninclude the data source validation check and the\ncomparative analysis of the algorithm with the base\ntechnique, which are the effectiveness indicators of\nthe assumption and results made in the algorithm.\nScalable machine-learning algorithms were evaluated\non these metrics to perform a comparative analysis.\nBIG DATA ANALYTICS\nAND ITS CHALLENGES\nBig data analytics has led to data explosion where\ndata from sensors, devices, and networks are col-\nlected and stored without discarding anything from\nit. The data are \ufb02owing at very high rate, and the\nWIREs Data Mining and Knowledge Discovery\nScalable machine-learning algorithms for big data analytics\nVolume 6, November/December 2016\n\u00a9 2016 John Wiley & Sons, Ltd\n195\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68]], "Search Process": ["paper, an overview of big data analytics is provided.\nThe task of big data analytics is divided into two\nphases. The \ufb01rst phase involves setting the stage for big\ndata processing and includes the selection of big data\nstorage and big data computational framework. The\nsecond phase involves the designing and implementa-\ntion of machine-learning tools for extracting insights\nfrom the data. The paper is divided into seven sections.\nThe \ufb01rst section starts with the general introduction of\nthe topic. The second section outlines the employed\nresearch methodology, highlighting the basis on which\nwe selected the research papers for study and the cri-\nteria for their inclusion in our work. The third\nsection provides an introduction to big data and big\ndata analytics along with various challenges of big data\nanalytics. The fourth section covers details regarding\nbig data infrastructure. The \ufb01fth section provides\ndetails and a comparative analysis of the various\ndistributed data-intensive parallel machine-learning\nalgorithms for big data. The sixth section provides\nsome\nlimitations\nof\nour\nresearch.\nThe\nseventh\nsection\npresents\nthe\nresearch\nimplication\nof\nour\nresearch. The \ufb01nal section contains concluding remarks\nand the future scope of our work.\nRESEARCH METHODOLOGY\nObjective\nThe strong need of extracting relevant information\nfrom a data heap containing humungous and heteroge-\nneous data demands scalable and decentralized analy-\nsis techniques. This is where big data analytics steps\nin. It helps researchers and data scientists in extracting\nuseful insights from the data deluge. Traditional\nmachine-learning algorithms need to be adapted to the\nbig data realm for handling big data scalability. The\nobjective of this paper is to provide a solid base for\nscalable machine-learning algorithms for big data ana-\nlytics. The study covers an overview regarding big data\nstorage and big data computational frameworks along\nwith a survey of distributed parallel data-intensive\nalgorithms for big data. Although this search may not\nbe completely exhaustive, it provides a good compre-\nhensive base for understanding distributed scalable\nmachine-learning algorithms in the emergent and pro-\nfound \ufb01eld of big data analytics. The paper also pro-\nvides a comparative analysis of scalable machine-\nlearning algorithms on various metrics.\nSearch Process\nThis paper is a qualitative review study based on the\nauthors\u2019 perception from the study of various papers\nrelated to big data analytics. Literature selection\ncriteria employed by authors for deciding on research\npaper inclusions are represented diagrammatically in\nFigure 1. The relevant material was scattered across\nvarious journals, conferences, and book chapters.\nThe online databases that were referred for extract-\ning relevant literature were IEEE, Science Direct,\nHindawi ACM Digital Library, Springer, IGI global,\nand Taylor & Francis Online. The online databases\nwere searched based on descriptors such as \u2018big\ndata,\u2019 \u2018big data analytics,\u2019 \u2018big data challenges,\u2019 \u2018big\ndata\nstorage,\u2019\n\u2018big data\nand\nmachine\nlearning,\u2019\n\u2018machine\nlearning\nalgorithms\nemploying\nMapReduce,\u2019\n\u2018distributed\nparallel\nalgorithm\n&\nMapReduce,\u2019 and \u2018parallel machine learning algo-\nrithms employing Spark,\u2019 which produced various\njournal and conference papers from the year 2008\nto 2016.\nThe literature selection was divided into two\ncategories. One category included the papers related\nto big data infrastructure, and the other included\nscalable machine-learning algorithms for big data.\nThe full text of each article was reviewed to examine\nthe applicability of the article for the review, and\nonly the relevant articles were included. The papers\nthat have achieved parallelism using vertical scaling\nwere rejected. Papers that included distributed paral-\nlel programming without MapReduce or Spark were\nalso rejected.\nKey Factors for Evaluation\nOn the basis of the selected papers, several optimiza-\ntion and evaluation metrics are used to perform a\ncomparative analysis of scalable machine-learning\nalgorithms for big data. The optimization metrics\nused are sampling, indexing, intelligent partitioning,\nspecial data structure, in-memory computation, and\nasynchronous execution. The performance metrics\nused are number of MapReduce jobs, speedup, accu-\nracy, and scalability. The performance metrics also\ninclude the data source validation check and the\ncomparative analysis of the algorithm with the base\ntechnique, which are the effectiveness indicators of\nthe assumption and results made in the algorithm.\nScalable machine-learning algorithms were evaluated\non these metrics to perform a comparative analysis.\nBIG DATA ANALYTICS\nAND ITS CHALLENGES\nBig data analytics has led to data explosion where\ndata from sensors, devices, and networks are col-\nlected and stored without discarding anything from\nit. The data are \ufb02owing at very high rate, and the\nWIREs Data Mining and Knowledge Discovery\nScalable machine-learning algorithms for big data analytics\nVolume 6, November/December 2016\n\u00a9 2016 John Wiley & Sons, Ltd\n195\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68]], "Objective": ["paper, an overview of big data analytics is provided.\nThe task of big data analytics is divided into two\nphases. The \ufb01rst phase involves setting the stage for big\ndata processing and includes the selection of big data\nstorage and big data computational framework. The\nsecond phase involves the designing and implementa-\ntion of machine-learning tools for extracting insights\nfrom the data. The paper is divided into seven sections.\nThe \ufb01rst section starts with the general introduction of\nthe topic. The second section outlines the employed\nresearch methodology, highlighting the basis on which\nwe selected the research papers for study and the cri-\nteria for their inclusion in our work. The third\nsection provides an introduction to big data and big\ndata analytics along with various challenges of big data\nanalytics. The fourth section covers details regarding\nbig data infrastructure. The \ufb01fth section provides\ndetails and a comparative analysis of the various\ndistributed data-intensive parallel machine-learning\nalgorithms for big data. The sixth section provides\nsome\nlimitations\nof\nour\nresearch.\nThe\nseventh\nsection\npresents\nthe\nresearch\nimplication\nof\nour\nresearch. The \ufb01nal section contains concluding remarks\nand the future scope of our work.\nRESEARCH METHODOLOGY\nObjective\nThe strong need of extracting relevant information\nfrom a data heap containing humungous and heteroge-\nneous data demands scalable and decentralized analy-\nsis techniques. This is where big data analytics steps\nin. It helps researchers and data scientists in extracting\nuseful insights from the data deluge. Traditional\nmachine-learning algorithms need to be adapted to the\nbig data realm for handling big data scalability. The\nobjective of this paper is to provide a solid base for\nscalable machine-learning algorithms for big data ana-\nlytics. The study covers an overview regarding big data\nstorage and big data computational frameworks along\nwith a survey of distributed parallel data-intensive\nalgorithms for big data. Although this search may not\nbe completely exhaustive, it provides a good compre-\nhensive base for understanding distributed scalable\nmachine-learning algorithms in the emergent and pro-\nfound \ufb01eld of big data analytics. The paper also pro-\nvides a comparative analysis of scalable machine-\nlearning algorithms on various metrics.\nSearch Process\nThis paper is a qualitative review study based on the\nauthors\u2019 perception from the study of various papers\nrelated to big data analytics. Literature selection\ncriteria employed by authors for deciding on research\npaper inclusions are represented diagrammatically in\nFigure 1. The relevant material was scattered across\nvarious journals, conferences, and book chapters.\nThe online databases that were referred for extract-\ning relevant literature were IEEE, Science Direct,\nHindawi ACM Digital Library, Springer, IGI global,\nand Taylor & Francis Online. The online databases\nwere searched based on descriptors such as \u2018big\ndata,\u2019 \u2018big data analytics,\u2019 \u2018big data challenges,\u2019 \u2018big\ndata\nstorage,\u2019\n\u2018big data\nand\nmachine\nlearning,\u2019\n\u2018machine\nlearning\nalgorithms\nemploying\nMapReduce,\u2019\n\u2018distributed\nparallel\nalgorithm\n&\nMapReduce,\u2019 and \u2018parallel machine learning algo-\nrithms employing Spark,\u2019 which produced various\njournal and conference papers from the year 2008\nto 2016.\nThe literature selection was divided into two\ncategories. One category included the papers related\nto big data infrastructure, and the other included\nscalable machine-learning algorithms for big data.\nThe full text of each article was reviewed to examine\nthe applicability of the article for the review, and\nonly the relevant articles were included. The papers\nthat have achieved parallelism using vertical scaling\nwere rejected. Papers that included distributed paral-\nlel programming without MapReduce or Spark were\nalso rejected.\nKey Factors for Evaluation\nOn the basis of the selected papers, several optimiza-\ntion and evaluation metrics are used to perform a\ncomparative analysis of scalable machine-learning\nalgorithms for big data. The optimization metrics\nused are sampling, indexing, intelligent partitioning,\nspecial data structure, in-memory computation, and\nasynchronous execution. The performance metrics\nused are number of MapReduce jobs, speedup, accu-\nracy, and scalability. The performance metrics also\ninclude the data source validation check and the\ncomparative analysis of the algorithm with the base\ntechnique, which are the effectiveness indicators of\nthe assumption and results made in the algorithm.\nScalable machine-learning algorithms were evaluated\non these metrics to perform a comparative analysis.\nBIG DATA ANALYTICS\nAND ITS CHALLENGES\nBig data analytics has led to data explosion where\ndata from sensors, devices, and networks are col-\nlected and stored without discarding anything from\nit. The data are \ufb02owing at very high rate, and the\nWIREs Data Mining and Knowledge Discovery\nScalable machine-learning algorithms for big data analytics\nVolume 6, November/December 2016\n\u00a9 2016 John Wiley & Sons, Ltd\n195\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68]], "RESEARCH METHODOLOGY": ["paper, an overview of big data analytics is provided.\nThe task of big data analytics is divided into two\nphases. The \ufb01rst phase involves setting the stage for big\ndata processing and includes the selection of big data\nstorage and big data computational framework. The\nsecond phase involves the designing and implementa-\ntion of machine-learning tools for extracting insights\nfrom the data. The paper is divided into seven sections.\nThe \ufb01rst section starts with the general introduction of\nthe topic. The second section outlines the employed\nresearch methodology, highlighting the basis on which\nwe selected the research papers for study and the cri-\nteria for their inclusion in our work. The third\nsection provides an introduction to big data and big\ndata analytics along with various challenges of big data\nanalytics. The fourth section covers details regarding\nbig data infrastructure. The \ufb01fth section provides\ndetails and a comparative analysis of the various\ndistributed data-intensive parallel machine-learning\nalgorithms for big data. The sixth section provides\nsome\nlimitations\nof\nour\nresearch.\nThe\nseventh\nsection\npresents\nthe\nresearch\nimplication\nof\nour\nresearch. The \ufb01nal section contains concluding remarks\nand the future scope of our work.\nRESEARCH METHODOLOGY\nObjective\nThe strong need of extracting relevant information\nfrom a data heap containing humungous and heteroge-\nneous data demands scalable and decentralized analy-\nsis techniques. This is where big data analytics steps\nin. It helps researchers and data scientists in extracting\nuseful insights from the data deluge. Traditional\nmachine-learning algorithms need to be adapted to the\nbig data realm for handling big data scalability. The\nobjective of this paper is to provide a solid base for\nscalable machine-learning algorithms for big data ana-\nlytics. The study covers an overview regarding big data\nstorage and big data computational frameworks along\nwith a survey of distributed parallel data-intensive\nalgorithms for big data. Although this search may not\nbe completely exhaustive, it provides a good compre-\nhensive base for understanding distributed scalable\nmachine-learning algorithms in the emergent and pro-\nfound \ufb01eld of big data analytics. The paper also pro-\nvides a comparative analysis of scalable machine-\nlearning algorithms on various metrics.\nSearch Process\nThis paper is a qualitative review study based on the\nauthors\u2019 perception from the study of various papers\nrelated to big data analytics. Literature selection\ncriteria employed by authors for deciding on research\npaper inclusions are represented diagrammatically in\nFigure 1. The relevant material was scattered across\nvarious journals, conferences, and book chapters.\nThe online databases that were referred for extract-\ning relevant literature were IEEE, Science Direct,\nHindawi ACM Digital Library, Springer, IGI global,\nand Taylor & Francis Online. The online databases\nwere searched based on descriptors such as \u2018big\ndata,\u2019 \u2018big data analytics,\u2019 \u2018big data challenges,\u2019 \u2018big\ndata\nstorage,\u2019\n\u2018big data\nand\nmachine\nlearning,\u2019\n\u2018machine\nlearning\nalgorithms\nemploying\nMapReduce,\u2019\n\u2018distributed\nparallel\nalgorithm\n&\nMapReduce,\u2019 and \u2018parallel machine learning algo-\nrithms employing Spark,\u2019 which produced various\njournal and conference papers from the year 2008\nto 2016.\nThe literature selection was divided into two\ncategories. One category included the papers related\nto big data infrastructure, and the other included\nscalable machine-learning algorithms for big data.\nThe full text of each article was reviewed to examine\nthe applicability of the article for the review, and\nonly the relevant articles were included. The papers\nthat have achieved parallelism using vertical scaling\nwere rejected. Papers that included distributed paral-\nlel programming without MapReduce or Spark were\nalso rejected.\nKey Factors for Evaluation\nOn the basis of the selected papers, several optimiza-\ntion and evaluation metrics are used to perform a\ncomparative analysis of scalable machine-learning\nalgorithms for big data. The optimization metrics\nused are sampling, indexing, intelligent partitioning,\nspecial data structure, in-memory computation, and\nasynchronous execution. The performance metrics\nused are number of MapReduce jobs, speedup, accu-\nracy, and scalability. The performance metrics also\ninclude the data source validation check and the\ncomparative analysis of the algorithm with the base\ntechnique, which are the effectiveness indicators of\nthe assumption and results made in the algorithm.\nScalable machine-learning algorithms were evaluated\non these metrics to perform a comparative analysis.\nBIG DATA ANALYTICS\nAND ITS CHALLENGES\nBig data analytics has led to data explosion where\ndata from sensors, devices, and networks are col-\nlected and stored without discarding anything from\nit. The data are \ufb02owing at very high rate, and the\nWIREs Data Mining and Knowledge Discovery\nScalable machine-learning algorithms for big data analytics\nVolume 6, November/December 2016\n\u00a9 2016 John Wiley & Sons, Ltd\n195\n 19424795, 2016, 6, Downloaded from https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1194 by Northeastern University, Wiley Online Library on [12/12/2024]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\n", [68]], "INTRODUCTION": ["Overview\nScalable machine-learning\nalgorithms for big data analytics:\na comprehensive review\nPreeti Gupta,1* Arun Sharma1 and Rajni Jindal2\nBig data analytics is one of the emerging technologies as it promises to provide\nbetter insights from huge and heterogeneous data. Big data analytics involves\nselecting the suitable big data storage and computational framework augmented\nby scalable machine-learning algorithms. Despite the tremendous buzz around\nbig data analytics and its advantages, an extensive literature survey focused on\nparallel data-intensive machine-learning algorithms for big data has not been\nconducted so far. The present paper provides a comprehensive overview of vari-\nous machine-learning algorithms used in big data analytics. The present work is\nan attempt to identify the gaps in the work already performed by researchers,\nthus paving the way for further quality research in parallel scalable algorithms\nfor big data. \u00a9 2016 John Wiley & Sons, Ltd\nHow to cite this article:\nWIREs Data Mining Knowl Discov 2016, 6:194\u2013214. doi: 10.1002/widm.1194\nINTRODUCTION\nT\nhe advent of various technologies such as Social\nNetworks and Internet of Things has led to the\ngeneration of a global network for sharing and colla-\nborating information. The usage and in\ufb02uence of dig-\nital media, especially social media, has grown in every\nsphere of our life. This proliferation has generated a\nhuge amount of data, creating a data deluge. It is dif\ufb01-\ncult to effectively extract useful information from all\nthe available online information due to the volume and\nvariety\n(structured/semistructured/unstructured)\nof\ndata. However, the foundation of a good analytical\nframework relies totally on the quality of data; the\nricher the dataset, the better the inferences. The over-\nwhelming amount of data necessitates mechanisms for\nef\ufb01cient information \ufb01ltering and processing. Distribu-\nted parallelism is the default choice for processing volu-\nminous datasets as it enables faster execution of the job\nwith optimal utilization of computational resources. It\nis not the case, however, that earlier parallel distributed\nmechanisms of processing did not exist. Mechanisms\nsuch as MPI (Message Passing Interface) were available\nin the past literature. However, the major advantage of\nbig data frameworks such as MapReduce and Spark\nover other parallel distributed system is that it relieves\nthe programmer from the burden of code and data dis-\ntribution, replication, machine failures, and load balan-\ncing, which is taken care of by the underlying runtime\nsystem automatically. This is the main reason why big\ndata analytics has drawn so much attention from aca-\ndemicians and researchers. It allows the collecting or\ncrowding sense of data from multiple heterogeneous\nsources and aids in extracting useful insights more eas-\nily from the huge and heterogeneous datasets.\nA large amount of research is being conducted in\nthe evolving and multifaceted area of big data analyt-\nics. However, despite the tremendous interest in big\ndata analytics and its advantages, an extensive litera-\nture survey focused on parallel data-intensive machine-\nlearning algorithms for big data has not been con-\nducted so far. This has encouraged us to provide a\ncomprehensive survey of distributed parallel machine-\nlearning algorithms for big data along with various\noptimization and performance metrics for evaluation.\nThis is also the motivation of our paper. In the present\n*Correspondence to: preeti.cool80@gmail.com\n1Department of IT, Indira Gandhi Delhi Technical University for\nWomen (IGDTUW), New Delhi, India\n2Department of CSE, Delhi Technological University (DTU), Delhi,\nIndia\nCon\ufb02ict of interest: The authors have declared no con\ufb02icts of inter-\nest for this article.\n194\n\u00a9 2016 John Wiley & Sons, Ltd\nVolume 6, November/December 2016\n", [319, 68]], " Scalable machine-learning algorithms for big data analytics: a comprehensive review": ["Overview\nScalable machine-learning\nalgorithms for big data analytics:\na comprehensive review\nPreeti Gupta,1* Arun Sharma1 and Rajni Jindal2\nBig data analytics is one of the emerging technologies as it promises to provide\nbetter insights from huge and heterogeneous data. Big data analytics involves\nselecting the suitable big data storage and computational framework augmented\nby scalable machine-learning algorithms. Despite the tremendous buzz around\nbig data analytics and its advantages, an extensive literature survey focused on\nparallel data-intensive machine-learning algorithms for big data has not been\nconducted so far. The present paper provides a comprehensive overview of vari-\nous machine-learning algorithms used in big data analytics. The present work is\nan attempt to identify the gaps in the work already performed by researchers,\nthus paving the way for further quality research in parallel scalable algorithms\nfor big data. \u00a9 2016 John Wiley & Sons, Ltd\nHow to cite this article:\nWIREs Data Mining Knowl Discov 2016, 6:194\u2013214. doi: 10.1002/widm.1194\nINTRODUCTION\nT\nhe advent of various technologies such as Social\nNetworks and Internet of Things has led to the\ngeneration of a global network for sharing and colla-\nborating information. The usage and in\ufb02uence of dig-\nital media, especially social media, has grown in every\nsphere of our life. This proliferation has generated a\nhuge amount of data, creating a data deluge. It is dif\ufb01-\ncult to effectively extract useful information from all\nthe available online information due to the volume and\nvariety\n(structured/semistructured/unstructured)\nof\ndata. However, the foundation of a good analytical\nframework relies totally on the quality of data; the\nricher the dataset, the better the inferences. The over-\nwhelming amount of data necessitates mechanisms for\nef\ufb01cient information \ufb01ltering and processing. Distribu-\nted parallelism is the default choice for processing volu-\nminous datasets as it enables faster execution of the job\nwith optimal utilization of computational resources. It\nis not the case, however, that earlier parallel distributed\nmechanisms of processing did not exist. Mechanisms\nsuch as MPI (Message Passing Interface) were available\nin the past literature. However, the major advantage of\nbig data frameworks such as MapReduce and Spark\nover other parallel distributed system is that it relieves\nthe programmer from the burden of code and data dis-\ntribution, replication, machine failures, and load balan-\ncing, which is taken care of by the underlying runtime\nsystem automatically. This is the main reason why big\ndata analytics has drawn so much attention from aca-\ndemicians and researchers. It allows the collecting or\ncrowding sense of data from multiple heterogeneous\nsources and aids in extracting useful insights more eas-\nily from the huge and heterogeneous datasets.\nA large amount of research is being conducted in\nthe evolving and multifaceted area of big data analyt-\nics. However, despite the tremendous interest in big\ndata analytics and its advantages, an extensive litera-\nture survey focused on parallel data-intensive machine-\nlearning algorithms for big data has not been con-\nducted so far. This has encouraged us to provide a\ncomprehensive survey of distributed parallel machine-\nlearning algorithms for big data along with various\noptimization and performance metrics for evaluation.\nThis is also the motivation of our paper. In the present\n*Correspondence to: preeti.cool80@gmail.com\n1Department of IT, Indira Gandhi Delhi Technical University for\nWomen (IGDTUW), New Delhi, India\n2Department of CSE, Delhi Technological University (DTU), Delhi,\nIndia\nCon\ufb02ict of interest: The authors have declared no con\ufb02icts of inter-\nest for this article.\n194\n\u00a9 2016 John Wiley & Sons, Ltd\nVolume 6, November/December 2016\n", [319]]}