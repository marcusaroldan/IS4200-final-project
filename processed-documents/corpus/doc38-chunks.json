{"Publisher's note": ["114. Weiss SM, Baseman RJ, Tipu F, Collins CN, Davies WA,\nSingh R, Hopkins JW (2010) Rule-based data mining for\nyield improvement in semiconductor manufacturing. Appl Intell\n33(3):318\u2013329\n115. Weiss SM, Dhurandhar A, Baseman RJ (2013) Improving\nquality control by early prediction of manufacturing outcomes. In:\nProceedings of the 19th ACM SIGKDD international conference\non Knowledge discovery and data mining. ACM, pp 1258\u20131266\n116. Weiss SM, Dhurandhar A, Baseman RJ, White BF, Logan\nR, Winslow JK, Poindexter D (2016) Continuous prediction of\nmanufacturing performance throughout the production lifecycle. J\nIntell Manuf 27(4):751\u2013763\n117. Wu Z, Huang NE (2009) Ensemble empirical mode decomposi-\ntion: a noise-assisted data analysis method. Adv Adapt Data Anal\n01(01):1\u201341\n118. Wuest T, Weimer D, Irgens C, Thoben KD (2016) Machine learn-\ning in manufacturing: advantages, challenges, and applications.\nProd Manuf Res 4(1):23\u201345\n119. Xu G, Yang Z (2015) Multiobjective optimization of process\nparameters for plastic injection molding via soft computing and\ngrey correlation analysis. Int J Adv Manuf Technol 78(1-4):525\u2013\n536\n120. Yin S, Ding SX, Xie X, Luo H (2014) A review on basic data-\ndriven approaches for industrial process monitoring. IEEE Trans\nInd Electron 61(11):6418\u20136428\n121. Yun JP, Choi DC, Jeon YJ, Park C, Kim SW (2014) Defect\ninspection system for steel wire rods produced by hot rolling\nprocess. Int J Adv Manuf Technol 70(9-12):1625\u20131634\n122. Yusup N, Zain AM, Hashim SZM (2012) Evolutionary tech-\nniques in optimizing machining parameters: Review and recent\napplications (2007\u20132011). Expert Syst Appl 39(10):9909\u20139927\n123. Zain AM, Haron H, Sharif S (2008) An overview of ga technique\nfor surface roughness optimization in milling process. 2008 Int\nSympos Inf Technol 4:1\u20136\n124. Zain AM, Haron H, Sharif S (2011) Optimization of process\nparameters in the abrasive waterjet machining using integrated\nsa\u2013ga. Appl Soft Comput 11(8):5350\u20135359\n125. Zain AM, Haron H, Sharif S (2012) Integrated ann\u2013ga for\nestimating the minimum value for machining performance. Int J\nProd Res 50(1):191\u2013213\n126. Zhang L, Jia Z, Wang F, Liu W (2010) A hybrid model using\nsupporting vector machine and multi-objective genetic algorithm\nfor processing parameters optimization in micro-edm. Int J Adv\nManuf Technol 51(5-8):575\u2013586\n127. Zhang W, Jia MP, Zhu L, Yan XA (2017) Comprehensive\noverview on computational intelligence techniques for machinery\ncondition monitoring and fault diagnosis. Chin J Mech Eng\n30(4):782\u2013795\n128. Zhao T, Shi Y, Lin X, Duan J, Sun P, Zhang J (2014) Surface\nroughness prediction and parameters optimization in grinding and\npolishing process for ibr of aero-engine. Int J Adv Manuf Technol\n74(5-8):653\u2013663\nPublisher\u2019s note Springer Nature remains neutral with regard to\njurisdictional claims in published maps and institutional affiliations.\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1902\n", []], "References": ["Yet another future research topic could be the simplifica-\ntion of machines and the use of larger tolerances of the raw\nmaterial. Machine learning\u2013based optimization techniques\nmight face the higher requirements of the processing steps,\nensuring unvarying quality, and simultaneously reducing the\ncosts of machines and the raw material.\nAcknowledgments This work was supported by Fraunhofer Cluster of\nExcellence \u201cCognitive Internet Technologies.\u201d\nFunding information This work is part of the Fraunhofer Lighthouse\nProject ML4P (Machine Learning for Production).\nReferences\n1. Adibi MA, Shahrabi J (2014) A clustering-based modified\nvariable neighborhood search algorithm for a dynamic job shop\nscheduling problem. Int J Adv Manuf Technol 70(9):1955\u20131961\n2. Adibi\nMA,\nZandieh\nM,\nAmiri\nM\n(2010)\nMulti-objective\nscheduling of dynamic job shop using variable neighborhood\nsearch. Expert Syst Appl 37(1):282\u2013287\n3. Ahmad R, Kamaruddin S (2012) An overview of time-based and\ncondition-based maintenance in industrial application. Comput\nInd Eng 63(1):135\u2013149\n4. Apte C, Weiss S, Grout G Predicting defects in disk drive\nmanufacturing: a case study in high-dimensional classification. in:\nCAIA. IEEE Computer Society Press, Los Alamitos, pp 212\u2013218\n5. Arif F, Suryana N, Hussin B (2013) Cascade quality prediction\nmethod using multiple pca+id3 for multi-stage manufacturing\nsystem. IERI Procedia 4:201\u2013207\n6. Assarzadeh S, Ghoreishi M (2008) Neural-network-based model-\ning and optimization of the electro-discharge machining process.\nInt J Adv Manuf Technol 39(5-6):488\u2013500\n7. Batista G, Prati R, Monard M (2004) A study of the behavior\nof several methods for balancing machine learning training data.\nACM SIGKDD Explor Newslett 6(1):20\u201329\n8. Bellini A, Filippetti F, Tassoni C, Capolino GA (2008) Advances\nin diagnostic techniques for induction machines. IEEE Trans Ind\nElectron 55(12):4109\u20134126\n9. Bouacha K, Terrab A (2016) Hard turning behavior improvement\nusing nsga-ii and pso-nn hybrid model. Int J Adv Manuf Technol\n86(9-12):3527\u20133546\n10. Braha D (2001) Data mining for design and manufacturing:\nMethods and applications massive computing, vol 3. Springer,\nBoston\n11. Calder J, Sapsford R (2006) Statistical techniques. In: Sapsford R,\nJupp V (eds) Data collection and analysis. Sage Publications Ltd,\nLondon, pp 208\u2013242\n12. Cao WD, Yan CP, Ding L, Ma Y (2016) A continuous\noptimization decision making of process parameters in high-speed\ngear hobbing using ibpnn/de algorithm. Int J Adv Manuf Technol\n85(9-12):2657\u20132667\n13. Cassady CR, Kutanoglu E (2005) Integrating preventive mainte-\nnance planning and production scheduling for a single machine.\nIEEE Trans Reliab 54(2):304\u2013309\n14. Ceglarek D, Prakash PK (2012) Enhanced piecewise least squares\napproach for diagnosis of ill-conditioned multistation assembly\nwith compliant parts. Proc Inst Mech Eng Part B: J Eng Manuf\n226(3):485\u2013502\n15. Chandrasekaran M, Muralidhar M, Krishna CM, Dixit US\n(2010) Application of soft computing techniques in machining\nperformance prediction and optimization: a literature review. Int J\nAdv Manuf Technol 46(5):445\u2013464\n16. Chen H, Boning D (2017) Online and incremental machine learn-\ning approaches for ic yield improvement. In: 2017 IEEE/ACM\nInternational conference on computer-aided design (ICCAD),\nIrvine, pp pp 786\u2013793\n17. Chen SH, Perng DB (2011) Directional textures auto-inspection\nusing principal component analysis. Int J Adv Manuf Technol\n55(9):1099\u20131110\n18. Chen WC, Fu GL, Tai PH, Deng WJ (2009) Process parameter\noptimization for mimo plastic injection molding via soft\ncomputing. Expert Syst Appl 36(2):1114\u20131122\n19. Chen Z, Li X, Wang L, Zhang S, Cao Y, Jiang S, Rong Y (2018)\nDevelopment of a hybrid particle swarm optimization algorithm\nfor multi-pass roller grinding process optimization. Int J Adv\nManuf Technol 99(1-4):97\u2013112\n20. Cheng H, Chen H (2014) Online parameter optimization in robotic\nforce controlled assembly processes. In: 2014 IEEE International\nconference on robotics and automation (ICRA). Piscataway, pp\n3465\u20133470\n21. Chien CF, Chuang SC (2014) A framework for root cause\ndetection of sub-batch processing system for semiconductor\nmanufacturing big data analytics. IEEE Trans Semicond Manuf\n27(4):475\u2013488\n22. Chien CF, Hsu CY, Chen PN (2013) Semiconductor fault detec-\ntion and classification for yield enhancement and manufacturing\nintelligence. Flex Serv Manuf J 25(3):367\u2013388\n23. Chien CF, Liu CW, Chuang SC (2017) Analysing semiconductor\nmanufacturing big data for root cause detection of excursion for\nyield enhancement. Int J Prod Res 55(17):5095\u20135107\n24. Chien CF, Wang WC, Cheng J (2007) Data mining for yield\nenhancement in semiconductor manufacturing and an empirical\nstudy. Expert Syst Appl 33(1):192\u2013198\n25. Colosimo BM, Pagani L, Strano M (2015) Reduction of\ncalibration effort in fem-based optimization via numerical and\nexperimental data fusion. Struct Multidiscip Optim 51(2):463\u2013478\n26. Coppel R, Abellan-Nebot JV, Siller HR, Rodriguez CA, Guedea\nF (2016) Adaptive control optimization in micro-milling of\nhardened steels\u2014evaluation of optimization approaches. Int J Adv\nManuf Technol 84(9-12):2219\u20132238\n27. Demetgul M, Tansel IN, Taskin S (2009) Fault diagnosis of\npneumatic systems with artificial neural network algorithms.\nExpert Syst Appl 36(7):10,512\u201310,519\n28. Denkena B, Dittrich MA, Uhlich F (2016) Self-optimizing cutting\nprocess using learning process models. Procedia Technol 26:221\u2013\n226\n29. Dhas JER, Kumanan S (2011) Optimization of parameters of\nsubmerged arc weld using non conventional techniques. Appl Soft\nComput 11(8):5198\u20135204\n30. Diao G, Zhao L, Yao Y (2015) A dynamic quality control\napproach by improving dominant factors based on improved\nprincipal component analysis. Int J Prod Res 53(14):4287\u20134303\n31. Fernandes C, Pontes AJ, Viana JC, Gaspar-Cunha A (2018)\nModeling and optimization of the injection-molding process: a\nreview. Adv Polym Technol 37(2):429\u2013449\n32. Franciosa P, Palit A, Vitolo F, Ceglarek D (2017) Rapid response\ndiagnosis of multi-stage assembly process with compliant non-\nideal parts using self-evolving measurement system. Procedia\nCIRP 60:38\u201343\n33. Gao RX, Yan R (2011) Wavelets. Springer, Boston\n34. Genna S, Simoncini A, Tagliaferri V, Ucciardello N (2017) Opti-\nmization of the sandblasting process for a better electrodeposition\nof copper thin films on aluminum substrate by feedforward neural\nnetwork. Procedia CIRP 62:435\u2013439\n35. Grzegorzewski P, Kocha\u00b4nski A, Kacprzyk J (2019) Soft Modeling\nin Industrial Manufacturing. Springer, Berlin\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1899\n", []], "Funding information": ["Yet another future research topic could be the simplifica-\ntion of machines and the use of larger tolerances of the raw\nmaterial. Machine learning\u2013based optimization techniques\nmight face the higher requirements of the processing steps,\nensuring unvarying quality, and simultaneously reducing the\ncosts of machines and the raw material.\nAcknowledgments This work was supported by Fraunhofer Cluster of\nExcellence \u201cCognitive Internet Technologies.\u201d\nFunding information This work is part of the Fraunhofer Lighthouse\nProject ML4P (Machine Learning for Production).\nReferences\n1. Adibi MA, Shahrabi J (2014) A clustering-based modified\nvariable neighborhood search algorithm for a dynamic job shop\nscheduling problem. Int J Adv Manuf Technol 70(9):1955\u20131961\n2. Adibi\nMA,\nZandieh\nM,\nAmiri\nM\n(2010)\nMulti-objective\nscheduling of dynamic job shop using variable neighborhood\nsearch. Expert Syst Appl 37(1):282\u2013287\n3. Ahmad R, Kamaruddin S (2012) An overview of time-based and\ncondition-based maintenance in industrial application. Comput\nInd Eng 63(1):135\u2013149\n4. Apte C, Weiss S, Grout G Predicting defects in disk drive\nmanufacturing: a case study in high-dimensional classification. in:\nCAIA. IEEE Computer Society Press, Los Alamitos, pp 212\u2013218\n5. Arif F, Suryana N, Hussin B (2013) Cascade quality prediction\nmethod using multiple pca+id3 for multi-stage manufacturing\nsystem. IERI Procedia 4:201\u2013207\n6. Assarzadeh S, Ghoreishi M (2008) Neural-network-based model-\ning and optimization of the electro-discharge machining process.\nInt J Adv Manuf Technol 39(5-6):488\u2013500\n7. Batista G, Prati R, Monard M (2004) A study of the behavior\nof several methods for balancing machine learning training data.\nACM SIGKDD Explor Newslett 6(1):20\u201329\n8. Bellini A, Filippetti F, Tassoni C, Capolino GA (2008) Advances\nin diagnostic techniques for induction machines. IEEE Trans Ind\nElectron 55(12):4109\u20134126\n9. Bouacha K, Terrab A (2016) Hard turning behavior improvement\nusing nsga-ii and pso-nn hybrid model. Int J Adv Manuf Technol\n86(9-12):3527\u20133546\n10. Braha D (2001) Data mining for design and manufacturing:\nMethods and applications massive computing, vol 3. Springer,\nBoston\n11. Calder J, Sapsford R (2006) Statistical techniques. In: Sapsford R,\nJupp V (eds) Data collection and analysis. Sage Publications Ltd,\nLondon, pp 208\u2013242\n12. Cao WD, Yan CP, Ding L, Ma Y (2016) A continuous\noptimization decision making of process parameters in high-speed\ngear hobbing using ibpnn/de algorithm. Int J Adv Manuf Technol\n85(9-12):2657\u20132667\n13. Cassady CR, Kutanoglu E (2005) Integrating preventive mainte-\nnance planning and production scheduling for a single machine.\nIEEE Trans Reliab 54(2):304\u2013309\n14. Ceglarek D, Prakash PK (2012) Enhanced piecewise least squares\napproach for diagnosis of ill-conditioned multistation assembly\nwith compliant parts. Proc Inst Mech Eng Part B: J Eng Manuf\n226(3):485\u2013502\n15. Chandrasekaran M, Muralidhar M, Krishna CM, Dixit US\n(2010) Application of soft computing techniques in machining\nperformance prediction and optimization: a literature review. Int J\nAdv Manuf Technol 46(5):445\u2013464\n16. Chen H, Boning D (2017) Online and incremental machine learn-\ning approaches for ic yield improvement. In: 2017 IEEE/ACM\nInternational conference on computer-aided design (ICCAD),\nIrvine, pp pp 786\u2013793\n17. Chen SH, Perng DB (2011) Directional textures auto-inspection\nusing principal component analysis. Int J Adv Manuf Technol\n55(9):1099\u20131110\n18. Chen WC, Fu GL, Tai PH, Deng WJ (2009) Process parameter\noptimization for mimo plastic injection molding via soft\ncomputing. Expert Syst Appl 36(2):1114\u20131122\n19. Chen Z, Li X, Wang L, Zhang S, Cao Y, Jiang S, Rong Y (2018)\nDevelopment of a hybrid particle swarm optimization algorithm\nfor multi-pass roller grinding process optimization. Int J Adv\nManuf Technol 99(1-4):97\u2013112\n20. Cheng H, Chen H (2014) Online parameter optimization in robotic\nforce controlled assembly processes. In: 2014 IEEE International\nconference on robotics and automation (ICRA). Piscataway, pp\n3465\u20133470\n21. Chien CF, Chuang SC (2014) A framework for root cause\ndetection of sub-batch processing system for semiconductor\nmanufacturing big data analytics. IEEE Trans Semicond Manuf\n27(4):475\u2013488\n22. Chien CF, Hsu CY, Chen PN (2013) Semiconductor fault detec-\ntion and classification for yield enhancement and manufacturing\nintelligence. Flex Serv Manuf J 25(3):367\u2013388\n23. Chien CF, Liu CW, Chuang SC (2017) Analysing semiconductor\nmanufacturing big data for root cause detection of excursion for\nyield enhancement. Int J Prod Res 55(17):5095\u20135107\n24. Chien CF, Wang WC, Cheng J (2007) Data mining for yield\nenhancement in semiconductor manufacturing and an empirical\nstudy. Expert Syst Appl 33(1):192\u2013198\n25. Colosimo BM, Pagani L, Strano M (2015) Reduction of\ncalibration effort in fem-based optimization via numerical and\nexperimental data fusion. Struct Multidiscip Optim 51(2):463\u2013478\n26. Coppel R, Abellan-Nebot JV, Siller HR, Rodriguez CA, Guedea\nF (2016) Adaptive control optimization in micro-milling of\nhardened steels\u2014evaluation of optimization approaches. Int J Adv\nManuf Technol 84(9-12):2219\u20132238\n27. Demetgul M, Tansel IN, Taskin S (2009) Fault diagnosis of\npneumatic systems with artificial neural network algorithms.\nExpert Syst Appl 36(7):10,512\u201310,519\n28. Denkena B, Dittrich MA, Uhlich F (2016) Self-optimizing cutting\nprocess using learning process models. Procedia Technol 26:221\u2013\n226\n29. Dhas JER, Kumanan S (2011) Optimization of parameters of\nsubmerged arc weld using non conventional techniques. Appl Soft\nComput 11(8):5198\u20135204\n30. Diao G, Zhao L, Yao Y (2015) A dynamic quality control\napproach by improving dominant factors based on improved\nprincipal component analysis. Int J Prod Res 53(14):4287\u20134303\n31. Fernandes C, Pontes AJ, Viana JC, Gaspar-Cunha A (2018)\nModeling and optimization of the injection-molding process: a\nreview. Adv Polym Technol 37(2):429\u2013449\n32. Franciosa P, Palit A, Vitolo F, Ceglarek D (2017) Rapid response\ndiagnosis of multi-stage assembly process with compliant non-\nideal parts using self-evolving measurement system. Procedia\nCIRP 60:38\u201343\n33. Gao RX, Yan R (2011) Wavelets. Springer, Boston\n34. Genna S, Simoncini A, Tagliaferri V, Ucciardello N (2017) Opti-\nmization of the sandblasting process for a better electrodeposition\nof copper thin films on aluminum substrate by feedforward neural\nnetwork. Procedia CIRP 62:435\u2013439\n35. Grzegorzewski P, Kocha\u00b4nski A, Kacprzyk J (2019) Soft Modeling\nin Industrial Manufacturing. Springer, Berlin\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1899\n", []], "Acknowledgments": ["Yet another future research topic could be the simplifica-\ntion of machines and the use of larger tolerances of the raw\nmaterial. Machine learning\u2013based optimization techniques\nmight face the higher requirements of the processing steps,\nensuring unvarying quality, and simultaneously reducing the\ncosts of machines and the raw material.\nAcknowledgments This work was supported by Fraunhofer Cluster of\nExcellence \u201cCognitive Internet Technologies.\u201d\nFunding information This work is part of the Fraunhofer Lighthouse\nProject ML4P (Machine Learning for Production).\nReferences\n1. Adibi MA, Shahrabi J (2014) A clustering-based modified\nvariable neighborhood search algorithm for a dynamic job shop\nscheduling problem. Int J Adv Manuf Technol 70(9):1955\u20131961\n2. Adibi\nMA,\nZandieh\nM,\nAmiri\nM\n(2010)\nMulti-objective\nscheduling of dynamic job shop using variable neighborhood\nsearch. Expert Syst Appl 37(1):282\u2013287\n3. Ahmad R, Kamaruddin S (2012) An overview of time-based and\ncondition-based maintenance in industrial application. Comput\nInd Eng 63(1):135\u2013149\n4. Apte C, Weiss S, Grout G Predicting defects in disk drive\nmanufacturing: a case study in high-dimensional classification. in:\nCAIA. IEEE Computer Society Press, Los Alamitos, pp 212\u2013218\n5. Arif F, Suryana N, Hussin B (2013) Cascade quality prediction\nmethod using multiple pca+id3 for multi-stage manufacturing\nsystem. IERI Procedia 4:201\u2013207\n6. Assarzadeh S, Ghoreishi M (2008) Neural-network-based model-\ning and optimization of the electro-discharge machining process.\nInt J Adv Manuf Technol 39(5-6):488\u2013500\n7. Batista G, Prati R, Monard M (2004) A study of the behavior\nof several methods for balancing machine learning training data.\nACM SIGKDD Explor Newslett 6(1):20\u201329\n8. Bellini A, Filippetti F, Tassoni C, Capolino GA (2008) Advances\nin diagnostic techniques for induction machines. IEEE Trans Ind\nElectron 55(12):4109\u20134126\n9. Bouacha K, Terrab A (2016) Hard turning behavior improvement\nusing nsga-ii and pso-nn hybrid model. Int J Adv Manuf Technol\n86(9-12):3527\u20133546\n10. Braha D (2001) Data mining for design and manufacturing:\nMethods and applications massive computing, vol 3. Springer,\nBoston\n11. Calder J, Sapsford R (2006) Statistical techniques. In: Sapsford R,\nJupp V (eds) Data collection and analysis. Sage Publications Ltd,\nLondon, pp 208\u2013242\n12. Cao WD, Yan CP, Ding L, Ma Y (2016) A continuous\noptimization decision making of process parameters in high-speed\ngear hobbing using ibpnn/de algorithm. Int J Adv Manuf Technol\n85(9-12):2657\u20132667\n13. Cassady CR, Kutanoglu E (2005) Integrating preventive mainte-\nnance planning and production scheduling for a single machine.\nIEEE Trans Reliab 54(2):304\u2013309\n14. Ceglarek D, Prakash PK (2012) Enhanced piecewise least squares\napproach for diagnosis of ill-conditioned multistation assembly\nwith compliant parts. Proc Inst Mech Eng Part B: J Eng Manuf\n226(3):485\u2013502\n15. Chandrasekaran M, Muralidhar M, Krishna CM, Dixit US\n(2010) Application of soft computing techniques in machining\nperformance prediction and optimization: a literature review. Int J\nAdv Manuf Technol 46(5):445\u2013464\n16. Chen H, Boning D (2017) Online and incremental machine learn-\ning approaches for ic yield improvement. In: 2017 IEEE/ACM\nInternational conference on computer-aided design (ICCAD),\nIrvine, pp pp 786\u2013793\n17. Chen SH, Perng DB (2011) Directional textures auto-inspection\nusing principal component analysis. Int J Adv Manuf Technol\n55(9):1099\u20131110\n18. Chen WC, Fu GL, Tai PH, Deng WJ (2009) Process parameter\noptimization for mimo plastic injection molding via soft\ncomputing. Expert Syst Appl 36(2):1114\u20131122\n19. Chen Z, Li X, Wang L, Zhang S, Cao Y, Jiang S, Rong Y (2018)\nDevelopment of a hybrid particle swarm optimization algorithm\nfor multi-pass roller grinding process optimization. Int J Adv\nManuf Technol 99(1-4):97\u2013112\n20. Cheng H, Chen H (2014) Online parameter optimization in robotic\nforce controlled assembly processes. In: 2014 IEEE International\nconference on robotics and automation (ICRA). Piscataway, pp\n3465\u20133470\n21. Chien CF, Chuang SC (2014) A framework for root cause\ndetection of sub-batch processing system for semiconductor\nmanufacturing big data analytics. IEEE Trans Semicond Manuf\n27(4):475\u2013488\n22. Chien CF, Hsu CY, Chen PN (2013) Semiconductor fault detec-\ntion and classification for yield enhancement and manufacturing\nintelligence. Flex Serv Manuf J 25(3):367\u2013388\n23. Chien CF, Liu CW, Chuang SC (2017) Analysing semiconductor\nmanufacturing big data for root cause detection of excursion for\nyield enhancement. Int J Prod Res 55(17):5095\u20135107\n24. Chien CF, Wang WC, Cheng J (2007) Data mining for yield\nenhancement in semiconductor manufacturing and an empirical\nstudy. Expert Syst Appl 33(1):192\u2013198\n25. Colosimo BM, Pagani L, Strano M (2015) Reduction of\ncalibration effort in fem-based optimization via numerical and\nexperimental data fusion. Struct Multidiscip Optim 51(2):463\u2013478\n26. Coppel R, Abellan-Nebot JV, Siller HR, Rodriguez CA, Guedea\nF (2016) Adaptive control optimization in micro-milling of\nhardened steels\u2014evaluation of optimization approaches. Int J Adv\nManuf Technol 84(9-12):2219\u20132238\n27. Demetgul M, Tansel IN, Taskin S (2009) Fault diagnosis of\npneumatic systems with artificial neural network algorithms.\nExpert Syst Appl 36(7):10,512\u201310,519\n28. Denkena B, Dittrich MA, Uhlich F (2016) Self-optimizing cutting\nprocess using learning process models. Procedia Technol 26:221\u2013\n226\n29. Dhas JER, Kumanan S (2011) Optimization of parameters of\nsubmerged arc weld using non conventional techniques. Appl Soft\nComput 11(8):5198\u20135204\n30. Diao G, Zhao L, Yao Y (2015) A dynamic quality control\napproach by improving dominant factors based on improved\nprincipal component analysis. Int J Prod Res 53(14):4287\u20134303\n31. Fernandes C, Pontes AJ, Viana JC, Gaspar-Cunha A (2018)\nModeling and optimization of the injection-molding process: a\nreview. Adv Polym Technol 37(2):429\u2013449\n32. Franciosa P, Palit A, Vitolo F, Ceglarek D (2017) Rapid response\ndiagnosis of multi-stage assembly process with compliant non-\nideal parts using self-evolving measurement system. Procedia\nCIRP 60:38\u201343\n33. Gao RX, Yan R (2011) Wavelets. Springer, Boston\n34. Genna S, Simoncini A, Tagliaferri V, Ucciardello N (2017) Opti-\nmization of the sandblasting process for a better electrodeposition\nof copper thin films on aluminum substrate by feedforward neural\nnetwork. Procedia CIRP 62:435\u2013439\n35. Grzegorzewski P, Kocha\u00b4nski A, Kacprzyk J (2019) Soft Modeling\nin Industrial Manufacturing. Springer, Berlin\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1899\n", []], "Future research directions": ["4.4 Applicability in the real process\nIn this section, the authors want to discuss the applicability\nof the different approaches in real production processes.\nFor root cause analysis, the early prediction of manu-\nfacturing outcomes, and diagnostic systems, approaches are\nassumed to work in real life (see e. g. [40, 44, 116]).\nIf process parameters are changed, the application is\nmore critical, due to several reasons. Firstly, as the used\ndata originates from simulations and experiments, it is not\ncertain that it truly represents the real production process.\nSecondly, for a running process, optimization results have\nto be robust. They should be valid for different machines\nand products and should be able to tolerate measurement\noutliers like a crashed sensor. Thirdly, for process chains,\ncertain parameter changes that are valid for a single\nmachine might be inconvertible due to the relationship\nto previous and subsequent process steps. Processing\ntimes cannot change if the process chain shall not get out\nof step.\nA more general problem seems to be the amount of\navailable data, as the analysis in Section 4.2 shows. If that\nis the case, the authors propose to add additional, better\navailable data such as simulation data or to inject knowledge\nusing a gray box approach. Both possibilities can result\nin higher model accuracy and higher acceptance of the\nmodel. More data generally provides the ability to map more\ncomplex processes and to reduce the model\u2019s variance. With\nrespect to the acceptance issue, the authors think that the\nopportunity to improve the model by domain knowledge can\nlower the hurdle to use it. Together with an interpretable\nmodel like the rule mining approach by Kamsu-Foguem\net al. [44], this can help establish appropriate data mining\napproaches for optimization in production.\n5 Conclusion and further aspects\n5.1 Summary\nThe advent of smart manufacturing simplifies the exploita-\ntion of data provided by whole production plants, individual\nmachines, or single sensors, enabling machine learning at\ndifferent stages of complexity. Simultaneously, a shortage\nof resources and the struggle of manufacturers to stay com-\npetitive makes machine learning necessary to spare energy,\ntime, and resources and to reduce waste. As data often\nalready exists in various storages or is cheap to create, the\nstep to its beneficial use is a small one.\nIn this review, the available data types and the use of\nthe data for machine learning in different applications were\ndescribed. The applications vary from the simple setting of\nlearning a valid machine learning model to the combination\nof machine learning with optimization. If only a model\nis learned, it can be used for root cause analysis, the\nearly prediction of manufacturing outcomes, and diagnostic\nsystems to optimize product quality or process efficiency.\nElse, if a model is combined with optimization algorithms,\nit is possible to find production parameters optimal for\na specified loss function. This function can include the\nmentioned constraints on energy, time, and resources and\nwaste or describe a specific measure of the part\u2019s quality.\nThe optimized parameters and their introduction into the\nmachine make the whole production process more flexible\nand adaptive to the different requirements occurring in the\nprocess.\n5.2 Conclusion\nGiven these potentials of optimization, the closer analysis\nof the overall process of data collection, model training,\nand optimization revealed a critical aspect: the connection\nbetween the process complexity, the stored data amount,\nand the model complexity. In the inspected papers, quite\noften, this connection was not respected, leading to complex\nmodels being trained on low amounts of data, risking\noverfitting and/or a lack of interpretability. This aspect can\ngain skepticism toward the application of machine learning\nin the manufacturing industry. To face this challenge, the\nauthors recommend being careful in every step of building\nthe optimization chain and to question the data, the used\nmachine learning methods, and optimizers. Other critical\naspects hindering the optimization of processes via machine\nlearning might be a lack of relevant data or difficulties\nin getting access to the machine\u2019s control systems. All\nthese problems might vanish with time passing to gain\nexpertise, fill storages, and lower hurdles by hard- and\nsoftware.\n5.3 Future research directions\nIn the author\u2019s eyes, machine learning in production is not\nlimited to the before-mentioned improvements. It has the\nspecific chance to improve product quality enormously if\napplied for open-loop control for multi-stage production\nprocesses, as already proposed by Konrad et al. [54],\nLieber et al. [59], and Arif et al. [5]. As product quality\ncan already be predicted at early production stages as\ndone by Weiss et al. [116], one could optimize for the\nbest subsequent machine parameter set to achieve the best\npossible product quality, given the limits of the raw material,\nthe production parameters, and the previous processing\nresults. Thinking bigger, this approach could be extended\nfrom the product-specific stage to machine- and plant-\nspecific stages, improving the overall efficiency taking\nresource, energy, and time restrictions into account.\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1898\n", []], "Conclusion": ["4.4 Applicability in the real process\nIn this section, the authors want to discuss the applicability\nof the different approaches in real production processes.\nFor root cause analysis, the early prediction of manu-\nfacturing outcomes, and diagnostic systems, approaches are\nassumed to work in real life (see e. g. [40, 44, 116]).\nIf process parameters are changed, the application is\nmore critical, due to several reasons. Firstly, as the used\ndata originates from simulations and experiments, it is not\ncertain that it truly represents the real production process.\nSecondly, for a running process, optimization results have\nto be robust. They should be valid for different machines\nand products and should be able to tolerate measurement\noutliers like a crashed sensor. Thirdly, for process chains,\ncertain parameter changes that are valid for a single\nmachine might be inconvertible due to the relationship\nto previous and subsequent process steps. Processing\ntimes cannot change if the process chain shall not get out\nof step.\nA more general problem seems to be the amount of\navailable data, as the analysis in Section 4.2 shows. If that\nis the case, the authors propose to add additional, better\navailable data such as simulation data or to inject knowledge\nusing a gray box approach. Both possibilities can result\nin higher model accuracy and higher acceptance of the\nmodel. More data generally provides the ability to map more\ncomplex processes and to reduce the model\u2019s variance. With\nrespect to the acceptance issue, the authors think that the\nopportunity to improve the model by domain knowledge can\nlower the hurdle to use it. Together with an interpretable\nmodel like the rule mining approach by Kamsu-Foguem\net al. [44], this can help establish appropriate data mining\napproaches for optimization in production.\n5 Conclusion and further aspects\n5.1 Summary\nThe advent of smart manufacturing simplifies the exploita-\ntion of data provided by whole production plants, individual\nmachines, or single sensors, enabling machine learning at\ndifferent stages of complexity. Simultaneously, a shortage\nof resources and the struggle of manufacturers to stay com-\npetitive makes machine learning necessary to spare energy,\ntime, and resources and to reduce waste. As data often\nalready exists in various storages or is cheap to create, the\nstep to its beneficial use is a small one.\nIn this review, the available data types and the use of\nthe data for machine learning in different applications were\ndescribed. The applications vary from the simple setting of\nlearning a valid machine learning model to the combination\nof machine learning with optimization. If only a model\nis learned, it can be used for root cause analysis, the\nearly prediction of manufacturing outcomes, and diagnostic\nsystems to optimize product quality or process efficiency.\nElse, if a model is combined with optimization algorithms,\nit is possible to find production parameters optimal for\na specified loss function. This function can include the\nmentioned constraints on energy, time, and resources and\nwaste or describe a specific measure of the part\u2019s quality.\nThe optimized parameters and their introduction into the\nmachine make the whole production process more flexible\nand adaptive to the different requirements occurring in the\nprocess.\n5.2 Conclusion\nGiven these potentials of optimization, the closer analysis\nof the overall process of data collection, model training,\nand optimization revealed a critical aspect: the connection\nbetween the process complexity, the stored data amount,\nand the model complexity. In the inspected papers, quite\noften, this connection was not respected, leading to complex\nmodels being trained on low amounts of data, risking\noverfitting and/or a lack of interpretability. This aspect can\ngain skepticism toward the application of machine learning\nin the manufacturing industry. To face this challenge, the\nauthors recommend being careful in every step of building\nthe optimization chain and to question the data, the used\nmachine learning methods, and optimizers. Other critical\naspects hindering the optimization of processes via machine\nlearning might be a lack of relevant data or difficulties\nin getting access to the machine\u2019s control systems. All\nthese problems might vanish with time passing to gain\nexpertise, fill storages, and lower hurdles by hard- and\nsoftware.\n5.3 Future research directions\nIn the author\u2019s eyes, machine learning in production is not\nlimited to the before-mentioned improvements. It has the\nspecific chance to improve product quality enormously if\napplied for open-loop control for multi-stage production\nprocesses, as already proposed by Konrad et al. [54],\nLieber et al. [59], and Arif et al. [5]. As product quality\ncan already be predicted at early production stages as\ndone by Weiss et al. [116], one could optimize for the\nbest subsequent machine parameter set to achieve the best\npossible product quality, given the limits of the raw material,\nthe production parameters, and the previous processing\nresults. Thinking bigger, this approach could be extended\nfrom the product-specific stage to machine- and plant-\nspecific stages, improving the overall efficiency taking\nresource, energy, and time restrictions into account.\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1898\n", []], "Summary": ["4.4 Applicability in the real process\nIn this section, the authors want to discuss the applicability\nof the different approaches in real production processes.\nFor root cause analysis, the early prediction of manu-\nfacturing outcomes, and diagnostic systems, approaches are\nassumed to work in real life (see e. g. [40, 44, 116]).\nIf process parameters are changed, the application is\nmore critical, due to several reasons. Firstly, as the used\ndata originates from simulations and experiments, it is not\ncertain that it truly represents the real production process.\nSecondly, for a running process, optimization results have\nto be robust. They should be valid for different machines\nand products and should be able to tolerate measurement\noutliers like a crashed sensor. Thirdly, for process chains,\ncertain parameter changes that are valid for a single\nmachine might be inconvertible due to the relationship\nto previous and subsequent process steps. Processing\ntimes cannot change if the process chain shall not get out\nof step.\nA more general problem seems to be the amount of\navailable data, as the analysis in Section 4.2 shows. If that\nis the case, the authors propose to add additional, better\navailable data such as simulation data or to inject knowledge\nusing a gray box approach. Both possibilities can result\nin higher model accuracy and higher acceptance of the\nmodel. More data generally provides the ability to map more\ncomplex processes and to reduce the model\u2019s variance. With\nrespect to the acceptance issue, the authors think that the\nopportunity to improve the model by domain knowledge can\nlower the hurdle to use it. Together with an interpretable\nmodel like the rule mining approach by Kamsu-Foguem\net al. [44], this can help establish appropriate data mining\napproaches for optimization in production.\n5 Conclusion and further aspects\n5.1 Summary\nThe advent of smart manufacturing simplifies the exploita-\ntion of data provided by whole production plants, individual\nmachines, or single sensors, enabling machine learning at\ndifferent stages of complexity. Simultaneously, a shortage\nof resources and the struggle of manufacturers to stay com-\npetitive makes machine learning necessary to spare energy,\ntime, and resources and to reduce waste. As data often\nalready exists in various storages or is cheap to create, the\nstep to its beneficial use is a small one.\nIn this review, the available data types and the use of\nthe data for machine learning in different applications were\ndescribed. The applications vary from the simple setting of\nlearning a valid machine learning model to the combination\nof machine learning with optimization. If only a model\nis learned, it can be used for root cause analysis, the\nearly prediction of manufacturing outcomes, and diagnostic\nsystems to optimize product quality or process efficiency.\nElse, if a model is combined with optimization algorithms,\nit is possible to find production parameters optimal for\na specified loss function. This function can include the\nmentioned constraints on energy, time, and resources and\nwaste or describe a specific measure of the part\u2019s quality.\nThe optimized parameters and their introduction into the\nmachine make the whole production process more flexible\nand adaptive to the different requirements occurring in the\nprocess.\n5.2 Conclusion\nGiven these potentials of optimization, the closer analysis\nof the overall process of data collection, model training,\nand optimization revealed a critical aspect: the connection\nbetween the process complexity, the stored data amount,\nand the model complexity. In the inspected papers, quite\noften, this connection was not respected, leading to complex\nmodels being trained on low amounts of data, risking\noverfitting and/or a lack of interpretability. This aspect can\ngain skepticism toward the application of machine learning\nin the manufacturing industry. To face this challenge, the\nauthors recommend being careful in every step of building\nthe optimization chain and to question the data, the used\nmachine learning methods, and optimizers. Other critical\naspects hindering the optimization of processes via machine\nlearning might be a lack of relevant data or difficulties\nin getting access to the machine\u2019s control systems. All\nthese problems might vanish with time passing to gain\nexpertise, fill storages, and lower hurdles by hard- and\nsoftware.\n5.3 Future research directions\nIn the author\u2019s eyes, machine learning in production is not\nlimited to the before-mentioned improvements. It has the\nspecific chance to improve product quality enormously if\napplied for open-loop control for multi-stage production\nprocesses, as already proposed by Konrad et al. [54],\nLieber et al. [59], and Arif et al. [5]. As product quality\ncan already be predicted at early production stages as\ndone by Weiss et al. [116], one could optimize for the\nbest subsequent machine parameter set to achieve the best\npossible product quality, given the limits of the raw material,\nthe production parameters, and the previous processing\nresults. Thinking bigger, this approach could be extended\nfrom the product-specific stage to machine- and plant-\nspecific stages, improving the overall efficiency taking\nresource, energy, and time restrictions into account.\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1898\n", []], "Conclusion and further aspects": ["4.4 Applicability in the real process\nIn this section, the authors want to discuss the applicability\nof the different approaches in real production processes.\nFor root cause analysis, the early prediction of manu-\nfacturing outcomes, and diagnostic systems, approaches are\nassumed to work in real life (see e. g. [40, 44, 116]).\nIf process parameters are changed, the application is\nmore critical, due to several reasons. Firstly, as the used\ndata originates from simulations and experiments, it is not\ncertain that it truly represents the real production process.\nSecondly, for a running process, optimization results have\nto be robust. They should be valid for different machines\nand products and should be able to tolerate measurement\noutliers like a crashed sensor. Thirdly, for process chains,\ncertain parameter changes that are valid for a single\nmachine might be inconvertible due to the relationship\nto previous and subsequent process steps. Processing\ntimes cannot change if the process chain shall not get out\nof step.\nA more general problem seems to be the amount of\navailable data, as the analysis in Section 4.2 shows. If that\nis the case, the authors propose to add additional, better\navailable data such as simulation data or to inject knowledge\nusing a gray box approach. Both possibilities can result\nin higher model accuracy and higher acceptance of the\nmodel. More data generally provides the ability to map more\ncomplex processes and to reduce the model\u2019s variance. With\nrespect to the acceptance issue, the authors think that the\nopportunity to improve the model by domain knowledge can\nlower the hurdle to use it. Together with an interpretable\nmodel like the rule mining approach by Kamsu-Foguem\net al. [44], this can help establish appropriate data mining\napproaches for optimization in production.\n5 Conclusion and further aspects\n5.1 Summary\nThe advent of smart manufacturing simplifies the exploita-\ntion of data provided by whole production plants, individual\nmachines, or single sensors, enabling machine learning at\ndifferent stages of complexity. Simultaneously, a shortage\nof resources and the struggle of manufacturers to stay com-\npetitive makes machine learning necessary to spare energy,\ntime, and resources and to reduce waste. As data often\nalready exists in various storages or is cheap to create, the\nstep to its beneficial use is a small one.\nIn this review, the available data types and the use of\nthe data for machine learning in different applications were\ndescribed. The applications vary from the simple setting of\nlearning a valid machine learning model to the combination\nof machine learning with optimization. If only a model\nis learned, it can be used for root cause analysis, the\nearly prediction of manufacturing outcomes, and diagnostic\nsystems to optimize product quality or process efficiency.\nElse, if a model is combined with optimization algorithms,\nit is possible to find production parameters optimal for\na specified loss function. This function can include the\nmentioned constraints on energy, time, and resources and\nwaste or describe a specific measure of the part\u2019s quality.\nThe optimized parameters and their introduction into the\nmachine make the whole production process more flexible\nand adaptive to the different requirements occurring in the\nprocess.\n5.2 Conclusion\nGiven these potentials of optimization, the closer analysis\nof the overall process of data collection, model training,\nand optimization revealed a critical aspect: the connection\nbetween the process complexity, the stored data amount,\nand the model complexity. In the inspected papers, quite\noften, this connection was not respected, leading to complex\nmodels being trained on low amounts of data, risking\noverfitting and/or a lack of interpretability. This aspect can\ngain skepticism toward the application of machine learning\nin the manufacturing industry. To face this challenge, the\nauthors recommend being careful in every step of building\nthe optimization chain and to question the data, the used\nmachine learning methods, and optimizers. Other critical\naspects hindering the optimization of processes via machine\nlearning might be a lack of relevant data or difficulties\nin getting access to the machine\u2019s control systems. All\nthese problems might vanish with time passing to gain\nexpertise, fill storages, and lower hurdles by hard- and\nsoftware.\n5.3 Future research directions\nIn the author\u2019s eyes, machine learning in production is not\nlimited to the before-mentioned improvements. It has the\nspecific chance to improve product quality enormously if\napplied for open-loop control for multi-stage production\nprocesses, as already proposed by Konrad et al. [54],\nLieber et al. [59], and Arif et al. [5]. As product quality\ncan already be predicted at early production stages as\ndone by Weiss et al. [116], one could optimize for the\nbest subsequent machine parameter set to achieve the best\npossible product quality, given the limits of the raw material,\nthe production parameters, and the previous processing\nresults. Thinking bigger, this approach could be extended\nfrom the product-specific stage to machine- and plant-\nspecific stages, improving the overall efficiency taking\nresource, energy, and time restrictions into account.\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1898\n", []], "Applicability in the real process": ["4.4 Applicability in the real process\nIn this section, the authors want to discuss the applicability\nof the different approaches in real production processes.\nFor root cause analysis, the early prediction of manu-\nfacturing outcomes, and diagnostic systems, approaches are\nassumed to work in real life (see e. g. [40, 44, 116]).\nIf process parameters are changed, the application is\nmore critical, due to several reasons. Firstly, as the used\ndata originates from simulations and experiments, it is not\ncertain that it truly represents the real production process.\nSecondly, for a running process, optimization results have\nto be robust. They should be valid for different machines\nand products and should be able to tolerate measurement\noutliers like a crashed sensor. Thirdly, for process chains,\ncertain parameter changes that are valid for a single\nmachine might be inconvertible due to the relationship\nto previous and subsequent process steps. Processing\ntimes cannot change if the process chain shall not get out\nof step.\nA more general problem seems to be the amount of\navailable data, as the analysis in Section 4.2 shows. If that\nis the case, the authors propose to add additional, better\navailable data such as simulation data or to inject knowledge\nusing a gray box approach. Both possibilities can result\nin higher model accuracy and higher acceptance of the\nmodel. More data generally provides the ability to map more\ncomplex processes and to reduce the model\u2019s variance. With\nrespect to the acceptance issue, the authors think that the\nopportunity to improve the model by domain knowledge can\nlower the hurdle to use it. Together with an interpretable\nmodel like the rule mining approach by Kamsu-Foguem\net al. [44], this can help establish appropriate data mining\napproaches for optimization in production.\n5 Conclusion and further aspects\n5.1 Summary\nThe advent of smart manufacturing simplifies the exploita-\ntion of data provided by whole production plants, individual\nmachines, or single sensors, enabling machine learning at\ndifferent stages of complexity. Simultaneously, a shortage\nof resources and the struggle of manufacturers to stay com-\npetitive makes machine learning necessary to spare energy,\ntime, and resources and to reduce waste. As data often\nalready exists in various storages or is cheap to create, the\nstep to its beneficial use is a small one.\nIn this review, the available data types and the use of\nthe data for machine learning in different applications were\ndescribed. The applications vary from the simple setting of\nlearning a valid machine learning model to the combination\nof machine learning with optimization. If only a model\nis learned, it can be used for root cause analysis, the\nearly prediction of manufacturing outcomes, and diagnostic\nsystems to optimize product quality or process efficiency.\nElse, if a model is combined with optimization algorithms,\nit is possible to find production parameters optimal for\na specified loss function. This function can include the\nmentioned constraints on energy, time, and resources and\nwaste or describe a specific measure of the part\u2019s quality.\nThe optimized parameters and their introduction into the\nmachine make the whole production process more flexible\nand adaptive to the different requirements occurring in the\nprocess.\n5.2 Conclusion\nGiven these potentials of optimization, the closer analysis\nof the overall process of data collection, model training,\nand optimization revealed a critical aspect: the connection\nbetween the process complexity, the stored data amount,\nand the model complexity. In the inspected papers, quite\noften, this connection was not respected, leading to complex\nmodels being trained on low amounts of data, risking\noverfitting and/or a lack of interpretability. This aspect can\ngain skepticism toward the application of machine learning\nin the manufacturing industry. To face this challenge, the\nauthors recommend being careful in every step of building\nthe optimization chain and to question the data, the used\nmachine learning methods, and optimizers. Other critical\naspects hindering the optimization of processes via machine\nlearning might be a lack of relevant data or difficulties\nin getting access to the machine\u2019s control systems. All\nthese problems might vanish with time passing to gain\nexpertise, fill storages, and lower hurdles by hard- and\nsoftware.\n5.3 Future research directions\nIn the author\u2019s eyes, machine learning in production is not\nlimited to the before-mentioned improvements. It has the\nspecific chance to improve product quality enormously if\napplied for open-loop control for multi-stage production\nprocesses, as already proposed by Konrad et al. [54],\nLieber et al. [59], and Arif et al. [5]. As product quality\ncan already be predicted at early production stages as\ndone by Weiss et al. [116], one could optimize for the\nbest subsequent machine parameter set to achieve the best\npossible product quality, given the limits of the raw material,\nthe production parameters, and the previous processing\nresults. Thinking bigger, this approach could be extended\nfrom the product-specific stage to machine- and plant-\nspecific stages, improving the overall efficiency taking\nresource, energy, and time restrictions into account.\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1898\n", []], "Optimization algorithms": ["Table 2 Classification of algorithms\nClustering\nProjections\nDecision tree\nSpecial neural\nOther classification\nOther regression\nensembles\nnetworks\nalgorithms\nalgorithms\nkNN\nPCA\nBoosted trees\nANFIS\nHMM\nGLM\nk-means\nICA\nRF\nCNN\nLogistic regression\nMARS\nGabor filter\nRBF-NN\nAssociation rule mining\nRegression tree\nSOM\nDecision tree\nGaussian process\nFuzzy classification\nExtreme learning machine\nStatistical image processing\nper input dimension for different algorithms, sorted roughly\nby their complexity. Some really high ratios occurring in\ndiagnosis via projections are skipped for a better scaling.\nTwo important points can be recognized from this figure.\nFirstly, the values of the data points per input dimension;\nsecondly, the missing relationship of this ratio to the used\nalgorithms.\nThe number of data points per input dimension varies\nbetween 1 and some thousand, and the authors like to\nstate that ratios below 10 might be critical. To learn\nan appropriate model, the data has to represent the full\ncomplexity of the given process. For example, if the process\nis linear and assuming no noise, at least two data points\nFig. 2 Point-dimension ratio for used algorithms. The image was\ncreated using a swarm plot to make points with the same values\ndistinguishable. The gray area indicates a critical amount of points per\ndimensions\nper dimension are necessary to map this relationship from\nthe data. With increasing noise and the potential of outliers,\nthe ratio has to increase as well to learn an appropriate\nmodel. As the industrial processes are assumed to have\na higher complexity, it might be possible that even with\na sophisticated DOE not all relevant relationships are\nrepresented by the data.\nRelating the ratio to the algorithms, the authors expected\nthem to be correlated, as a more complex algorithm that\nis able to map more complex relationships typically needs\nmore representative data. But this expectation was not\nfulfilled, as there is no correlation visible. All algorithms\nare used with all possible ratios. In the opinion of the\nauthors, this is considered critical. To stay with the example\nmentioned beforehand, an ANN can be used for a linear\nmapping as well as a simple linear regression, but the\nless complex model has several advantages over the ANN.\nOn the one hand, it provides a better interpretability, so\nthe mapped relationships can be understood and possible\nfailures (of the data and the model) can be detected. On the\nother hand, a complex model needs more time for training,\nsplit into the actual training time, the feature engineering,\nand the tuning of the hyperparameters. If training time is an\nissue, this fact should not be ignored.\nAt the end of this paragraph, the authors want to point\nout that process complexity, the number of data points per\ninput dimension to the model, and the model complexity are\nhighly related. To learn an appropriate model, the data has to\nrepresent the process complexity and the model complexity\nhas to fit both the process complexity and the number of\ndata points available.\n4.3 Optimization algorithms\nIf optimization is used to find the best process parameters as\nstated in Section 3.2, an appropriate optimization algorithm\nhas to be selected. As the loss function is assumed to be\ncomplex with different local optima, global optimization\nalgorithms are used. In the meantime, GA is just as popular\nas PSO, while both approaches can provide similar results\nas comparisons like [29, 62, 71] show.\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1897\n", []], "Machine learning and applications": ["Fig. 1 Applications, algorithms, and number of data points per input. Size and color indicate the median of the number of data points per input\ndimension of the model. On the horizontal axis, the machine learning algorithms are roughly sorted by complexity\n[51, 77, 103]. In the remaining articles, only measured data\nhave been used.\n4.2 Machine learning and applications\nA closer look on the reviewed papers reveals several\npotentials to increase the effectiveness of machine learning\nfor optimization of processes.\nFigure 1 gives an overview of the analyzed research\npapers. Tables 1 and 2 map the different applications and\nalgorithms to the classes used in Figs. 1 and 2.\nIt is obvious that in nearly every mentioned field of\napplication every mentioned algorithm has been used. The\nsize and color of the points additionally give a feeling for the\nused data. They represent the median of the number of data\npoints per input dimension; the median is used due to the\nfact that the specific distributions are unequally distributed.\nIt can be seen that most entries are on the same level, but\nthere are upper outliers in semiconductor manufacturing and\ndiagnosis, where huge databases are available.\nTo dive deeper into the topic of the used data and the\nmodel complexity, Fig. 2 shows the ratio of data points\nTable 1 Classification of applications\nDiagnosis\nMachining\nPlastic manufacturing\nOthers\nDefect detection\nMilling\nPIM\nwelding\nAutomatic visual inspection\nWelding\nFused deposition modeling\nGas forming\nAssembly fault detection\nGear hobbing\nPolyester film manufacturing\nPress hardening\nFinishing\nJob shop scheduling\nDrilling\nTextile draping\nTurning\nDeep drawing\nEDM\nAbrasive waterjet machining\nBoring\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1896\n", [228]], "Classes and origin of used data": ["process of integrally bladed rotors by using a regression\nmodel and the signal to noise ratio for the optimization.\nPlastic injection molding (PIM) and fused deposition mod-\neling For PIM, extensive reviews are found in [31, 48],\nextending the possible methods to other meta-models and\noptimization algorithms. Further, authors like Chen et al.\n[18] and Xu and Yang [119] used ANN and GA or rather\nANN, gray correlation analysis, PSO, and multi-objective\nPSO for the parameter optimization. Peng et al. [75]\nimproved fused deposition modeling by using the response\nsurface methodology combined with a fuzzy inference sys-\ntem and a GA optimization.\nWelding In the field of welding, Rong et al. [83] proposed\nan extreme learning machine; Dhas and Kumanan [29],\na quadratic regression model; and Norouzi et al. [71],\nan ANN, an ANFIS, and an ANN trained with PSO\nfor predicting quality parameters. For process parameter\noptimization, Rong et al. used only PSO algorithm [83],\nwhile the other authors used both PSO and GA.\nOthers The last three examples for research in parameter\noptimization based on machine learning models are press\nhardening [103], electroplating [34], and selective laser\nsintering [84]. Stoll et al. [103] predicted their quality\ncriteria with a linear regression model. In the second\nstep, a parameter optimization based on the least squares\nmethod was performed. Genna et al. [34] and Rong-Ji\net al. [84] predicted their quality criteria in electroplating\nand selective laser sintering with ANN and optimized\nthe process parameters by a so-called external optimized\nalgorithm and GA, respectively.\n3.2.2 Machine learning with other optimization approaches\nThe\npreviously\nmentioned\npapers\ncontain\nvarious\napproaches to optimize process parameters and improve\nquality in many different manufacturing applications. In\ngeneral, many researchers used ANN to describe their\nmanufacturing process and predict the quality criterion\nof interest. In the second step, a GA was applied. Alter-\nnatively, the model and the optimization can be realized\nsimultaneously by using an active DOE [94, 95], sequential\napproximate optimization [51, 52], or Bayesian optimiza-\ntion [20, 99, 102]. Another possibility is to inverse the\nproblem. Instead of building a model and optimizing the\ninput parameters, a model with quality parameters as inputs\nand process parameters as outputs is constructed [98].\nThis rejects the underlying assumption used beforehand\nthat one specific parameter configuration will result in a\ndefined quality value, but different parameter configura-\ntions can result in the same quality. Here, the assumption is\nthat different qualities can result from the same parameter\nconfiguration. This seems counterintuitive to the authors,\nbut according to [98] the prediction error compared to\nexperimental data is less than 5%.\n4 Discussion and analysis\nThe reviewed literature shows that the production-related\napplications of machine learning with or without optimiza-\ntion are manifold. In this study, we investigated which\ncombinations of production methods and machine learning\nmodels are most successful and how optimization methods\nfor quality improvement can be integrated. Our results are\npresented in the following.\n4.1 Classes and origin of used data\nThe available data for training the machine learning models\ncan be classified according to the categories explained in\nSection 2: Process parameters mostly are on continuous\nscales, therefore most data in the mentioned papers contain\nquantitative data such as water pressure or jet traverse rate\n[100]. Further examples for interval and ratio data can be\nfound in [116]. In a few cases, also nominal qualitative data\nare available, for example in [12, 16, 116].\nDepending on the selected optimization goal, data can be\navailable in the shape of time series and product-specific\ndata. If the parameters are not changed during optimization\n(see Section 3.1), often only product-specific data are\navailable, except in the area of anomaly detection [8, 27, 57,\n86]. If the parameters are changed during optimization (see\nSection 3.2), the data may be available both as time series\nand as product-specific data. In the work of Bouacha and\nTerrab [9], among other things, the process forces and the\nsurface roughness of the part are defined as outputs. Here,\nthe process forces are available as time series and the surface\nroughness of the part as product-specific quantity.\nFor the distinction into controllable and uncontrollable\ndata, as well as observable quantities and process state\nvariables, it can be summarized that input variables are\nmostly controllable and observable quantities, for example:\ncutting speed [36] or electrode feed rate [104]. Input\nvariables can also only be controlled indirectly, for example\nfeed rates [26, 36]. The output variables, however, are\nmostly uncontrollable or only indirectly controllable, for\nexample the process forces in Bouacha and Terrab [9].\nMost of the data in the investigated papers was recorded\nand subsequently a machine learning model was trained.\nExceptions are the work of Denkena et al. [28]; here, the\nmodel is further trained with present data. Furthermore, they\nalso use simulated data to train the model. More examples\nof approaches based only on simulated data can be found in\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1895\n", [228]], "Discussion and analysis": ["process of integrally bladed rotors by using a regression\nmodel and the signal to noise ratio for the optimization.\nPlastic injection molding (PIM) and fused deposition mod-\neling For PIM, extensive reviews are found in [31, 48],\nextending the possible methods to other meta-models and\noptimization algorithms. Further, authors like Chen et al.\n[18] and Xu and Yang [119] used ANN and GA or rather\nANN, gray correlation analysis, PSO, and multi-objective\nPSO for the parameter optimization. Peng et al. [75]\nimproved fused deposition modeling by using the response\nsurface methodology combined with a fuzzy inference sys-\ntem and a GA optimization.\nWelding In the field of welding, Rong et al. [83] proposed\nan extreme learning machine; Dhas and Kumanan [29],\na quadratic regression model; and Norouzi et al. [71],\nan ANN, an ANFIS, and an ANN trained with PSO\nfor predicting quality parameters. For process parameter\noptimization, Rong et al. used only PSO algorithm [83],\nwhile the other authors used both PSO and GA.\nOthers The last three examples for research in parameter\noptimization based on machine learning models are press\nhardening [103], electroplating [34], and selective laser\nsintering [84]. Stoll et al. [103] predicted their quality\ncriteria with a linear regression model. In the second\nstep, a parameter optimization based on the least squares\nmethod was performed. Genna et al. [34] and Rong-Ji\net al. [84] predicted their quality criteria in electroplating\nand selective laser sintering with ANN and optimized\nthe process parameters by a so-called external optimized\nalgorithm and GA, respectively.\n3.2.2 Machine learning with other optimization approaches\nThe\npreviously\nmentioned\npapers\ncontain\nvarious\napproaches to optimize process parameters and improve\nquality in many different manufacturing applications. In\ngeneral, many researchers used ANN to describe their\nmanufacturing process and predict the quality criterion\nof interest. In the second step, a GA was applied. Alter-\nnatively, the model and the optimization can be realized\nsimultaneously by using an active DOE [94, 95], sequential\napproximate optimization [51, 52], or Bayesian optimiza-\ntion [20, 99, 102]. Another possibility is to inverse the\nproblem. Instead of building a model and optimizing the\ninput parameters, a model with quality parameters as inputs\nand process parameters as outputs is constructed [98].\nThis rejects the underlying assumption used beforehand\nthat one specific parameter configuration will result in a\ndefined quality value, but different parameter configura-\ntions can result in the same quality. Here, the assumption is\nthat different qualities can result from the same parameter\nconfiguration. This seems counterintuitive to the authors,\nbut according to [98] the prediction error compared to\nexperimental data is less than 5%.\n4 Discussion and analysis\nThe reviewed literature shows that the production-related\napplications of machine learning with or without optimiza-\ntion are manifold. In this study, we investigated which\ncombinations of production methods and machine learning\nmodels are most successful and how optimization methods\nfor quality improvement can be integrated. Our results are\npresented in the following.\n4.1 Classes and origin of used data\nThe available data for training the machine learning models\ncan be classified according to the categories explained in\nSection 2: Process parameters mostly are on continuous\nscales, therefore most data in the mentioned papers contain\nquantitative data such as water pressure or jet traverse rate\n[100]. Further examples for interval and ratio data can be\nfound in [116]. In a few cases, also nominal qualitative data\nare available, for example in [12, 16, 116].\nDepending on the selected optimization goal, data can be\navailable in the shape of time series and product-specific\ndata. If the parameters are not changed during optimization\n(see Section 3.1), often only product-specific data are\navailable, except in the area of anomaly detection [8, 27, 57,\n86]. If the parameters are changed during optimization (see\nSection 3.2), the data may be available both as time series\nand as product-specific data. In the work of Bouacha and\nTerrab [9], among other things, the process forces and the\nsurface roughness of the part are defined as outputs. Here,\nthe process forces are available as time series and the surface\nroughness of the part as product-specific quantity.\nFor the distinction into controllable and uncontrollable\ndata, as well as observable quantities and process state\nvariables, it can be summarized that input variables are\nmostly controllable and observable quantities, for example:\ncutting speed [36] or electrode feed rate [104]. Input\nvariables can also only be controlled indirectly, for example\nfeed rates [26, 36]. The output variables, however, are\nmostly uncontrollable or only indirectly controllable, for\nexample the process forces in Bouacha and Terrab [9].\nMost of the data in the investigated papers was recorded\nand subsequently a machine learning model was trained.\nExceptions are the work of Denkena et al. [28]; here, the\nmodel is further trained with present data. Furthermore, they\nalso use simulated data to train the model. More examples\nof approaches based only on simulated data can be found in\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1895\n", []], "Machine learning with other optimization approaches": ["process of integrally bladed rotors by using a regression\nmodel and the signal to noise ratio for the optimization.\nPlastic injection molding (PIM) and fused deposition mod-\neling For PIM, extensive reviews are found in [31, 48],\nextending the possible methods to other meta-models and\noptimization algorithms. Further, authors like Chen et al.\n[18] and Xu and Yang [119] used ANN and GA or rather\nANN, gray correlation analysis, PSO, and multi-objective\nPSO for the parameter optimization. Peng et al. [75]\nimproved fused deposition modeling by using the response\nsurface methodology combined with a fuzzy inference sys-\ntem and a GA optimization.\nWelding In the field of welding, Rong et al. [83] proposed\nan extreme learning machine; Dhas and Kumanan [29],\na quadratic regression model; and Norouzi et al. [71],\nan ANN, an ANFIS, and an ANN trained with PSO\nfor predicting quality parameters. For process parameter\noptimization, Rong et al. used only PSO algorithm [83],\nwhile the other authors used both PSO and GA.\nOthers The last three examples for research in parameter\noptimization based on machine learning models are press\nhardening [103], electroplating [34], and selective laser\nsintering [84]. Stoll et al. [103] predicted their quality\ncriteria with a linear regression model. In the second\nstep, a parameter optimization based on the least squares\nmethod was performed. Genna et al. [34] and Rong-Ji\net al. [84] predicted their quality criteria in electroplating\nand selective laser sintering with ANN and optimized\nthe process parameters by a so-called external optimized\nalgorithm and GA, respectively.\n3.2.2 Machine learning with other optimization approaches\nThe\npreviously\nmentioned\npapers\ncontain\nvarious\napproaches to optimize process parameters and improve\nquality in many different manufacturing applications. In\ngeneral, many researchers used ANN to describe their\nmanufacturing process and predict the quality criterion\nof interest. In the second step, a GA was applied. Alter-\nnatively, the model and the optimization can be realized\nsimultaneously by using an active DOE [94, 95], sequential\napproximate optimization [51, 52], or Bayesian optimiza-\ntion [20, 99, 102]. Another possibility is to inverse the\nproblem. Instead of building a model and optimizing the\ninput parameters, a model with quality parameters as inputs\nand process parameters as outputs is constructed [98].\nThis rejects the underlying assumption used beforehand\nthat one specific parameter configuration will result in a\ndefined quality value, but different parameter configura-\ntions can result in the same quality. Here, the assumption is\nthat different qualities can result from the same parameter\nconfiguration. This seems counterintuitive to the authors,\nbut according to [98] the prediction error compared to\nexperimental data is less than 5%.\n4 Discussion and analysis\nThe reviewed literature shows that the production-related\napplications of machine learning with or without optimiza-\ntion are manifold. In this study, we investigated which\ncombinations of production methods and machine learning\nmodels are most successful and how optimization methods\nfor quality improvement can be integrated. Our results are\npresented in the following.\n4.1 Classes and origin of used data\nThe available data for training the machine learning models\ncan be classified according to the categories explained in\nSection 2: Process parameters mostly are on continuous\nscales, therefore most data in the mentioned papers contain\nquantitative data such as water pressure or jet traverse rate\n[100]. Further examples for interval and ratio data can be\nfound in [116]. In a few cases, also nominal qualitative data\nare available, for example in [12, 16, 116].\nDepending on the selected optimization goal, data can be\navailable in the shape of time series and product-specific\ndata. If the parameters are not changed during optimization\n(see Section 3.1), often only product-specific data are\navailable, except in the area of anomaly detection [8, 27, 57,\n86]. If the parameters are changed during optimization (see\nSection 3.2), the data may be available both as time series\nand as product-specific data. In the work of Bouacha and\nTerrab [9], among other things, the process forces and the\nsurface roughness of the part are defined as outputs. Here,\nthe process forces are available as time series and the surface\nroughness of the part as product-specific quantity.\nFor the distinction into controllable and uncontrollable\ndata, as well as observable quantities and process state\nvariables, it can be summarized that input variables are\nmostly controllable and observable quantities, for example:\ncutting speed [36] or electrode feed rate [104]. Input\nvariables can also only be controlled indirectly, for example\nfeed rates [26, 36]. The output variables, however, are\nmostly uncontrollable or only indirectly controllable, for\nexample the process forces in Bouacha and Terrab [9].\nMost of the data in the investigated papers was recorded\nand subsequently a machine learning model was trained.\nExceptions are the work of Denkena et al. [28]; here, the\nmodel is further trained with present data. Furthermore, they\nalso use simulated data to train the model. More examples\nof approaches based only on simulated data can be found in\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1895\n", []], "Others": ["process of integrally bladed rotors by using a regression\nmodel and the signal to noise ratio for the optimization.\nPlastic injection molding (PIM) and fused deposition mod-\neling For PIM, extensive reviews are found in [31, 48],\nextending the possible methods to other meta-models and\noptimization algorithms. Further, authors like Chen et al.\n[18] and Xu and Yang [119] used ANN and GA or rather\nANN, gray correlation analysis, PSO, and multi-objective\nPSO for the parameter optimization. Peng et al. [75]\nimproved fused deposition modeling by using the response\nsurface methodology combined with a fuzzy inference sys-\ntem and a GA optimization.\nWelding In the field of welding, Rong et al. [83] proposed\nan extreme learning machine; Dhas and Kumanan [29],\na quadratic regression model; and Norouzi et al. [71],\nan ANN, an ANFIS, and an ANN trained with PSO\nfor predicting quality parameters. For process parameter\noptimization, Rong et al. used only PSO algorithm [83],\nwhile the other authors used both PSO and GA.\nOthers The last three examples for research in parameter\noptimization based on machine learning models are press\nhardening [103], electroplating [34], and selective laser\nsintering [84]. Stoll et al. [103] predicted their quality\ncriteria with a linear regression model. In the second\nstep, a parameter optimization based on the least squares\nmethod was performed. Genna et al. [34] and Rong-Ji\net al. [84] predicted their quality criteria in electroplating\nand selective laser sintering with ANN and optimized\nthe process parameters by a so-called external optimized\nalgorithm and GA, respectively.\n3.2.2 Machine learning with other optimization approaches\nThe\npreviously\nmentioned\npapers\ncontain\nvarious\napproaches to optimize process parameters and improve\nquality in many different manufacturing applications. In\ngeneral, many researchers used ANN to describe their\nmanufacturing process and predict the quality criterion\nof interest. In the second step, a GA was applied. Alter-\nnatively, the model and the optimization can be realized\nsimultaneously by using an active DOE [94, 95], sequential\napproximate optimization [51, 52], or Bayesian optimiza-\ntion [20, 99, 102]. Another possibility is to inverse the\nproblem. Instead of building a model and optimizing the\ninput parameters, a model with quality parameters as inputs\nand process parameters as outputs is constructed [98].\nThis rejects the underlying assumption used beforehand\nthat one specific parameter configuration will result in a\ndefined quality value, but different parameter configura-\ntions can result in the same quality. Here, the assumption is\nthat different qualities can result from the same parameter\nconfiguration. This seems counterintuitive to the authors,\nbut according to [98] the prediction error compared to\nexperimental data is less than 5%.\n4 Discussion and analysis\nThe reviewed literature shows that the production-related\napplications of machine learning with or without optimiza-\ntion are manifold. In this study, we investigated which\ncombinations of production methods and machine learning\nmodels are most successful and how optimization methods\nfor quality improvement can be integrated. Our results are\npresented in the following.\n4.1 Classes and origin of used data\nThe available data for training the machine learning models\ncan be classified according to the categories explained in\nSection 2: Process parameters mostly are on continuous\nscales, therefore most data in the mentioned papers contain\nquantitative data such as water pressure or jet traverse rate\n[100]. Further examples for interval and ratio data can be\nfound in [116]. In a few cases, also nominal qualitative data\nare available, for example in [12, 16, 116].\nDepending on the selected optimization goal, data can be\navailable in the shape of time series and product-specific\ndata. If the parameters are not changed during optimization\n(see Section 3.1), often only product-specific data are\navailable, except in the area of anomaly detection [8, 27, 57,\n86]. If the parameters are changed during optimization (see\nSection 3.2), the data may be available both as time series\nand as product-specific data. In the work of Bouacha and\nTerrab [9], among other things, the process forces and the\nsurface roughness of the part are defined as outputs. Here,\nthe process forces are available as time series and the surface\nroughness of the part as product-specific quantity.\nFor the distinction into controllable and uncontrollable\ndata, as well as observable quantities and process state\nvariables, it can be summarized that input variables are\nmostly controllable and observable quantities, for example:\ncutting speed [36] or electrode feed rate [104]. Input\nvariables can also only be controlled indirectly, for example\nfeed rates [26, 36]. The output variables, however, are\nmostly uncontrollable or only indirectly controllable, for\nexample the process forces in Bouacha and Terrab [9].\nMost of the data in the investigated papers was recorded\nand subsequently a machine learning model was trained.\nExceptions are the work of Denkena et al. [28]; here, the\nmodel is further trained with present data. Furthermore, they\nalso use simulated data to train the model. More examples\nof approaches based only on simulated data can be found in\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1895\n", []], "Welding": ["process of integrally bladed rotors by using a regression\nmodel and the signal to noise ratio for the optimization.\nPlastic injection molding (PIM) and fused deposition mod-\neling For PIM, extensive reviews are found in [31, 48],\nextending the possible methods to other meta-models and\noptimization algorithms. Further, authors like Chen et al.\n[18] and Xu and Yang [119] used ANN and GA or rather\nANN, gray correlation analysis, PSO, and multi-objective\nPSO for the parameter optimization. Peng et al. [75]\nimproved fused deposition modeling by using the response\nsurface methodology combined with a fuzzy inference sys-\ntem and a GA optimization.\nWelding In the field of welding, Rong et al. [83] proposed\nan extreme learning machine; Dhas and Kumanan [29],\na quadratic regression model; and Norouzi et al. [71],\nan ANN, an ANFIS, and an ANN trained with PSO\nfor predicting quality parameters. For process parameter\noptimization, Rong et al. used only PSO algorithm [83],\nwhile the other authors used both PSO and GA.\nOthers The last three examples for research in parameter\noptimization based on machine learning models are press\nhardening [103], electroplating [34], and selective laser\nsintering [84]. Stoll et al. [103] predicted their quality\ncriteria with a linear regression model. In the second\nstep, a parameter optimization based on the least squares\nmethod was performed. Genna et al. [34] and Rong-Ji\net al. [84] predicted their quality criteria in electroplating\nand selective laser sintering with ANN and optimized\nthe process parameters by a so-called external optimized\nalgorithm and GA, respectively.\n3.2.2 Machine learning with other optimization approaches\nThe\npreviously\nmentioned\npapers\ncontain\nvarious\napproaches to optimize process parameters and improve\nquality in many different manufacturing applications. In\ngeneral, many researchers used ANN to describe their\nmanufacturing process and predict the quality criterion\nof interest. In the second step, a GA was applied. Alter-\nnatively, the model and the optimization can be realized\nsimultaneously by using an active DOE [94, 95], sequential\napproximate optimization [51, 52], or Bayesian optimiza-\ntion [20, 99, 102]. Another possibility is to inverse the\nproblem. Instead of building a model and optimizing the\ninput parameters, a model with quality parameters as inputs\nand process parameters as outputs is constructed [98].\nThis rejects the underlying assumption used beforehand\nthat one specific parameter configuration will result in a\ndefined quality value, but different parameter configura-\ntions can result in the same quality. Here, the assumption is\nthat different qualities can result from the same parameter\nconfiguration. This seems counterintuitive to the authors,\nbut according to [98] the prediction error compared to\nexperimental data is less than 5%.\n4 Discussion and analysis\nThe reviewed literature shows that the production-related\napplications of machine learning with or without optimiza-\ntion are manifold. In this study, we investigated which\ncombinations of production methods and machine learning\nmodels are most successful and how optimization methods\nfor quality improvement can be integrated. Our results are\npresented in the following.\n4.1 Classes and origin of used data\nThe available data for training the machine learning models\ncan be classified according to the categories explained in\nSection 2: Process parameters mostly are on continuous\nscales, therefore most data in the mentioned papers contain\nquantitative data such as water pressure or jet traverse rate\n[100]. Further examples for interval and ratio data can be\nfound in [116]. In a few cases, also nominal qualitative data\nare available, for example in [12, 16, 116].\nDepending on the selected optimization goal, data can be\navailable in the shape of time series and product-specific\ndata. If the parameters are not changed during optimization\n(see Section 3.1), often only product-specific data are\navailable, except in the area of anomaly detection [8, 27, 57,\n86]. If the parameters are changed during optimization (see\nSection 3.2), the data may be available both as time series\nand as product-specific data. In the work of Bouacha and\nTerrab [9], among other things, the process forces and the\nsurface roughness of the part are defined as outputs. Here,\nthe process forces are available as time series and the surface\nroughness of the part as product-specific quantity.\nFor the distinction into controllable and uncontrollable\ndata, as well as observable quantities and process state\nvariables, it can be summarized that input variables are\nmostly controllable and observable quantities, for example:\ncutting speed [36] or electrode feed rate [104]. Input\nvariables can also only be controlled indirectly, for example\nfeed rates [26, 36]. The output variables, however, are\nmostly uncontrollable or only indirectly controllable, for\nexample the process forces in Bouacha and Terrab [9].\nMost of the data in the investigated papers was recorded\nand subsequently a machine learning model was trained.\nExceptions are the work of Denkena et al. [28]; here, the\nmodel is further trained with present data. Furthermore, they\nalso use simulated data to train the model. More examples\nof approaches based only on simulated data can be found in\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1895\n", []], "Plastic injection molding (PIM) and fused deposition modeling": ["process of integrally bladed rotors by using a regression\nmodel and the signal to noise ratio for the optimization.\nPlastic injection molding (PIM) and fused deposition mod-\neling For PIM, extensive reviews are found in [31, 48],\nextending the possible methods to other meta-models and\noptimization algorithms. Further, authors like Chen et al.\n[18] and Xu and Yang [119] used ANN and GA or rather\nANN, gray correlation analysis, PSO, and multi-objective\nPSO for the parameter optimization. Peng et al. [75]\nimproved fused deposition modeling by using the response\nsurface methodology combined with a fuzzy inference sys-\ntem and a GA optimization.\nWelding In the field of welding, Rong et al. [83] proposed\nan extreme learning machine; Dhas and Kumanan [29],\na quadratic regression model; and Norouzi et al. [71],\nan ANN, an ANFIS, and an ANN trained with PSO\nfor predicting quality parameters. For process parameter\noptimization, Rong et al. used only PSO algorithm [83],\nwhile the other authors used both PSO and GA.\nOthers The last three examples for research in parameter\noptimization based on machine learning models are press\nhardening [103], electroplating [34], and selective laser\nsintering [84]. Stoll et al. [103] predicted their quality\ncriteria with a linear regression model. In the second\nstep, a parameter optimization based on the least squares\nmethod was performed. Genna et al. [34] and Rong-Ji\net al. [84] predicted their quality criteria in electroplating\nand selective laser sintering with ANN and optimized\nthe process parameters by a so-called external optimized\nalgorithm and GA, respectively.\n3.2.2 Machine learning with other optimization approaches\nThe\npreviously\nmentioned\npapers\ncontain\nvarious\napproaches to optimize process parameters and improve\nquality in many different manufacturing applications. In\ngeneral, many researchers used ANN to describe their\nmanufacturing process and predict the quality criterion\nof interest. In the second step, a GA was applied. Alter-\nnatively, the model and the optimization can be realized\nsimultaneously by using an active DOE [94, 95], sequential\napproximate optimization [51, 52], or Bayesian optimiza-\ntion [20, 99, 102]. Another possibility is to inverse the\nproblem. Instead of building a model and optimizing the\ninput parameters, a model with quality parameters as inputs\nand process parameters as outputs is constructed [98].\nThis rejects the underlying assumption used beforehand\nthat one specific parameter configuration will result in a\ndefined quality value, but different parameter configura-\ntions can result in the same quality. Here, the assumption is\nthat different qualities can result from the same parameter\nconfiguration. This seems counterintuitive to the authors,\nbut according to [98] the prediction error compared to\nexperimental data is less than 5%.\n4 Discussion and analysis\nThe reviewed literature shows that the production-related\napplications of machine learning with or without optimiza-\ntion are manifold. In this study, we investigated which\ncombinations of production methods and machine learning\nmodels are most successful and how optimization methods\nfor quality improvement can be integrated. Our results are\npresented in the following.\n4.1 Classes and origin of used data\nThe available data for training the machine learning models\ncan be classified according to the categories explained in\nSection 2: Process parameters mostly are on continuous\nscales, therefore most data in the mentioned papers contain\nquantitative data such as water pressure or jet traverse rate\n[100]. Further examples for interval and ratio data can be\nfound in [116]. In a few cases, also nominal qualitative data\nare available, for example in [12, 16, 116].\nDepending on the selected optimization goal, data can be\navailable in the shape of time series and product-specific\ndata. If the parameters are not changed during optimization\n(see Section 3.1), often only product-specific data are\navailable, except in the area of anomaly detection [8, 27, 57,\n86]. If the parameters are changed during optimization (see\nSection 3.2), the data may be available both as time series\nand as product-specific data. In the work of Bouacha and\nTerrab [9], among other things, the process forces and the\nsurface roughness of the part are defined as outputs. Here,\nthe process forces are available as time series and the surface\nroughness of the part as product-specific quantity.\nFor the distinction into controllable and uncontrollable\ndata, as well as observable quantities and process state\nvariables, it can be summarized that input variables are\nmostly controllable and observable quantities, for example:\ncutting speed [36] or electrode feed rate [104]. Input\nvariables can also only be controlled indirectly, for example\nfeed rates [26, 36]. The output variables, however, are\nmostly uncontrollable or only indirectly controllable, for\nexample the process forces in Bouacha and Terrab [9].\nMost of the data in the investigated papers was recorded\nand subsequently a machine learning model was trained.\nExceptions are the work of Denkena et al. [28]; here, the\nmodel is further trained with present data. Furthermore, they\nalso use simulated data to train the model. More examples\nof approaches based only on simulated data can be found in\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1895\n", []], "Finishing": ["can consist of measured data like in [46] or of simulated\ndata [77, 103]. If the machine learning model is supposed\nto replace a time-consuming physics-based simulation, it\nis called a meta- or surrogate-model [78, 111]. With\nthis method, the risk of error propagation through the\ndifferent models is given. Both systematic and stochastic\nerrors can occur during construction of the physics-based\nsimulation and subsequently be adapted by the meta-model\nbuilt from its calculations, resulting in an invalid meta-\nmodel as well. But even with valid physics- and meta-\nmodels, approximation errors to the real process have to be\nconsidered. However, the approaches discussed below are\nbased on measured data. Often, the created process models\nare not simple linear regression models but complex non-\nlinear models as SVM or ANN. The training of these models\ncan be time consuming and computationally expensive, but\nfor a good representation of the physical correlations, the\nusage of non-linear models is often indispensable.\nThe optimization of process parameters can be realized\nby traditional approaches like Newton\u2019s method, hill climb-\ning algorithms, or gradient descent algorithms, leading to\na local optimum. A second possibility to optimize the pro-\ncess parameters is to use evolutionary algorithms, usually\nleading to the global optimum of the given search domain.\nThe usage of evolutionary techniques received a lot of\nattention in recent years [122, 123]. The approaches dis-\ncussed in the following section use evolutionary algorithms\nin most cases.\n3.2.1 Machine learning with subsequent optimization\napproaches\nThere exist a lot of different fields for machine learning\napproaches and subsequent parameter optimization. The\nfollowing sections present examples in different specific\nmanufacturing fields.\nMilling Especially in milling processes, a lot of research\nwas done on approaches including ANN and genetic\nalgorithms (GA). The authors of [46, 97, 107] used\nthese techniques to improve different quality criteria by\noptimizing the cutting parameters of the milling process.\nDenkena et al. [28] suggest a SVM to predict the\ngeometric deviation of the workpiece. To optimize the\ncutting parameters, they were sampled on a grid and optimal\nparameters were chosen based on the prediction of the\nSVM. In [26], Coppel et al. compare ANN and SVM models\nto predict quality criteria and also test different optimization\nalgorithms, such as GA, particle swarm optimization (PSO),\nand simulated annealing (SA) algorithms, respectively,\nto determine optimal cutting parameters for the milling\noperation. An ANN model with subsequent PSO achieved\nthe best results.\nTurning Turning operations were the process of interest in\n[9, 36]. In Bouacha and Terrab [9], an ANN with subsequent\nPSO was compared with a non-dominated sorting genetic\nalgorithm (NSGA-II)-based RSM model. Because of less\ncomputation time, the ANN with PSO algorithm was the\nbetter choice in this case. Gupta et al. [36] used different\nmodeling approaches like regression, RSM, SVM, and\nANN to predict the quality criteria; GA was used to find\noptimal process parameters.\nGear hobbing and boring In the field of gear hobbing [12]\nANN and in boring [108] ANN and SVR were proposed\nto predict the quality criteria. Cao et al. [12] optimized\ntheir process parameters based on ANN with a differential\nevolution algorithm. Venkata Rao and Murthy [108] used an\nunspecified multi-response optimizer.\nElectrical discharge and abrasive waterjet machining The\nauthors of [6, 62] have done research on parameter\noptimization in electrical discharge machining (EDM)\nand wire EDM [65, 79], respectively. All of them used\nANN to predict the quality criteria, except Rao and\nPawar [79], who applied a second-order regression model.\nThe process parameters were optimized with different\nalgorithms: augmented Lagrange multiplier algorithm [6],\nGA, PSO and SA algorithm [62], wolf pack algorithm\nbased on the strategy of the leader (LWPA) [65], and\nartificial bee colony (ABC) algorithm [79]. In more special\nEDM, applications like wire EDM turning [55], micro-\nEDM [126], or micro-clearance electrolysis-assisted laser\nmachining [104] parameter optimizations based on machine\nlearned prediction models were conducted as well. All\nused more or less already mentioned combinations of ANN\nand NSGA-II [55], SVM and GA [126], and ANN and\nimproved ant colony algorithm [104]. Zhang et al. [126]\npredicted the processing time and electrode wear with a\nsupport vector machine as a regression model. In the second\nstep, they performed a multi-objective optimization with a\nGA. The results represent a pareto-optimal solution between\nthe minimum processing time and minimum electrode\nwear. Srinivasu and Babu [100] and Zain et al. [124,\n125] optimized the process parameters of abrasive waterjet\nmachining with regression models and ANN, respectively,\nfollowed by GA.\nFinishing For the parameter optimization process in roller\ngrinding, Chen et al. [19] used RSM for the quality\nprediction and a hybrid PSO algorithm for the optimization\ntask. For the optimal configuration of the grinding slurry of\nwaterjet grinding, Liang et al. [58] used an adaptive neuro-\nfuzzy inference system (ANFIS) approach. Zhao et al. [128]\noptimized the parameters of the grinding and polishing\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1894\n", []], "Electrical discharge and abrasive waterjet machining": ["can consist of measured data like in [46] or of simulated\ndata [77, 103]. If the machine learning model is supposed\nto replace a time-consuming physics-based simulation, it\nis called a meta- or surrogate-model [78, 111]. With\nthis method, the risk of error propagation through the\ndifferent models is given. Both systematic and stochastic\nerrors can occur during construction of the physics-based\nsimulation and subsequently be adapted by the meta-model\nbuilt from its calculations, resulting in an invalid meta-\nmodel as well. But even with valid physics- and meta-\nmodels, approximation errors to the real process have to be\nconsidered. However, the approaches discussed below are\nbased on measured data. Often, the created process models\nare not simple linear regression models but complex non-\nlinear models as SVM or ANN. The training of these models\ncan be time consuming and computationally expensive, but\nfor a good representation of the physical correlations, the\nusage of non-linear models is often indispensable.\nThe optimization of process parameters can be realized\nby traditional approaches like Newton\u2019s method, hill climb-\ning algorithms, or gradient descent algorithms, leading to\na local optimum. A second possibility to optimize the pro-\ncess parameters is to use evolutionary algorithms, usually\nleading to the global optimum of the given search domain.\nThe usage of evolutionary techniques received a lot of\nattention in recent years [122, 123]. The approaches dis-\ncussed in the following section use evolutionary algorithms\nin most cases.\n3.2.1 Machine learning with subsequent optimization\napproaches\nThere exist a lot of different fields for machine learning\napproaches and subsequent parameter optimization. The\nfollowing sections present examples in different specific\nmanufacturing fields.\nMilling Especially in milling processes, a lot of research\nwas done on approaches including ANN and genetic\nalgorithms (GA). The authors of [46, 97, 107] used\nthese techniques to improve different quality criteria by\noptimizing the cutting parameters of the milling process.\nDenkena et al. [28] suggest a SVM to predict the\ngeometric deviation of the workpiece. To optimize the\ncutting parameters, they were sampled on a grid and optimal\nparameters were chosen based on the prediction of the\nSVM. In [26], Coppel et al. compare ANN and SVM models\nto predict quality criteria and also test different optimization\nalgorithms, such as GA, particle swarm optimization (PSO),\nand simulated annealing (SA) algorithms, respectively,\nto determine optimal cutting parameters for the milling\noperation. An ANN model with subsequent PSO achieved\nthe best results.\nTurning Turning operations were the process of interest in\n[9, 36]. In Bouacha and Terrab [9], an ANN with subsequent\nPSO was compared with a non-dominated sorting genetic\nalgorithm (NSGA-II)-based RSM model. Because of less\ncomputation time, the ANN with PSO algorithm was the\nbetter choice in this case. Gupta et al. [36] used different\nmodeling approaches like regression, RSM, SVM, and\nANN to predict the quality criteria; GA was used to find\noptimal process parameters.\nGear hobbing and boring In the field of gear hobbing [12]\nANN and in boring [108] ANN and SVR were proposed\nto predict the quality criteria. Cao et al. [12] optimized\ntheir process parameters based on ANN with a differential\nevolution algorithm. Venkata Rao and Murthy [108] used an\nunspecified multi-response optimizer.\nElectrical discharge and abrasive waterjet machining The\nauthors of [6, 62] have done research on parameter\noptimization in electrical discharge machining (EDM)\nand wire EDM [65, 79], respectively. All of them used\nANN to predict the quality criteria, except Rao and\nPawar [79], who applied a second-order regression model.\nThe process parameters were optimized with different\nalgorithms: augmented Lagrange multiplier algorithm [6],\nGA, PSO and SA algorithm [62], wolf pack algorithm\nbased on the strategy of the leader (LWPA) [65], and\nartificial bee colony (ABC) algorithm [79]. In more special\nEDM, applications like wire EDM turning [55], micro-\nEDM [126], or micro-clearance electrolysis-assisted laser\nmachining [104] parameter optimizations based on machine\nlearned prediction models were conducted as well. All\nused more or less already mentioned combinations of ANN\nand NSGA-II [55], SVM and GA [126], and ANN and\nimproved ant colony algorithm [104]. Zhang et al. [126]\npredicted the processing time and electrode wear with a\nsupport vector machine as a regression model. In the second\nstep, they performed a multi-objective optimization with a\nGA. The results represent a pareto-optimal solution between\nthe minimum processing time and minimum electrode\nwear. Srinivasu and Babu [100] and Zain et al. [124,\n125] optimized the process parameters of abrasive waterjet\nmachining with regression models and ANN, respectively,\nfollowed by GA.\nFinishing For the parameter optimization process in roller\ngrinding, Chen et al. [19] used RSM for the quality\nprediction and a hybrid PSO algorithm for the optimization\ntask. For the optimal configuration of the grinding slurry of\nwaterjet grinding, Liang et al. [58] used an adaptive neuro-\nfuzzy inference system (ANFIS) approach. Zhao et al. [128]\noptimized the parameters of the grinding and polishing\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1894\n", []], "Gear hobbing and boring": ["can consist of measured data like in [46] or of simulated\ndata [77, 103]. If the machine learning model is supposed\nto replace a time-consuming physics-based simulation, it\nis called a meta- or surrogate-model [78, 111]. With\nthis method, the risk of error propagation through the\ndifferent models is given. Both systematic and stochastic\nerrors can occur during construction of the physics-based\nsimulation and subsequently be adapted by the meta-model\nbuilt from its calculations, resulting in an invalid meta-\nmodel as well. But even with valid physics- and meta-\nmodels, approximation errors to the real process have to be\nconsidered. However, the approaches discussed below are\nbased on measured data. Often, the created process models\nare not simple linear regression models but complex non-\nlinear models as SVM or ANN. The training of these models\ncan be time consuming and computationally expensive, but\nfor a good representation of the physical correlations, the\nusage of non-linear models is often indispensable.\nThe optimization of process parameters can be realized\nby traditional approaches like Newton\u2019s method, hill climb-\ning algorithms, or gradient descent algorithms, leading to\na local optimum. A second possibility to optimize the pro-\ncess parameters is to use evolutionary algorithms, usually\nleading to the global optimum of the given search domain.\nThe usage of evolutionary techniques received a lot of\nattention in recent years [122, 123]. The approaches dis-\ncussed in the following section use evolutionary algorithms\nin most cases.\n3.2.1 Machine learning with subsequent optimization\napproaches\nThere exist a lot of different fields for machine learning\napproaches and subsequent parameter optimization. The\nfollowing sections present examples in different specific\nmanufacturing fields.\nMilling Especially in milling processes, a lot of research\nwas done on approaches including ANN and genetic\nalgorithms (GA). The authors of [46, 97, 107] used\nthese techniques to improve different quality criteria by\noptimizing the cutting parameters of the milling process.\nDenkena et al. [28] suggest a SVM to predict the\ngeometric deviation of the workpiece. To optimize the\ncutting parameters, they were sampled on a grid and optimal\nparameters were chosen based on the prediction of the\nSVM. In [26], Coppel et al. compare ANN and SVM models\nto predict quality criteria and also test different optimization\nalgorithms, such as GA, particle swarm optimization (PSO),\nand simulated annealing (SA) algorithms, respectively,\nto determine optimal cutting parameters for the milling\noperation. An ANN model with subsequent PSO achieved\nthe best results.\nTurning Turning operations were the process of interest in\n[9, 36]. In Bouacha and Terrab [9], an ANN with subsequent\nPSO was compared with a non-dominated sorting genetic\nalgorithm (NSGA-II)-based RSM model. Because of less\ncomputation time, the ANN with PSO algorithm was the\nbetter choice in this case. Gupta et al. [36] used different\nmodeling approaches like regression, RSM, SVM, and\nANN to predict the quality criteria; GA was used to find\noptimal process parameters.\nGear hobbing and boring In the field of gear hobbing [12]\nANN and in boring [108] ANN and SVR were proposed\nto predict the quality criteria. Cao et al. [12] optimized\ntheir process parameters based on ANN with a differential\nevolution algorithm. Venkata Rao and Murthy [108] used an\nunspecified multi-response optimizer.\nElectrical discharge and abrasive waterjet machining The\nauthors of [6, 62] have done research on parameter\noptimization in electrical discharge machining (EDM)\nand wire EDM [65, 79], respectively. All of them used\nANN to predict the quality criteria, except Rao and\nPawar [79], who applied a second-order regression model.\nThe process parameters were optimized with different\nalgorithms: augmented Lagrange multiplier algorithm [6],\nGA, PSO and SA algorithm [62], wolf pack algorithm\nbased on the strategy of the leader (LWPA) [65], and\nartificial bee colony (ABC) algorithm [79]. In more special\nEDM, applications like wire EDM turning [55], micro-\nEDM [126], or micro-clearance electrolysis-assisted laser\nmachining [104] parameter optimizations based on machine\nlearned prediction models were conducted as well. All\nused more or less already mentioned combinations of ANN\nand NSGA-II [55], SVM and GA [126], and ANN and\nimproved ant colony algorithm [104]. Zhang et al. [126]\npredicted the processing time and electrode wear with a\nsupport vector machine as a regression model. In the second\nstep, they performed a multi-objective optimization with a\nGA. The results represent a pareto-optimal solution between\nthe minimum processing time and minimum electrode\nwear. Srinivasu and Babu [100] and Zain et al. [124,\n125] optimized the process parameters of abrasive waterjet\nmachining with regression models and ANN, respectively,\nfollowed by GA.\nFinishing For the parameter optimization process in roller\ngrinding, Chen et al. [19] used RSM for the quality\nprediction and a hybrid PSO algorithm for the optimization\ntask. For the optimal configuration of the grinding slurry of\nwaterjet grinding, Liang et al. [58] used an adaptive neuro-\nfuzzy inference system (ANFIS) approach. Zhao et al. [128]\noptimized the parameters of the grinding and polishing\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1894\n", []], "Turning": ["can consist of measured data like in [46] or of simulated\ndata [77, 103]. If the machine learning model is supposed\nto replace a time-consuming physics-based simulation, it\nis called a meta- or surrogate-model [78, 111]. With\nthis method, the risk of error propagation through the\ndifferent models is given. Both systematic and stochastic\nerrors can occur during construction of the physics-based\nsimulation and subsequently be adapted by the meta-model\nbuilt from its calculations, resulting in an invalid meta-\nmodel as well. But even with valid physics- and meta-\nmodels, approximation errors to the real process have to be\nconsidered. However, the approaches discussed below are\nbased on measured data. Often, the created process models\nare not simple linear regression models but complex non-\nlinear models as SVM or ANN. The training of these models\ncan be time consuming and computationally expensive, but\nfor a good representation of the physical correlations, the\nusage of non-linear models is often indispensable.\nThe optimization of process parameters can be realized\nby traditional approaches like Newton\u2019s method, hill climb-\ning algorithms, or gradient descent algorithms, leading to\na local optimum. A second possibility to optimize the pro-\ncess parameters is to use evolutionary algorithms, usually\nleading to the global optimum of the given search domain.\nThe usage of evolutionary techniques received a lot of\nattention in recent years [122, 123]. The approaches dis-\ncussed in the following section use evolutionary algorithms\nin most cases.\n3.2.1 Machine learning with subsequent optimization\napproaches\nThere exist a lot of different fields for machine learning\napproaches and subsequent parameter optimization. The\nfollowing sections present examples in different specific\nmanufacturing fields.\nMilling Especially in milling processes, a lot of research\nwas done on approaches including ANN and genetic\nalgorithms (GA). The authors of [46, 97, 107] used\nthese techniques to improve different quality criteria by\noptimizing the cutting parameters of the milling process.\nDenkena et al. [28] suggest a SVM to predict the\ngeometric deviation of the workpiece. To optimize the\ncutting parameters, they were sampled on a grid and optimal\nparameters were chosen based on the prediction of the\nSVM. In [26], Coppel et al. compare ANN and SVM models\nto predict quality criteria and also test different optimization\nalgorithms, such as GA, particle swarm optimization (PSO),\nand simulated annealing (SA) algorithms, respectively,\nto determine optimal cutting parameters for the milling\noperation. An ANN model with subsequent PSO achieved\nthe best results.\nTurning Turning operations were the process of interest in\n[9, 36]. In Bouacha and Terrab [9], an ANN with subsequent\nPSO was compared with a non-dominated sorting genetic\nalgorithm (NSGA-II)-based RSM model. Because of less\ncomputation time, the ANN with PSO algorithm was the\nbetter choice in this case. Gupta et al. [36] used different\nmodeling approaches like regression, RSM, SVM, and\nANN to predict the quality criteria; GA was used to find\noptimal process parameters.\nGear hobbing and boring In the field of gear hobbing [12]\nANN and in boring [108] ANN and SVR were proposed\nto predict the quality criteria. Cao et al. [12] optimized\ntheir process parameters based on ANN with a differential\nevolution algorithm. Venkata Rao and Murthy [108] used an\nunspecified multi-response optimizer.\nElectrical discharge and abrasive waterjet machining The\nauthors of [6, 62] have done research on parameter\noptimization in electrical discharge machining (EDM)\nand wire EDM [65, 79], respectively. All of them used\nANN to predict the quality criteria, except Rao and\nPawar [79], who applied a second-order regression model.\nThe process parameters were optimized with different\nalgorithms: augmented Lagrange multiplier algorithm [6],\nGA, PSO and SA algorithm [62], wolf pack algorithm\nbased on the strategy of the leader (LWPA) [65], and\nartificial bee colony (ABC) algorithm [79]. In more special\nEDM, applications like wire EDM turning [55], micro-\nEDM [126], or micro-clearance electrolysis-assisted laser\nmachining [104] parameter optimizations based on machine\nlearned prediction models were conducted as well. All\nused more or less already mentioned combinations of ANN\nand NSGA-II [55], SVM and GA [126], and ANN and\nimproved ant colony algorithm [104]. Zhang et al. [126]\npredicted the processing time and electrode wear with a\nsupport vector machine as a regression model. In the second\nstep, they performed a multi-objective optimization with a\nGA. The results represent a pareto-optimal solution between\nthe minimum processing time and minimum electrode\nwear. Srinivasu and Babu [100] and Zain et al. [124,\n125] optimized the process parameters of abrasive waterjet\nmachining with regression models and ANN, respectively,\nfollowed by GA.\nFinishing For the parameter optimization process in roller\ngrinding, Chen et al. [19] used RSM for the quality\nprediction and a hybrid PSO algorithm for the optimization\ntask. For the optimal configuration of the grinding slurry of\nwaterjet grinding, Liang et al. [58] used an adaptive neuro-\nfuzzy inference system (ANFIS) approach. Zhao et al. [128]\noptimized the parameters of the grinding and polishing\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1894\n", []], "Milling": ["can consist of measured data like in [46] or of simulated\ndata [77, 103]. If the machine learning model is supposed\nto replace a time-consuming physics-based simulation, it\nis called a meta- or surrogate-model [78, 111]. With\nthis method, the risk of error propagation through the\ndifferent models is given. Both systematic and stochastic\nerrors can occur during construction of the physics-based\nsimulation and subsequently be adapted by the meta-model\nbuilt from its calculations, resulting in an invalid meta-\nmodel as well. But even with valid physics- and meta-\nmodels, approximation errors to the real process have to be\nconsidered. However, the approaches discussed below are\nbased on measured data. Often, the created process models\nare not simple linear regression models but complex non-\nlinear models as SVM or ANN. The training of these models\ncan be time consuming and computationally expensive, but\nfor a good representation of the physical correlations, the\nusage of non-linear models is often indispensable.\nThe optimization of process parameters can be realized\nby traditional approaches like Newton\u2019s method, hill climb-\ning algorithms, or gradient descent algorithms, leading to\na local optimum. A second possibility to optimize the pro-\ncess parameters is to use evolutionary algorithms, usually\nleading to the global optimum of the given search domain.\nThe usage of evolutionary techniques received a lot of\nattention in recent years [122, 123]. The approaches dis-\ncussed in the following section use evolutionary algorithms\nin most cases.\n3.2.1 Machine learning with subsequent optimization\napproaches\nThere exist a lot of different fields for machine learning\napproaches and subsequent parameter optimization. The\nfollowing sections present examples in different specific\nmanufacturing fields.\nMilling Especially in milling processes, a lot of research\nwas done on approaches including ANN and genetic\nalgorithms (GA). The authors of [46, 97, 107] used\nthese techniques to improve different quality criteria by\noptimizing the cutting parameters of the milling process.\nDenkena et al. [28] suggest a SVM to predict the\ngeometric deviation of the workpiece. To optimize the\ncutting parameters, they were sampled on a grid and optimal\nparameters were chosen based on the prediction of the\nSVM. In [26], Coppel et al. compare ANN and SVM models\nto predict quality criteria and also test different optimization\nalgorithms, such as GA, particle swarm optimization (PSO),\nand simulated annealing (SA) algorithms, respectively,\nto determine optimal cutting parameters for the milling\noperation. An ANN model with subsequent PSO achieved\nthe best results.\nTurning Turning operations were the process of interest in\n[9, 36]. In Bouacha and Terrab [9], an ANN with subsequent\nPSO was compared with a non-dominated sorting genetic\nalgorithm (NSGA-II)-based RSM model. Because of less\ncomputation time, the ANN with PSO algorithm was the\nbetter choice in this case. Gupta et al. [36] used different\nmodeling approaches like regression, RSM, SVM, and\nANN to predict the quality criteria; GA was used to find\noptimal process parameters.\nGear hobbing and boring In the field of gear hobbing [12]\nANN and in boring [108] ANN and SVR were proposed\nto predict the quality criteria. Cao et al. [12] optimized\ntheir process parameters based on ANN with a differential\nevolution algorithm. Venkata Rao and Murthy [108] used an\nunspecified multi-response optimizer.\nElectrical discharge and abrasive waterjet machining The\nauthors of [6, 62] have done research on parameter\noptimization in electrical discharge machining (EDM)\nand wire EDM [65, 79], respectively. All of them used\nANN to predict the quality criteria, except Rao and\nPawar [79], who applied a second-order regression model.\nThe process parameters were optimized with different\nalgorithms: augmented Lagrange multiplier algorithm [6],\nGA, PSO and SA algorithm [62], wolf pack algorithm\nbased on the strategy of the leader (LWPA) [65], and\nartificial bee colony (ABC) algorithm [79]. In more special\nEDM, applications like wire EDM turning [55], micro-\nEDM [126], or micro-clearance electrolysis-assisted laser\nmachining [104] parameter optimizations based on machine\nlearned prediction models were conducted as well. All\nused more or less already mentioned combinations of ANN\nand NSGA-II [55], SVM and GA [126], and ANN and\nimproved ant colony algorithm [104]. Zhang et al. [126]\npredicted the processing time and electrode wear with a\nsupport vector machine as a regression model. In the second\nstep, they performed a multi-objective optimization with a\nGA. The results represent a pareto-optimal solution between\nthe minimum processing time and minimum electrode\nwear. Srinivasu and Babu [100] and Zain et al. [124,\n125] optimized the process parameters of abrasive waterjet\nmachining with regression models and ANN, respectively,\nfollowed by GA.\nFinishing For the parameter optimization process in roller\ngrinding, Chen et al. [19] used RSM for the quality\nprediction and a hybrid PSO algorithm for the optimization\ntask. For the optimal configuration of the grinding slurry of\nwaterjet grinding, Liang et al. [58] used an adaptive neuro-\nfuzzy inference system (ANFIS) approach. Zhao et al. [128]\noptimized the parameters of the grinding and polishing\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1894\n", []], "Machine learning with subsequent optimization approaches": ["can consist of measured data like in [46] or of simulated\ndata [77, 103]. If the machine learning model is supposed\nto replace a time-consuming physics-based simulation, it\nis called a meta- or surrogate-model [78, 111]. With\nthis method, the risk of error propagation through the\ndifferent models is given. Both systematic and stochastic\nerrors can occur during construction of the physics-based\nsimulation and subsequently be adapted by the meta-model\nbuilt from its calculations, resulting in an invalid meta-\nmodel as well. But even with valid physics- and meta-\nmodels, approximation errors to the real process have to be\nconsidered. However, the approaches discussed below are\nbased on measured data. Often, the created process models\nare not simple linear regression models but complex non-\nlinear models as SVM or ANN. The training of these models\ncan be time consuming and computationally expensive, but\nfor a good representation of the physical correlations, the\nusage of non-linear models is often indispensable.\nThe optimization of process parameters can be realized\nby traditional approaches like Newton\u2019s method, hill climb-\ning algorithms, or gradient descent algorithms, leading to\na local optimum. A second possibility to optimize the pro-\ncess parameters is to use evolutionary algorithms, usually\nleading to the global optimum of the given search domain.\nThe usage of evolutionary techniques received a lot of\nattention in recent years [122, 123]. The approaches dis-\ncussed in the following section use evolutionary algorithms\nin most cases.\n3.2.1 Machine learning with subsequent optimization\napproaches\nThere exist a lot of different fields for machine learning\napproaches and subsequent parameter optimization. The\nfollowing sections present examples in different specific\nmanufacturing fields.\nMilling Especially in milling processes, a lot of research\nwas done on approaches including ANN and genetic\nalgorithms (GA). The authors of [46, 97, 107] used\nthese techniques to improve different quality criteria by\noptimizing the cutting parameters of the milling process.\nDenkena et al. [28] suggest a SVM to predict the\ngeometric deviation of the workpiece. To optimize the\ncutting parameters, they were sampled on a grid and optimal\nparameters were chosen based on the prediction of the\nSVM. In [26], Coppel et al. compare ANN and SVM models\nto predict quality criteria and also test different optimization\nalgorithms, such as GA, particle swarm optimization (PSO),\nand simulated annealing (SA) algorithms, respectively,\nto determine optimal cutting parameters for the milling\noperation. An ANN model with subsequent PSO achieved\nthe best results.\nTurning Turning operations were the process of interest in\n[9, 36]. In Bouacha and Terrab [9], an ANN with subsequent\nPSO was compared with a non-dominated sorting genetic\nalgorithm (NSGA-II)-based RSM model. Because of less\ncomputation time, the ANN with PSO algorithm was the\nbetter choice in this case. Gupta et al. [36] used different\nmodeling approaches like regression, RSM, SVM, and\nANN to predict the quality criteria; GA was used to find\noptimal process parameters.\nGear hobbing and boring In the field of gear hobbing [12]\nANN and in boring [108] ANN and SVR were proposed\nto predict the quality criteria. Cao et al. [12] optimized\ntheir process parameters based on ANN with a differential\nevolution algorithm. Venkata Rao and Murthy [108] used an\nunspecified multi-response optimizer.\nElectrical discharge and abrasive waterjet machining The\nauthors of [6, 62] have done research on parameter\noptimization in electrical discharge machining (EDM)\nand wire EDM [65, 79], respectively. All of them used\nANN to predict the quality criteria, except Rao and\nPawar [79], who applied a second-order regression model.\nThe process parameters were optimized with different\nalgorithms: augmented Lagrange multiplier algorithm [6],\nGA, PSO and SA algorithm [62], wolf pack algorithm\nbased on the strategy of the leader (LWPA) [65], and\nartificial bee colony (ABC) algorithm [79]. In more special\nEDM, applications like wire EDM turning [55], micro-\nEDM [126], or micro-clearance electrolysis-assisted laser\nmachining [104] parameter optimizations based on machine\nlearned prediction models were conducted as well. All\nused more or less already mentioned combinations of ANN\nand NSGA-II [55], SVM and GA [126], and ANN and\nimproved ant colony algorithm [104]. Zhang et al. [126]\npredicted the processing time and electrode wear with a\nsupport vector machine as a regression model. In the second\nstep, they performed a multi-objective optimization with a\nGA. The results represent a pareto-optimal solution between\nthe minimum processing time and minimum electrode\nwear. Srinivasu and Babu [100] and Zain et al. [124,\n125] optimized the process parameters of abrasive waterjet\nmachining with regression models and ANN, respectively,\nfollowed by GA.\nFinishing For the parameter optimization process in roller\ngrinding, Chen et al. [19] used RSM for the quality\nprediction and a hybrid PSO algorithm for the optimization\ntask. For the optimal configuration of the grinding slurry of\nwaterjet grinding, Liang et al. [58] used an adaptive neuro-\nfuzzy inference system (ANFIS) approach. Zhao et al. [128]\noptimized the parameters of the grinding and polishing\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1894\n", []], "Optimization with parameter changes": ["3.1.4 Part diagnosis\nFor the diagnosis of parts, two main applications are\ndescribed, namely visual inspection and the diagnosis of\npart assemblies.\nAutomatic visual inspection, applied before, during, and\nafter production processes, serves to maintain good part\nquality, examining images for possible faults. Various meth-\nods were developed for the production of semiconductors\nand screen glasses [40, 43, 105], ceramics and tiles [47],\nand miscellaneous processes relating to metal parts [42, 63,\n88, 113, 121]. Additionally, generic methods for different\nmaterials and purposes were developed [73, 80].\nMethods for visual inspection vary over projection meth-\nods like independent component analysis [105] and PCA\n[17]; filter-based approaches like discrete cosine trans-\nform [76] and discrete wavelet transform [121]; learning-\nbased approaches like SVM [106], Hidden Markov Models\n(HMM) [42], fuzzy clustering [43], and convolutional neu-\nral networks (CNN) [63, 73, 80, 113] for regression or\nclassification; and statistical methods [88].\nDiagnosis of assembly processes or its results usually\nuses data sources different from images, resulting in the\nuse of different methods. Additionally, recent authors try to\ncover not only one specific processing stage but multi-stage\nprocesses as well. This complicates the problem to be solved\ndue to correlations between the different process steps and\nthe resulting error propagation. For sheet metal assemblies,\nCeglarek and Prakash [14] show a piecewise least squares\napproach for use in a state-space model. Their introduction\nreviews various publications in the field of fixture diagnosis\nmethods. The force signature of the assembling robot arm is\nused by Rodriguez et al. as input to an SVM [82]. Luo et al.\n[61] extend this approach by abstracting specific behavior\nrepresentations from the force signature.\n3.1.5 Plant diagnosis\nDiagnosis of production plants or machines can be\nrealized by anomaly detection methods. In anomaly\ndetection of production plants, one distinguishes between\nphenomenological and model-based approaches [70]. In\nphenomenological approaches, measurements are classified\ndirectly to detect anomalous behavior, while model-based\napproaches compare a system model representing the\nnormal system behavior and the system\u2019s measurement data.\nDue to the high amount of available publications,\nonly a short introduction into the topic is given and the\nimportant topic of one-class classification is being skipped.\nFor this, the authors would like to refer the interested\nreader to the comprehensive work of Shin et al. [96].\nIn case of phenomenological approaches, sensor data like\ntime-series data is processed. To extract features from\nit, transformations like wavelet transform [33], empirical\nmode decomposition [39, 117], or independent component\nanalysis [101] are used. The features can be processed with\nvarious algorithms like ANN, SVM, optimizers, or fuzzy\nlogic [127]. Typical applications are induction machines\n[8], pneumatic systems [27], gear boxes [86], and bearings\n[57]. Model-based approaches usually do not rely on feature\nextraction from time-series and can use machine learning\nalgorithms like PCA or partial least squares [120] directly.\nClosely related to anomaly detection methods, which are\nmostly used for failure detection, is the field of maintenance\nmethods which aim to prevent machine failures due\nto deterioration of the machine. A distinction is made\nbetween time-based and condition-based maintenance,\ncalled preventive and predictive maintenance [66].\nPreventive maintenance tries to extract the mean useful\nlife of a machine and/or its parts to schedule maintenance\nactivities before breakdown. To the author\u2019s knowledge, the\nuse of machine learning methods for this task has not been\nreported to the scientific community yet, as simple statistics\nleads to good results [66]. For preventive maintenance,\na mathematical formulation of the loss function to be\noptimized can be found (see, e.g., the work of Cassady and\nKutanoglu [13]). If the term of preventive maintenance is\nabstracted to the level of job shop scheduling, the work\nof Adibi et al. shows parameter estimation by clustering\n[1], reinforcement learning [91], and ANN [2]. Predictive\nmaintenance tries to extend the maintenance intervals by\nmonitoring the machine\u2019s conditions, sparing costs for\nunnecessary, time-based scheduled, maintenance activities.\nIn contrast to preventive maintenance, there are several\nauthors applying machine learning methods in this field, and\nthe authors like to refer the interested reader to the review\nof Ahmad and Kamaruddin comparing both time-based and\ncondition-based maintenance for various examples [3].\n3.2 Optimization with parameter changes\nIn order to optimize parameters of industrial processes\nwhich were described by machine learning methods, the\ntypical workflow contains the following four steps [53]:\n1.\nGenerating a database with few experiments or run\nsimulations with DOE methods,\n2.\nModeling the physical correlations between the process\nparameters and the quality criteria with statistical or\nmachine learning methods,\n3.\nOptimization of the process parameters using the\ncreated process model,\n4.\nAdjusting the process parameters manually or automat-\nically.\nAs mentioned in Section 2, the database for modelling\nthe physical correlations with machine learning methods\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1893\n", []], "Plant diagnosis": ["3.1.4 Part diagnosis\nFor the diagnosis of parts, two main applications are\ndescribed, namely visual inspection and the diagnosis of\npart assemblies.\nAutomatic visual inspection, applied before, during, and\nafter production processes, serves to maintain good part\nquality, examining images for possible faults. Various meth-\nods were developed for the production of semiconductors\nand screen glasses [40, 43, 105], ceramics and tiles [47],\nand miscellaneous processes relating to metal parts [42, 63,\n88, 113, 121]. Additionally, generic methods for different\nmaterials and purposes were developed [73, 80].\nMethods for visual inspection vary over projection meth-\nods like independent component analysis [105] and PCA\n[17]; filter-based approaches like discrete cosine trans-\nform [76] and discrete wavelet transform [121]; learning-\nbased approaches like SVM [106], Hidden Markov Models\n(HMM) [42], fuzzy clustering [43], and convolutional neu-\nral networks (CNN) [63, 73, 80, 113] for regression or\nclassification; and statistical methods [88].\nDiagnosis of assembly processes or its results usually\nuses data sources different from images, resulting in the\nuse of different methods. Additionally, recent authors try to\ncover not only one specific processing stage but multi-stage\nprocesses as well. This complicates the problem to be solved\ndue to correlations between the different process steps and\nthe resulting error propagation. For sheet metal assemblies,\nCeglarek and Prakash [14] show a piecewise least squares\napproach for use in a state-space model. Their introduction\nreviews various publications in the field of fixture diagnosis\nmethods. The force signature of the assembling robot arm is\nused by Rodriguez et al. as input to an SVM [82]. Luo et al.\n[61] extend this approach by abstracting specific behavior\nrepresentations from the force signature.\n3.1.5 Plant diagnosis\nDiagnosis of production plants or machines can be\nrealized by anomaly detection methods. In anomaly\ndetection of production plants, one distinguishes between\nphenomenological and model-based approaches [70]. In\nphenomenological approaches, measurements are classified\ndirectly to detect anomalous behavior, while model-based\napproaches compare a system model representing the\nnormal system behavior and the system\u2019s measurement data.\nDue to the high amount of available publications,\nonly a short introduction into the topic is given and the\nimportant topic of one-class classification is being skipped.\nFor this, the authors would like to refer the interested\nreader to the comprehensive work of Shin et al. [96].\nIn case of phenomenological approaches, sensor data like\ntime-series data is processed. To extract features from\nit, transformations like wavelet transform [33], empirical\nmode decomposition [39, 117], or independent component\nanalysis [101] are used. The features can be processed with\nvarious algorithms like ANN, SVM, optimizers, or fuzzy\nlogic [127]. Typical applications are induction machines\n[8], pneumatic systems [27], gear boxes [86], and bearings\n[57]. Model-based approaches usually do not rely on feature\nextraction from time-series and can use machine learning\nalgorithms like PCA or partial least squares [120] directly.\nClosely related to anomaly detection methods, which are\nmostly used for failure detection, is the field of maintenance\nmethods which aim to prevent machine failures due\nto deterioration of the machine. A distinction is made\nbetween time-based and condition-based maintenance,\ncalled preventive and predictive maintenance [66].\nPreventive maintenance tries to extract the mean useful\nlife of a machine and/or its parts to schedule maintenance\nactivities before breakdown. To the author\u2019s knowledge, the\nuse of machine learning methods for this task has not been\nreported to the scientific community yet, as simple statistics\nleads to good results [66]. For preventive maintenance,\na mathematical formulation of the loss function to be\noptimized can be found (see, e.g., the work of Cassady and\nKutanoglu [13]). If the term of preventive maintenance is\nabstracted to the level of job shop scheduling, the work\nof Adibi et al. shows parameter estimation by clustering\n[1], reinforcement learning [91], and ANN [2]. Predictive\nmaintenance tries to extend the maintenance intervals by\nmonitoring the machine\u2019s conditions, sparing costs for\nunnecessary, time-based scheduled, maintenance activities.\nIn contrast to preventive maintenance, there are several\nauthors applying machine learning methods in this field, and\nthe authors like to refer the interested reader to the review\nof Ahmad and Kamaruddin comparing both time-based and\ncondition-based maintenance for various examples [3].\n3.2 Optimization with parameter changes\nIn order to optimize parameters of industrial processes\nwhich were described by machine learning methods, the\ntypical workflow contains the following four steps [53]:\n1.\nGenerating a database with few experiments or run\nsimulations with DOE methods,\n2.\nModeling the physical correlations between the process\nparameters and the quality criteria with statistical or\nmachine learning methods,\n3.\nOptimization of the process parameters using the\ncreated process model,\n4.\nAdjusting the process parameters manually or automat-\nically.\nAs mentioned in Section 2, the database for modelling\nthe physical correlations with machine learning methods\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1893\n", []], "Part diagnosis": ["3.1.4 Part diagnosis\nFor the diagnosis of parts, two main applications are\ndescribed, namely visual inspection and the diagnosis of\npart assemblies.\nAutomatic visual inspection, applied before, during, and\nafter production processes, serves to maintain good part\nquality, examining images for possible faults. Various meth-\nods were developed for the production of semiconductors\nand screen glasses [40, 43, 105], ceramics and tiles [47],\nand miscellaneous processes relating to metal parts [42, 63,\n88, 113, 121]. Additionally, generic methods for different\nmaterials and purposes were developed [73, 80].\nMethods for visual inspection vary over projection meth-\nods like independent component analysis [105] and PCA\n[17]; filter-based approaches like discrete cosine trans-\nform [76] and discrete wavelet transform [121]; learning-\nbased approaches like SVM [106], Hidden Markov Models\n(HMM) [42], fuzzy clustering [43], and convolutional neu-\nral networks (CNN) [63, 73, 80, 113] for regression or\nclassification; and statistical methods [88].\nDiagnosis of assembly processes or its results usually\nuses data sources different from images, resulting in the\nuse of different methods. Additionally, recent authors try to\ncover not only one specific processing stage but multi-stage\nprocesses as well. This complicates the problem to be solved\ndue to correlations between the different process steps and\nthe resulting error propagation. For sheet metal assemblies,\nCeglarek and Prakash [14] show a piecewise least squares\napproach for use in a state-space model. Their introduction\nreviews various publications in the field of fixture diagnosis\nmethods. The force signature of the assembling robot arm is\nused by Rodriguez et al. as input to an SVM [82]. Luo et al.\n[61] extend this approach by abstracting specific behavior\nrepresentations from the force signature.\n3.1.5 Plant diagnosis\nDiagnosis of production plants or machines can be\nrealized by anomaly detection methods. In anomaly\ndetection of production plants, one distinguishes between\nphenomenological and model-based approaches [70]. In\nphenomenological approaches, measurements are classified\ndirectly to detect anomalous behavior, while model-based\napproaches compare a system model representing the\nnormal system behavior and the system\u2019s measurement data.\nDue to the high amount of available publications,\nonly a short introduction into the topic is given and the\nimportant topic of one-class classification is being skipped.\nFor this, the authors would like to refer the interested\nreader to the comprehensive work of Shin et al. [96].\nIn case of phenomenological approaches, sensor data like\ntime-series data is processed. To extract features from\nit, transformations like wavelet transform [33], empirical\nmode decomposition [39, 117], or independent component\nanalysis [101] are used. The features can be processed with\nvarious algorithms like ANN, SVM, optimizers, or fuzzy\nlogic [127]. Typical applications are induction machines\n[8], pneumatic systems [27], gear boxes [86], and bearings\n[57]. Model-based approaches usually do not rely on feature\nextraction from time-series and can use machine learning\nalgorithms like PCA or partial least squares [120] directly.\nClosely related to anomaly detection methods, which are\nmostly used for failure detection, is the field of maintenance\nmethods which aim to prevent machine failures due\nto deterioration of the machine. A distinction is made\nbetween time-based and condition-based maintenance,\ncalled preventive and predictive maintenance [66].\nPreventive maintenance tries to extract the mean useful\nlife of a machine and/or its parts to schedule maintenance\nactivities before breakdown. To the author\u2019s knowledge, the\nuse of machine learning methods for this task has not been\nreported to the scientific community yet, as simple statistics\nleads to good results [66]. For preventive maintenance,\na mathematical formulation of the loss function to be\noptimized can be found (see, e.g., the work of Cassady and\nKutanoglu [13]). If the term of preventive maintenance is\nabstracted to the level of job shop scheduling, the work\nof Adibi et al. shows parameter estimation by clustering\n[1], reinforcement learning [91], and ANN [2]. Predictive\nmaintenance tries to extend the maintenance intervals by\nmonitoring the machine\u2019s conditions, sparing costs for\nunnecessary, time-based scheduled, maintenance activities.\nIn contrast to preventive maintenance, there are several\nauthors applying machine learning methods in this field, and\nthe authors like to refer the interested reader to the review\nof Ahmad and Kamaruddin comparing both time-based and\ncondition-based maintenance for various examples [3].\n3.2 Optimization with parameter changes\nIn order to optimize parameters of industrial processes\nwhich were described by machine learning methods, the\ntypical workflow contains the following four steps [53]:\n1.\nGenerating a database with few experiments or run\nsimulations with DOE methods,\n2.\nModeling the physical correlations between the process\nparameters and the quality criteria with statistical or\nmachine learning methods,\n3.\nOptimization of the process parameters using the\ncreated process model,\n4.\nAdjusting the process parameters manually or automat-\nically.\nAs mentioned in Section 2, the database for modelling\nthe physical correlations with machine learning methods\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1893\n", []], "Diagnostic systems": ["3.1.1 Root cause analysis\nAn obvious approach for quality improvement is the\nanalysis of existing data records to extract relevant features\nand feature combinations for high or low product quality.\nThis might be done by feature selection at a preliminary\nstage of learning a model or as specific root cause analysis.\nThere exists a lot of literature in these fields (see the\nalready mentioned reviews [10, 15, 37, 67, 92, 112, 118])\nand analysts seem to be satisfied with the identification\nof previously unknown patterns and important features\nrelevant to product quality. Reports on the consequences of\nchanges of production parameters drawn from the patterns\nare rare.\nIn the sector of semiconductor manufacturing, the\nresearch of Chien et al. on root cause analysis is quite\nfundamental. In his work, he proposed k-means clustering\n[24]; principal component analysis (PCA), clustering, and\ndecision trees [22]; stepwise batch regression algorithms\nwith random forests [21] and feature selection together with\nlogistic regression [23] to find root causes for poor quality\nand finally enhance yield.\nOther authors such as Kumar et al. [56] or Diao et al.\n[30] apply hierarchical generalized linear models (GLM)\nor improved PCA and modified support vector machines\n(SVM) to identify dominant factors for quality and quality\nprediction. It is also possible to apply Gibbs Sampling\nfor variable selection, learn multivariate adaptive regression\nsplines (MARS) to predict semiconductor yield, and use\ndecision tables to extract root causes [49].\nAnother method to find root causes for quality issues\nis the extraction of defect patterns. For instance, Franciosa\net al. [32] analyze a multi-stage assembly system and\nutilize a combination of multi-physics simulations from\nfirst principles, measurement data and artificial neural\nnetworks (ANN) to identify defect patterns. In the field\nof semiconductor production, Wang [110] proposes the\nclustering of defect patterns.\nAssociation rule mining is a method to extract inter-\npretable relationships relevant for product quality (see\n[114] in semiconductor manufacturing). In drill produc-\ntion, Kamsu-Foguem et al. thoroughly describe the use of\nassociation rules [44].\n3.1.2 Early prediction of manufacturing outcomes\nIn optimization of manufacturing processes, not only is\nproduct quality a highly relevant criterion, but so are\nthe costs of production steps. If production steps are\nexpensive in terms of time or price, it is useful to\npredict manufacturing outcomes beforehand. With this\nmethod, unnecessary and costly production steps can be\navoided by dropping products from the production line\nbefore the critical steps. Alternatively, additive corrective\nmanufacturing actions can be initiated, for example the\ncorrection of wafers with expected poor performance in\nsemiconductor production [116].\nThe early prediction of production outcomes differs from\ntraditional process identification in the size of the parameter\nset. For process identification, a full set of relevant\nproduction parameters of all processing stages is needed,\nwhile the early prediction already works with process\nparameters of an early relevant part of the production line,\nallowing to introduce correcting actions before finishing the\nwhole production process.\nBut simple process identification with the full parameter\nset enables the so-called virtual metrology as exemplarily\ndescribed by Kang et al. [45] and Khan et al. [50]. Here,\nthe quality of the out-of-sample products is predicted by a\nmachine learning method, saving time and costs. As this\ndoes not optimize the production process but only means\na regression/classification of the production output, the\nauthors would like to refer the reader to the work mentioned\nabove.\nThe challenge of the early prediction of manufacturing\noutcomes is to make a reliable prediction of the final quality\nat early stages of the process and to identify relations\nbetween process steps. Several authors proposed solutions,\ne. g., the work of Lieber et al. [59] and Konrad et al.\n[54] for rolling mill processes with self-organizing maps\n(SOM) and k-Nearest-Neighbor (kNN) approaches or Arif\net al. [5] for decision trees in semiconductor manufacturing.\nBoth works have in common that no application was\nreported.\nMore promising is the work of Weiss et al. [115,\n116], who estimated the final microprocessor speed after\neach manufacturing operation applying linear regression\nand boosted trees: the predictions initiating corrective\nmanufacturing actions if necessary. The authors were\nchallenged by the already mentioned concept drift, missing\ndata, and imbalanced datasets. Special methods to overcome\nthese problems were developed by Chen and Boning [16],\nwho apply boosting and bagging of customized decision\ntrees to predict semiconductor yield before packaging.\n3.1.3 Diagnostic systems\nAnother way of optimizing the final quality of a product is\nthe use of diagnostic systems within the production line. It is\npossible to monitor the product itself (part diagnosis) and/or\nthe processing machines (plant diagnosis). Both approaches\nlead to an alarm being raised if the condition of the part or\nmachine is anomalous or becoming anomalous, requesting\ncorrection actions to be taken.\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1892\n", []], "Early prediction of manufacturing outcomes": ["3.1.1 Root cause analysis\nAn obvious approach for quality improvement is the\nanalysis of existing data records to extract relevant features\nand feature combinations for high or low product quality.\nThis might be done by feature selection at a preliminary\nstage of learning a model or as specific root cause analysis.\nThere exists a lot of literature in these fields (see the\nalready mentioned reviews [10, 15, 37, 67, 92, 112, 118])\nand analysts seem to be satisfied with the identification\nof previously unknown patterns and important features\nrelevant to product quality. Reports on the consequences of\nchanges of production parameters drawn from the patterns\nare rare.\nIn the sector of semiconductor manufacturing, the\nresearch of Chien et al. on root cause analysis is quite\nfundamental. In his work, he proposed k-means clustering\n[24]; principal component analysis (PCA), clustering, and\ndecision trees [22]; stepwise batch regression algorithms\nwith random forests [21] and feature selection together with\nlogistic regression [23] to find root causes for poor quality\nand finally enhance yield.\nOther authors such as Kumar et al. [56] or Diao et al.\n[30] apply hierarchical generalized linear models (GLM)\nor improved PCA and modified support vector machines\n(SVM) to identify dominant factors for quality and quality\nprediction. It is also possible to apply Gibbs Sampling\nfor variable selection, learn multivariate adaptive regression\nsplines (MARS) to predict semiconductor yield, and use\ndecision tables to extract root causes [49].\nAnother method to find root causes for quality issues\nis the extraction of defect patterns. For instance, Franciosa\net al. [32] analyze a multi-stage assembly system and\nutilize a combination of multi-physics simulations from\nfirst principles, measurement data and artificial neural\nnetworks (ANN) to identify defect patterns. In the field\nof semiconductor production, Wang [110] proposes the\nclustering of defect patterns.\nAssociation rule mining is a method to extract inter-\npretable relationships relevant for product quality (see\n[114] in semiconductor manufacturing). In drill produc-\ntion, Kamsu-Foguem et al. thoroughly describe the use of\nassociation rules [44].\n3.1.2 Early prediction of manufacturing outcomes\nIn optimization of manufacturing processes, not only is\nproduct quality a highly relevant criterion, but so are\nthe costs of production steps. If production steps are\nexpensive in terms of time or price, it is useful to\npredict manufacturing outcomes beforehand. With this\nmethod, unnecessary and costly production steps can be\navoided by dropping products from the production line\nbefore the critical steps. Alternatively, additive corrective\nmanufacturing actions can be initiated, for example the\ncorrection of wafers with expected poor performance in\nsemiconductor production [116].\nThe early prediction of production outcomes differs from\ntraditional process identification in the size of the parameter\nset. For process identification, a full set of relevant\nproduction parameters of all processing stages is needed,\nwhile the early prediction already works with process\nparameters of an early relevant part of the production line,\nallowing to introduce correcting actions before finishing the\nwhole production process.\nBut simple process identification with the full parameter\nset enables the so-called virtual metrology as exemplarily\ndescribed by Kang et al. [45] and Khan et al. [50]. Here,\nthe quality of the out-of-sample products is predicted by a\nmachine learning method, saving time and costs. As this\ndoes not optimize the production process but only means\na regression/classification of the production output, the\nauthors would like to refer the reader to the work mentioned\nabove.\nThe challenge of the early prediction of manufacturing\noutcomes is to make a reliable prediction of the final quality\nat early stages of the process and to identify relations\nbetween process steps. Several authors proposed solutions,\ne. g., the work of Lieber et al. [59] and Konrad et al.\n[54] for rolling mill processes with self-organizing maps\n(SOM) and k-Nearest-Neighbor (kNN) approaches or Arif\net al. [5] for decision trees in semiconductor manufacturing.\nBoth works have in common that no application was\nreported.\nMore promising is the work of Weiss et al. [115,\n116], who estimated the final microprocessor speed after\neach manufacturing operation applying linear regression\nand boosted trees: the predictions initiating corrective\nmanufacturing actions if necessary. The authors were\nchallenged by the already mentioned concept drift, missing\ndata, and imbalanced datasets. Special methods to overcome\nthese problems were developed by Chen and Boning [16],\nwho apply boosting and bagging of customized decision\ntrees to predict semiconductor yield before packaging.\n3.1.3 Diagnostic systems\nAnother way of optimizing the final quality of a product is\nthe use of diagnostic systems within the production line. It is\npossible to monitor the product itself (part diagnosis) and/or\nthe processing machines (plant diagnosis). Both approaches\nlead to an alarm being raised if the condition of the part or\nmachine is anomalous or becoming anomalous, requesting\ncorrection actions to be taken.\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1892\n", []], "Root cause analysis": ["3.1.1 Root cause analysis\nAn obvious approach for quality improvement is the\nanalysis of existing data records to extract relevant features\nand feature combinations for high or low product quality.\nThis might be done by feature selection at a preliminary\nstage of learning a model or as specific root cause analysis.\nThere exists a lot of literature in these fields (see the\nalready mentioned reviews [10, 15, 37, 67, 92, 112, 118])\nand analysts seem to be satisfied with the identification\nof previously unknown patterns and important features\nrelevant to product quality. Reports on the consequences of\nchanges of production parameters drawn from the patterns\nare rare.\nIn the sector of semiconductor manufacturing, the\nresearch of Chien et al. on root cause analysis is quite\nfundamental. In his work, he proposed k-means clustering\n[24]; principal component analysis (PCA), clustering, and\ndecision trees [22]; stepwise batch regression algorithms\nwith random forests [21] and feature selection together with\nlogistic regression [23] to find root causes for poor quality\nand finally enhance yield.\nOther authors such as Kumar et al. [56] or Diao et al.\n[30] apply hierarchical generalized linear models (GLM)\nor improved PCA and modified support vector machines\n(SVM) to identify dominant factors for quality and quality\nprediction. It is also possible to apply Gibbs Sampling\nfor variable selection, learn multivariate adaptive regression\nsplines (MARS) to predict semiconductor yield, and use\ndecision tables to extract root causes [49].\nAnother method to find root causes for quality issues\nis the extraction of defect patterns. For instance, Franciosa\net al. [32] analyze a multi-stage assembly system and\nutilize a combination of multi-physics simulations from\nfirst principles, measurement data and artificial neural\nnetworks (ANN) to identify defect patterns. In the field\nof semiconductor production, Wang [110] proposes the\nclustering of defect patterns.\nAssociation rule mining is a method to extract inter-\npretable relationships relevant for product quality (see\n[114] in semiconductor manufacturing). In drill produc-\ntion, Kamsu-Foguem et al. thoroughly describe the use of\nassociation rules [44].\n3.1.2 Early prediction of manufacturing outcomes\nIn optimization of manufacturing processes, not only is\nproduct quality a highly relevant criterion, but so are\nthe costs of production steps. If production steps are\nexpensive in terms of time or price, it is useful to\npredict manufacturing outcomes beforehand. With this\nmethod, unnecessary and costly production steps can be\navoided by dropping products from the production line\nbefore the critical steps. Alternatively, additive corrective\nmanufacturing actions can be initiated, for example the\ncorrection of wafers with expected poor performance in\nsemiconductor production [116].\nThe early prediction of production outcomes differs from\ntraditional process identification in the size of the parameter\nset. For process identification, a full set of relevant\nproduction parameters of all processing stages is needed,\nwhile the early prediction already works with process\nparameters of an early relevant part of the production line,\nallowing to introduce correcting actions before finishing the\nwhole production process.\nBut simple process identification with the full parameter\nset enables the so-called virtual metrology as exemplarily\ndescribed by Kang et al. [45] and Khan et al. [50]. Here,\nthe quality of the out-of-sample products is predicted by a\nmachine learning method, saving time and costs. As this\ndoes not optimize the production process but only means\na regression/classification of the production output, the\nauthors would like to refer the reader to the work mentioned\nabove.\nThe challenge of the early prediction of manufacturing\noutcomes is to make a reliable prediction of the final quality\nat early stages of the process and to identify relations\nbetween process steps. Several authors proposed solutions,\ne. g., the work of Lieber et al. [59] and Konrad et al.\n[54] for rolling mill processes with self-organizing maps\n(SOM) and k-Nearest-Neighbor (kNN) approaches or Arif\net al. [5] for decision trees in semiconductor manufacturing.\nBoth works have in common that no application was\nreported.\nMore promising is the work of Weiss et al. [115,\n116], who estimated the final microprocessor speed after\neach manufacturing operation applying linear regression\nand boosted trees: the predictions initiating corrective\nmanufacturing actions if necessary. The authors were\nchallenged by the already mentioned concept drift, missing\ndata, and imbalanced datasets. Special methods to overcome\nthese problems were developed by Chen and Boning [16],\nwho apply boosting and bagging of customized decision\ntrees to predict semiconductor yield before packaging.\n3.1.3 Diagnostic systems\nAnother way of optimizing the final quality of a product is\nthe use of diagnostic systems within the production line. It is\npossible to monitor the product itself (part diagnosis) and/or\nthe processing machines (plant diagnosis). Both approaches\nlead to an alarm being raised if the condition of the part or\nmachine is anomalous or becoming anomalous, requesting\ncorrection actions to be taken.\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1892\n", []], "Optimization without parameter changes": ["parameter is for example the sheet thickness at the begin-\nning of a press hardening process because this parameter is\ndefined by the coil producer. A controllable parameter can\nbe the time a part remains in the press.\n2.4 Present vs. historical data\nAnother way of subdividing data may be with respect to its\nmeasurement date. Machine learning algorithms can learn\nfrom historical data and then use present data to predict\nfuture outcomes. However, it has to be taken into account\nthat the data acquisition can be changed and adapted over\ntime. Therefore, it may be necessary to clean up historical\ndata, as for example described in [38] or models based on\nolder data have to be retrained.\n2.5 Measured vs. simulated data\nThe origin of data also plays a significant role. It is\nimportant to verify simulated data with real data. The\nuse of both simulated and experimental data is also\npossible (see for example [25] where new simulations are\nautomatically performed in order to improve the prediction\nquality of a platform that incorporates experimental data,\ncomputational simulations, and a machine learning model).\nIn the case of production processes, it should also be\nconsidered that established and robust processes almost\nexclusively produce good parts and very few data are\navailable for rejected parts. However, machine learning\nmodels need balanced data, so simulation plays a key role\nhere [7].\n2.6 Observable quantities vs. process state variables\nIn many manufacturing processes, it is not possible to\nmeasure on-line the state variable values that describe\nthe system state and are essential for process control.\nInstead, only quantities related to the state variables can be\nobserved [89]. Senn et al. [89, 90] for example describe\na deep drawing process where observable quantities are\nforces, displacements, and strains while state variables are\nthe high-dimensional stresses in the workpiece at various\nlocations.\nThe knowledge of the structure of production data is\ncrucial for the right choice of machine learning models.\nMost data coming from production systems equipped with\nsensors can be considered as structured data which is\nmuch easier to handle than unstructured data [85]. Another\nimportant aspect which is not the focus of this manuscript is\nthe fusion of data from multiple sensors. More information\non this topic can be found in [60] or [81]. The next section\ndescribes different approaches for a machine learning\u2013\nbased optimization in production.\n3 Application of machine learning\nfor optimization of production\nProcess optimization by machine learning can be struc-\ntured into two main topics, distinguished by the adjust-\nment of production parameters. The first is optimiza-\ntion without change of production parameters during the\nmanufacturing process. Examples are root cause analy-\nses to prevent from recurrent quality issues, early pre-\ndiction of manufacturing outcomes to spare unnecessary\nprocess steps, and diagnostic methods to detect erroneous\nbehavior of products or processing units. All examples\nhave in common that there is no direct adjustment of\nthe production parameters but product quality is improved\nindirectly.\nA second topic is optimization with change of production\nparameters.\nHere, optimal production parameters are\ndetermined using the data of an already running production\nprocess. By adjusting the parameters to the characteristics\nof the product and the specific optimization goal, a higher\nquality is achieved. Implementations can be distinguished in\nmachine learning approaches with additional optimization\nmodules and self-optimizing control systems based on\nanalytical process models. In this paper, only machine\nlearning approaches are discussed.\nIn both (direct and indirect) approaches, the objective\nfor optimization can be a product- or process-specific\nquantity. Product-specific quantities are for example surface\nroughness, shrinkage, and processor speed, while the energy\nconsumption of a plant or tool wear is a process-specific\none. Optimization of both types of objectives results in\nimproved product quality defined in terms of cost, time,\nconsumption of resources, and/or the specific optimization\nobjective.\n3.1 Optimization without parameter changes\nTypical industrial applications for quality improvement\nbased on machine learning are found in large-scale\nproduction such as plastic injection molding (PIM) and\nthe production of semiconductors. The authors assume\nthat this is grounded on the high amounts of usable\ndata points provided due to short cycle times. Especially\nthat in the manufacturing of micro-electronic parts exists\nlong-lasting tradition (see, e.g., [4, 41] for examples\nfor classification algorithms in industry as early as in\n1993). Up to now, scientists are still challenged by\nimbalanced datasets, missing data, and concept drift [16,\n115]. The following section provides an overview of\nthree different approaches for optimization without change\nof the production parameters: Root cause analysis, early\nprediction of manufacturing outcomes, and diagnostic\nsystems.\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1891\n", []], "Application of machine learning for optimization of production": ["parameter is for example the sheet thickness at the begin-\nning of a press hardening process because this parameter is\ndefined by the coil producer. A controllable parameter can\nbe the time a part remains in the press.\n2.4 Present vs. historical data\nAnother way of subdividing data may be with respect to its\nmeasurement date. Machine learning algorithms can learn\nfrom historical data and then use present data to predict\nfuture outcomes. However, it has to be taken into account\nthat the data acquisition can be changed and adapted over\ntime. Therefore, it may be necessary to clean up historical\ndata, as for example described in [38] or models based on\nolder data have to be retrained.\n2.5 Measured vs. simulated data\nThe origin of data also plays a significant role. It is\nimportant to verify simulated data with real data. The\nuse of both simulated and experimental data is also\npossible (see for example [25] where new simulations are\nautomatically performed in order to improve the prediction\nquality of a platform that incorporates experimental data,\ncomputational simulations, and a machine learning model).\nIn the case of production processes, it should also be\nconsidered that established and robust processes almost\nexclusively produce good parts and very few data are\navailable for rejected parts. However, machine learning\nmodels need balanced data, so simulation plays a key role\nhere [7].\n2.6 Observable quantities vs. process state variables\nIn many manufacturing processes, it is not possible to\nmeasure on-line the state variable values that describe\nthe system state and are essential for process control.\nInstead, only quantities related to the state variables can be\nobserved [89]. Senn et al. [89, 90] for example describe\na deep drawing process where observable quantities are\nforces, displacements, and strains while state variables are\nthe high-dimensional stresses in the workpiece at various\nlocations.\nThe knowledge of the structure of production data is\ncrucial for the right choice of machine learning models.\nMost data coming from production systems equipped with\nsensors can be considered as structured data which is\nmuch easier to handle than unstructured data [85]. Another\nimportant aspect which is not the focus of this manuscript is\nthe fusion of data from multiple sensors. More information\non this topic can be found in [60] or [81]. The next section\ndescribes different approaches for a machine learning\u2013\nbased optimization in production.\n3 Application of machine learning\nfor optimization of production\nProcess optimization by machine learning can be struc-\ntured into two main topics, distinguished by the adjust-\nment of production parameters. The first is optimiza-\ntion without change of production parameters during the\nmanufacturing process. Examples are root cause analy-\nses to prevent from recurrent quality issues, early pre-\ndiction of manufacturing outcomes to spare unnecessary\nprocess steps, and diagnostic methods to detect erroneous\nbehavior of products or processing units. All examples\nhave in common that there is no direct adjustment of\nthe production parameters but product quality is improved\nindirectly.\nA second topic is optimization with change of production\nparameters.\nHere, optimal production parameters are\ndetermined using the data of an already running production\nprocess. By adjusting the parameters to the characteristics\nof the product and the specific optimization goal, a higher\nquality is achieved. Implementations can be distinguished in\nmachine learning approaches with additional optimization\nmodules and self-optimizing control systems based on\nanalytical process models. In this paper, only machine\nlearning approaches are discussed.\nIn both (direct and indirect) approaches, the objective\nfor optimization can be a product- or process-specific\nquantity. Product-specific quantities are for example surface\nroughness, shrinkage, and processor speed, while the energy\nconsumption of a plant or tool wear is a process-specific\none. Optimization of both types of objectives results in\nimproved product quality defined in terms of cost, time,\nconsumption of resources, and/or the specific optimization\nobjective.\n3.1 Optimization without parameter changes\nTypical industrial applications for quality improvement\nbased on machine learning are found in large-scale\nproduction such as plastic injection molding (PIM) and\nthe production of semiconductors. The authors assume\nthat this is grounded on the high amounts of usable\ndata points provided due to short cycle times. Especially\nthat in the manufacturing of micro-electronic parts exists\nlong-lasting tradition (see, e.g., [4, 41] for examples\nfor classification algorithms in industry as early as in\n1993). Up to now, scientists are still challenged by\nimbalanced datasets, missing data, and concept drift [16,\n115]. The following section provides an overview of\nthree different approaches for optimization without change\nof the production parameters: Root cause analysis, early\nprediction of manufacturing outcomes, and diagnostic\nsystems.\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1891\n", []], "Observable quantities vs. process state variables": ["parameter is for example the sheet thickness at the begin-\nning of a press hardening process because this parameter is\ndefined by the coil producer. A controllable parameter can\nbe the time a part remains in the press.\n2.4 Present vs. historical data\nAnother way of subdividing data may be with respect to its\nmeasurement date. Machine learning algorithms can learn\nfrom historical data and then use present data to predict\nfuture outcomes. However, it has to be taken into account\nthat the data acquisition can be changed and adapted over\ntime. Therefore, it may be necessary to clean up historical\ndata, as for example described in [38] or models based on\nolder data have to be retrained.\n2.5 Measured vs. simulated data\nThe origin of data also plays a significant role. It is\nimportant to verify simulated data with real data. The\nuse of both simulated and experimental data is also\npossible (see for example [25] where new simulations are\nautomatically performed in order to improve the prediction\nquality of a platform that incorporates experimental data,\ncomputational simulations, and a machine learning model).\nIn the case of production processes, it should also be\nconsidered that established and robust processes almost\nexclusively produce good parts and very few data are\navailable for rejected parts. However, machine learning\nmodels need balanced data, so simulation plays a key role\nhere [7].\n2.6 Observable quantities vs. process state variables\nIn many manufacturing processes, it is not possible to\nmeasure on-line the state variable values that describe\nthe system state and are essential for process control.\nInstead, only quantities related to the state variables can be\nobserved [89]. Senn et al. [89, 90] for example describe\na deep drawing process where observable quantities are\nforces, displacements, and strains while state variables are\nthe high-dimensional stresses in the workpiece at various\nlocations.\nThe knowledge of the structure of production data is\ncrucial for the right choice of machine learning models.\nMost data coming from production systems equipped with\nsensors can be considered as structured data which is\nmuch easier to handle than unstructured data [85]. Another\nimportant aspect which is not the focus of this manuscript is\nthe fusion of data from multiple sensors. More information\non this topic can be found in [60] or [81]. The next section\ndescribes different approaches for a machine learning\u2013\nbased optimization in production.\n3 Application of machine learning\nfor optimization of production\nProcess optimization by machine learning can be struc-\ntured into two main topics, distinguished by the adjust-\nment of production parameters. The first is optimiza-\ntion without change of production parameters during the\nmanufacturing process. Examples are root cause analy-\nses to prevent from recurrent quality issues, early pre-\ndiction of manufacturing outcomes to spare unnecessary\nprocess steps, and diagnostic methods to detect erroneous\nbehavior of products or processing units. All examples\nhave in common that there is no direct adjustment of\nthe production parameters but product quality is improved\nindirectly.\nA second topic is optimization with change of production\nparameters.\nHere, optimal production parameters are\ndetermined using the data of an already running production\nprocess. By adjusting the parameters to the characteristics\nof the product and the specific optimization goal, a higher\nquality is achieved. Implementations can be distinguished in\nmachine learning approaches with additional optimization\nmodules and self-optimizing control systems based on\nanalytical process models. In this paper, only machine\nlearning approaches are discussed.\nIn both (direct and indirect) approaches, the objective\nfor optimization can be a product- or process-specific\nquantity. Product-specific quantities are for example surface\nroughness, shrinkage, and processor speed, while the energy\nconsumption of a plant or tool wear is a process-specific\none. Optimization of both types of objectives results in\nimproved product quality defined in terms of cost, time,\nconsumption of resources, and/or the specific optimization\nobjective.\n3.1 Optimization without parameter changes\nTypical industrial applications for quality improvement\nbased on machine learning are found in large-scale\nproduction such as plastic injection molding (PIM) and\nthe production of semiconductors. The authors assume\nthat this is grounded on the high amounts of usable\ndata points provided due to short cycle times. Especially\nthat in the manufacturing of micro-electronic parts exists\nlong-lasting tradition (see, e.g., [4, 41] for examples\nfor classification algorithms in industry as early as in\n1993). Up to now, scientists are still challenged by\nimbalanced datasets, missing data, and concept drift [16,\n115]. The following section provides an overview of\nthree different approaches for optimization without change\nof the production parameters: Root cause analysis, early\nprediction of manufacturing outcomes, and diagnostic\nsystems.\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1891\n", []], "Measured vs. simulated data": ["parameter is for example the sheet thickness at the begin-\nning of a press hardening process because this parameter is\ndefined by the coil producer. A controllable parameter can\nbe the time a part remains in the press.\n2.4 Present vs. historical data\nAnother way of subdividing data may be with respect to its\nmeasurement date. Machine learning algorithms can learn\nfrom historical data and then use present data to predict\nfuture outcomes. However, it has to be taken into account\nthat the data acquisition can be changed and adapted over\ntime. Therefore, it may be necessary to clean up historical\ndata, as for example described in [38] or models based on\nolder data have to be retrained.\n2.5 Measured vs. simulated data\nThe origin of data also plays a significant role. It is\nimportant to verify simulated data with real data. The\nuse of both simulated and experimental data is also\npossible (see for example [25] where new simulations are\nautomatically performed in order to improve the prediction\nquality of a platform that incorporates experimental data,\ncomputational simulations, and a machine learning model).\nIn the case of production processes, it should also be\nconsidered that established and robust processes almost\nexclusively produce good parts and very few data are\navailable for rejected parts. However, machine learning\nmodels need balanced data, so simulation plays a key role\nhere [7].\n2.6 Observable quantities vs. process state variables\nIn many manufacturing processes, it is not possible to\nmeasure on-line the state variable values that describe\nthe system state and are essential for process control.\nInstead, only quantities related to the state variables can be\nobserved [89]. Senn et al. [89, 90] for example describe\na deep drawing process where observable quantities are\nforces, displacements, and strains while state variables are\nthe high-dimensional stresses in the workpiece at various\nlocations.\nThe knowledge of the structure of production data is\ncrucial for the right choice of machine learning models.\nMost data coming from production systems equipped with\nsensors can be considered as structured data which is\nmuch easier to handle than unstructured data [85]. Another\nimportant aspect which is not the focus of this manuscript is\nthe fusion of data from multiple sensors. More information\non this topic can be found in [60] or [81]. The next section\ndescribes different approaches for a machine learning\u2013\nbased optimization in production.\n3 Application of machine learning\nfor optimization of production\nProcess optimization by machine learning can be struc-\ntured into two main topics, distinguished by the adjust-\nment of production parameters. The first is optimiza-\ntion without change of production parameters during the\nmanufacturing process. Examples are root cause analy-\nses to prevent from recurrent quality issues, early pre-\ndiction of manufacturing outcomes to spare unnecessary\nprocess steps, and diagnostic methods to detect erroneous\nbehavior of products or processing units. All examples\nhave in common that there is no direct adjustment of\nthe production parameters but product quality is improved\nindirectly.\nA second topic is optimization with change of production\nparameters.\nHere, optimal production parameters are\ndetermined using the data of an already running production\nprocess. By adjusting the parameters to the characteristics\nof the product and the specific optimization goal, a higher\nquality is achieved. Implementations can be distinguished in\nmachine learning approaches with additional optimization\nmodules and self-optimizing control systems based on\nanalytical process models. In this paper, only machine\nlearning approaches are discussed.\nIn both (direct and indirect) approaches, the objective\nfor optimization can be a product- or process-specific\nquantity. Product-specific quantities are for example surface\nroughness, shrinkage, and processor speed, while the energy\nconsumption of a plant or tool wear is a process-specific\none. Optimization of both types of objectives results in\nimproved product quality defined in terms of cost, time,\nconsumption of resources, and/or the specific optimization\nobjective.\n3.1 Optimization without parameter changes\nTypical industrial applications for quality improvement\nbased on machine learning are found in large-scale\nproduction such as plastic injection molding (PIM) and\nthe production of semiconductors. The authors assume\nthat this is grounded on the high amounts of usable\ndata points provided due to short cycle times. Especially\nthat in the manufacturing of micro-electronic parts exists\nlong-lasting tradition (see, e.g., [4, 41] for examples\nfor classification algorithms in industry as early as in\n1993). Up to now, scientists are still challenged by\nimbalanced datasets, missing data, and concept drift [16,\n115]. The following section provides an overview of\nthree different approaches for optimization without change\nof the production parameters: Root cause analysis, early\nprediction of manufacturing outcomes, and diagnostic\nsystems.\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1891\n", []], "Present vs. historical data": ["parameter is for example the sheet thickness at the begin-\nning of a press hardening process because this parameter is\ndefined by the coil producer. A controllable parameter can\nbe the time a part remains in the press.\n2.4 Present vs. historical data\nAnother way of subdividing data may be with respect to its\nmeasurement date. Machine learning algorithms can learn\nfrom historical data and then use present data to predict\nfuture outcomes. However, it has to be taken into account\nthat the data acquisition can be changed and adapted over\ntime. Therefore, it may be necessary to clean up historical\ndata, as for example described in [38] or models based on\nolder data have to be retrained.\n2.5 Measured vs. simulated data\nThe origin of data also plays a significant role. It is\nimportant to verify simulated data with real data. The\nuse of both simulated and experimental data is also\npossible (see for example [25] where new simulations are\nautomatically performed in order to improve the prediction\nquality of a platform that incorporates experimental data,\ncomputational simulations, and a machine learning model).\nIn the case of production processes, it should also be\nconsidered that established and robust processes almost\nexclusively produce good parts and very few data are\navailable for rejected parts. However, machine learning\nmodels need balanced data, so simulation plays a key role\nhere [7].\n2.6 Observable quantities vs. process state variables\nIn many manufacturing processes, it is not possible to\nmeasure on-line the state variable values that describe\nthe system state and are essential for process control.\nInstead, only quantities related to the state variables can be\nobserved [89]. Senn et al. [89, 90] for example describe\na deep drawing process where observable quantities are\nforces, displacements, and strains while state variables are\nthe high-dimensional stresses in the workpiece at various\nlocations.\nThe knowledge of the structure of production data is\ncrucial for the right choice of machine learning models.\nMost data coming from production systems equipped with\nsensors can be considered as structured data which is\nmuch easier to handle than unstructured data [85]. Another\nimportant aspect which is not the focus of this manuscript is\nthe fusion of data from multiple sensors. More information\non this topic can be found in [60] or [81]. The next section\ndescribes different approaches for a machine learning\u2013\nbased optimization in production.\n3 Application of machine learning\nfor optimization of production\nProcess optimization by machine learning can be struc-\ntured into two main topics, distinguished by the adjust-\nment of production parameters. The first is optimiza-\ntion without change of production parameters during the\nmanufacturing process. Examples are root cause analy-\nses to prevent from recurrent quality issues, early pre-\ndiction of manufacturing outcomes to spare unnecessary\nprocess steps, and diagnostic methods to detect erroneous\nbehavior of products or processing units. All examples\nhave in common that there is no direct adjustment of\nthe production parameters but product quality is improved\nindirectly.\nA second topic is optimization with change of production\nparameters.\nHere, optimal production parameters are\ndetermined using the data of an already running production\nprocess. By adjusting the parameters to the characteristics\nof the product and the specific optimization goal, a higher\nquality is achieved. Implementations can be distinguished in\nmachine learning approaches with additional optimization\nmodules and self-optimizing control systems based on\nanalytical process models. In this paper, only machine\nlearning approaches are discussed.\nIn both (direct and indirect) approaches, the objective\nfor optimization can be a product- or process-specific\nquantity. Product-specific quantities are for example surface\nroughness, shrinkage, and processor speed, while the energy\nconsumption of a plant or tool wear is a process-specific\none. Optimization of both types of objectives results in\nimproved product quality defined in terms of cost, time,\nconsumption of resources, and/or the specific optimization\nobjective.\n3.1 Optimization without parameter changes\nTypical industrial applications for quality improvement\nbased on machine learning are found in large-scale\nproduction such as plastic injection molding (PIM) and\nthe production of semiconductors. The authors assume\nthat this is grounded on the high amounts of usable\ndata points provided due to short cycle times. Especially\nthat in the manufacturing of micro-electronic parts exists\nlong-lasting tradition (see, e.g., [4, 41] for examples\nfor classification algorithms in industry as early as in\n1993). Up to now, scientists are still challenged by\nimbalanced datasets, missing data, and concept drift [16,\n115]. The following section provides an overview of\nthree different approaches for optimization without change\nof the production parameters: Root cause analysis, early\nprediction of manufacturing outcomes, and diagnostic\nsystems.\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1891\n", []], "Controllable vs. uncontrollable data": ["to 2018. Since earlier years, the authors refer to the\nextensive review of K\u00a8oksal et al. focusing on data min-\ning applications for quality improvement in manufactur-\ning industry [53]. Additionally, there exist more general\nreviews on machine learning in manufacturing that either\ndo not explicitly concentrate on optimization issues [10,\n37, 67, 92, 118] or focus on special methods and/or\napplications [15, 112].\nThe interest in the integration of machine learning\nand optimization algorithms in production processes has\nincreased steadily since 2009 and has been at a consistently\nhigh level since 2014. Thus, it remains a hot topic in\nlatest research, starting with the development of scientific\nmethods for sensor placement, going through data storage\nand processing architectures, and ending with machine\nlearning and optimization algorithms [118].\nSince the field of machine learning and optimization\nin production processes is very wide, the authors have\nidentified three closely related topics that will not be\ncovered extensively in this review. The first one is\noptimization with methods from the field of design of\nexperiments (DOE) and response surface methodology\n(RSM). Even if a DOE or RSM is used in applications,\nthe review will not focus on the specific designs. Here,\nthe authors like to refer the interested reader to the\ncomprehensive work of Montgomery [68], as a detailed\ndescription of methods and applications is beyond the\nscope of this review. The second topic is statistical process\ncontrol (SPC), pioneered by Shewhardt in 1925, which uses\nclassical statistical analysis of the collected data for process\nvariation reduction [93]. As the majority of publications\ndoes not fall back to the methods of \u201cmodern\u201d machine\nlearning, this field of research is excluded. A third topic\nto exclude is model predictive control (MPC) as a special\nfield of control engineering. Here, the authors would like\nto refer the interested reader for example to the work of\nMayne [64] and Scattolini [87]. In general, the application\nof machine learning methods for the optimization of\nproduction processes can take place with or without an\nimmediate quality feedback, depending on its\u2019 availability.\nWith a quality feedback, it is quite similar to closed\nloop control engineering, as it is used to adapt process\nparameters to improve the measured quality. But as neither\nthe quality feedback, the process parameters and the process\ndescription itself are in the typical format used for closed\nloop control (feedback and parameters as time series data\nand the process description as a state equation), nor is\nthere a frequent change of the parameters during a running\nproduction step, the authors will exclude this special field of\nresearch from the review.\nThe paper is organized as follows: firstly, the occurring\ndata types in manufacturing are reviewed. Secondly, an\noverview on applications of machine learning for quality\nimprovement without change of manufacturing parameters\nduring the process is given. Subsequently, applications\nwhere explicit changes of manufacturing parameters are\nallowed are reviewed in detail. After a detailed analysis\nconnecting data, machine learning, and optimization, a\nconclusion is drawn and open research questions are\ndiscussed.\n2 Data in machine learning in production\nThe first step to solving a machine learning problem is\nto identify the data that is available. There are different\ntypes of data which will affect the type of analyses that\ncan be used on them. Based on their types, the amount\nof information which data gives can vary considerably\n[11]. Data can be structured in the following ways. Topics\nsuch as data quality, missing data, or details about data\npreprocessing will not be addressed in this work, but may\nbe found, for example, in [35].\n2.1 Qualitative vs. quantitative data\nQualitative data can be divided into nominal data and\nordinal data. Nominal data only gives the name of a category\nto which something belongs like the name of a material\nfor the press hardening of a component [74]. Ordinal data\nindicate the order of something. For example, Neugebauer\net al. [69] divide the quality of gears, which are produced\nby forming, into classes depending on the pitch accuracy.\nQuantitative data can be interval data where there is no\nabsolute zero point such as the tool temperature in a press\nhardening process; and ratio data which can be used to give\ninformation about relative size, such as sheet thickness of a\npress hardened part at a certain point [11, 74].\n2.2 Time series vs. workpiece-related data\nMost commonly, a time series is a sequence or continuous\nsignal with equally spaced points in time like the energy\nconsumption of a machine tool over time (see for example\n[109]). Another possibility is data that is related to\na workpiece such as the workpiece temperature during\nthe heating of the press hardening process [74]. Such\nworkpiece-related data can, however, also be time series\ndata.\n2.3 Controllable vs. uncontrollable data\nAs described in Oh et al. [72], data can also be divided with\nregard to their controllability. Controllable parameters can\nbe adjusted either manually or automatically, while uncon-\ntrollable parameters may not be changed. An uncontrollable\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1890\n", []], "Time series vs. workpiece-related data": ["to 2018. Since earlier years, the authors refer to the\nextensive review of K\u00a8oksal et al. focusing on data min-\ning applications for quality improvement in manufactur-\ning industry [53]. Additionally, there exist more general\nreviews on machine learning in manufacturing that either\ndo not explicitly concentrate on optimization issues [10,\n37, 67, 92, 118] or focus on special methods and/or\napplications [15, 112].\nThe interest in the integration of machine learning\nand optimization algorithms in production processes has\nincreased steadily since 2009 and has been at a consistently\nhigh level since 2014. Thus, it remains a hot topic in\nlatest research, starting with the development of scientific\nmethods for sensor placement, going through data storage\nand processing architectures, and ending with machine\nlearning and optimization algorithms [118].\nSince the field of machine learning and optimization\nin production processes is very wide, the authors have\nidentified three closely related topics that will not be\ncovered extensively in this review. The first one is\noptimization with methods from the field of design of\nexperiments (DOE) and response surface methodology\n(RSM). Even if a DOE or RSM is used in applications,\nthe review will not focus on the specific designs. Here,\nthe authors like to refer the interested reader to the\ncomprehensive work of Montgomery [68], as a detailed\ndescription of methods and applications is beyond the\nscope of this review. The second topic is statistical process\ncontrol (SPC), pioneered by Shewhardt in 1925, which uses\nclassical statistical analysis of the collected data for process\nvariation reduction [93]. As the majority of publications\ndoes not fall back to the methods of \u201cmodern\u201d machine\nlearning, this field of research is excluded. A third topic\nto exclude is model predictive control (MPC) as a special\nfield of control engineering. Here, the authors would like\nto refer the interested reader for example to the work of\nMayne [64] and Scattolini [87]. In general, the application\nof machine learning methods for the optimization of\nproduction processes can take place with or without an\nimmediate quality feedback, depending on its\u2019 availability.\nWith a quality feedback, it is quite similar to closed\nloop control engineering, as it is used to adapt process\nparameters to improve the measured quality. But as neither\nthe quality feedback, the process parameters and the process\ndescription itself are in the typical format used for closed\nloop control (feedback and parameters as time series data\nand the process description as a state equation), nor is\nthere a frequent change of the parameters during a running\nproduction step, the authors will exclude this special field of\nresearch from the review.\nThe paper is organized as follows: firstly, the occurring\ndata types in manufacturing are reviewed. Secondly, an\noverview on applications of machine learning for quality\nimprovement without change of manufacturing parameters\nduring the process is given. Subsequently, applications\nwhere explicit changes of manufacturing parameters are\nallowed are reviewed in detail. After a detailed analysis\nconnecting data, machine learning, and optimization, a\nconclusion is drawn and open research questions are\ndiscussed.\n2 Data in machine learning in production\nThe first step to solving a machine learning problem is\nto identify the data that is available. There are different\ntypes of data which will affect the type of analyses that\ncan be used on them. Based on their types, the amount\nof information which data gives can vary considerably\n[11]. Data can be structured in the following ways. Topics\nsuch as data quality, missing data, or details about data\npreprocessing will not be addressed in this work, but may\nbe found, for example, in [35].\n2.1 Qualitative vs. quantitative data\nQualitative data can be divided into nominal data and\nordinal data. Nominal data only gives the name of a category\nto which something belongs like the name of a material\nfor the press hardening of a component [74]. Ordinal data\nindicate the order of something. For example, Neugebauer\net al. [69] divide the quality of gears, which are produced\nby forming, into classes depending on the pitch accuracy.\nQuantitative data can be interval data where there is no\nabsolute zero point such as the tool temperature in a press\nhardening process; and ratio data which can be used to give\ninformation about relative size, such as sheet thickness of a\npress hardened part at a certain point [11, 74].\n2.2 Time series vs. workpiece-related data\nMost commonly, a time series is a sequence or continuous\nsignal with equally spaced points in time like the energy\nconsumption of a machine tool over time (see for example\n[109]). Another possibility is data that is related to\na workpiece such as the workpiece temperature during\nthe heating of the press hardening process [74]. Such\nworkpiece-related data can, however, also be time series\ndata.\n2.3 Controllable vs. uncontrollable data\nAs described in Oh et al. [72], data can also be divided with\nregard to their controllability. Controllable parameters can\nbe adjusted either manually or automatically, while uncon-\ntrollable parameters may not be changed. An uncontrollable\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1890\n", []], "Qualitative vs. quantitative data": ["to 2018. Since earlier years, the authors refer to the\nextensive review of K\u00a8oksal et al. focusing on data min-\ning applications for quality improvement in manufactur-\ning industry [53]. Additionally, there exist more general\nreviews on machine learning in manufacturing that either\ndo not explicitly concentrate on optimization issues [10,\n37, 67, 92, 118] or focus on special methods and/or\napplications [15, 112].\nThe interest in the integration of machine learning\nand optimization algorithms in production processes has\nincreased steadily since 2009 and has been at a consistently\nhigh level since 2014. Thus, it remains a hot topic in\nlatest research, starting with the development of scientific\nmethods for sensor placement, going through data storage\nand processing architectures, and ending with machine\nlearning and optimization algorithms [118].\nSince the field of machine learning and optimization\nin production processes is very wide, the authors have\nidentified three closely related topics that will not be\ncovered extensively in this review. The first one is\noptimization with methods from the field of design of\nexperiments (DOE) and response surface methodology\n(RSM). Even if a DOE or RSM is used in applications,\nthe review will not focus on the specific designs. Here,\nthe authors like to refer the interested reader to the\ncomprehensive work of Montgomery [68], as a detailed\ndescription of methods and applications is beyond the\nscope of this review. The second topic is statistical process\ncontrol (SPC), pioneered by Shewhardt in 1925, which uses\nclassical statistical analysis of the collected data for process\nvariation reduction [93]. As the majority of publications\ndoes not fall back to the methods of \u201cmodern\u201d machine\nlearning, this field of research is excluded. A third topic\nto exclude is model predictive control (MPC) as a special\nfield of control engineering. Here, the authors would like\nto refer the interested reader for example to the work of\nMayne [64] and Scattolini [87]. In general, the application\nof machine learning methods for the optimization of\nproduction processes can take place with or without an\nimmediate quality feedback, depending on its\u2019 availability.\nWith a quality feedback, it is quite similar to closed\nloop control engineering, as it is used to adapt process\nparameters to improve the measured quality. But as neither\nthe quality feedback, the process parameters and the process\ndescription itself are in the typical format used for closed\nloop control (feedback and parameters as time series data\nand the process description as a state equation), nor is\nthere a frequent change of the parameters during a running\nproduction step, the authors will exclude this special field of\nresearch from the review.\nThe paper is organized as follows: firstly, the occurring\ndata types in manufacturing are reviewed. Secondly, an\noverview on applications of machine learning for quality\nimprovement without change of manufacturing parameters\nduring the process is given. Subsequently, applications\nwhere explicit changes of manufacturing parameters are\nallowed are reviewed in detail. After a detailed analysis\nconnecting data, machine learning, and optimization, a\nconclusion is drawn and open research questions are\ndiscussed.\n2 Data in machine learning in production\nThe first step to solving a machine learning problem is\nto identify the data that is available. There are different\ntypes of data which will affect the type of analyses that\ncan be used on them. Based on their types, the amount\nof information which data gives can vary considerably\n[11]. Data can be structured in the following ways. Topics\nsuch as data quality, missing data, or details about data\npreprocessing will not be addressed in this work, but may\nbe found, for example, in [35].\n2.1 Qualitative vs. quantitative data\nQualitative data can be divided into nominal data and\nordinal data. Nominal data only gives the name of a category\nto which something belongs like the name of a material\nfor the press hardening of a component [74]. Ordinal data\nindicate the order of something. For example, Neugebauer\net al. [69] divide the quality of gears, which are produced\nby forming, into classes depending on the pitch accuracy.\nQuantitative data can be interval data where there is no\nabsolute zero point such as the tool temperature in a press\nhardening process; and ratio data which can be used to give\ninformation about relative size, such as sheet thickness of a\npress hardened part at a certain point [11, 74].\n2.2 Time series vs. workpiece-related data\nMost commonly, a time series is a sequence or continuous\nsignal with equally spaced points in time like the energy\nconsumption of a machine tool over time (see for example\n[109]). Another possibility is data that is related to\na workpiece such as the workpiece temperature during\nthe heating of the press hardening process [74]. Such\nworkpiece-related data can, however, also be time series\ndata.\n2.3 Controllable vs. uncontrollable data\nAs described in Oh et al. [72], data can also be divided with\nregard to their controllability. Controllable parameters can\nbe adjusted either manually or automatically, while uncon-\ntrollable parameters may not be changed. An uncontrollable\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1890\n", []], "Data in machine learning in production": ["to 2018. Since earlier years, the authors refer to the\nextensive review of K\u00a8oksal et al. focusing on data min-\ning applications for quality improvement in manufactur-\ning industry [53]. Additionally, there exist more general\nreviews on machine learning in manufacturing that either\ndo not explicitly concentrate on optimization issues [10,\n37, 67, 92, 118] or focus on special methods and/or\napplications [15, 112].\nThe interest in the integration of machine learning\nand optimization algorithms in production processes has\nincreased steadily since 2009 and has been at a consistently\nhigh level since 2014. Thus, it remains a hot topic in\nlatest research, starting with the development of scientific\nmethods for sensor placement, going through data storage\nand processing architectures, and ending with machine\nlearning and optimization algorithms [118].\nSince the field of machine learning and optimization\nin production processes is very wide, the authors have\nidentified three closely related topics that will not be\ncovered extensively in this review. The first one is\noptimization with methods from the field of design of\nexperiments (DOE) and response surface methodology\n(RSM). Even if a DOE or RSM is used in applications,\nthe review will not focus on the specific designs. Here,\nthe authors like to refer the interested reader to the\ncomprehensive work of Montgomery [68], as a detailed\ndescription of methods and applications is beyond the\nscope of this review. The second topic is statistical process\ncontrol (SPC), pioneered by Shewhardt in 1925, which uses\nclassical statistical analysis of the collected data for process\nvariation reduction [93]. As the majority of publications\ndoes not fall back to the methods of \u201cmodern\u201d machine\nlearning, this field of research is excluded. A third topic\nto exclude is model predictive control (MPC) as a special\nfield of control engineering. Here, the authors would like\nto refer the interested reader for example to the work of\nMayne [64] and Scattolini [87]. In general, the application\nof machine learning methods for the optimization of\nproduction processes can take place with or without an\nimmediate quality feedback, depending on its\u2019 availability.\nWith a quality feedback, it is quite similar to closed\nloop control engineering, as it is used to adapt process\nparameters to improve the measured quality. But as neither\nthe quality feedback, the process parameters and the process\ndescription itself are in the typical format used for closed\nloop control (feedback and parameters as time series data\nand the process description as a state equation), nor is\nthere a frequent change of the parameters during a running\nproduction step, the authors will exclude this special field of\nresearch from the review.\nThe paper is organized as follows: firstly, the occurring\ndata types in manufacturing are reviewed. Secondly, an\noverview on applications of machine learning for quality\nimprovement without change of manufacturing parameters\nduring the process is given. Subsequently, applications\nwhere explicit changes of manufacturing parameters are\nallowed are reviewed in detail. After a detailed analysis\nconnecting data, machine learning, and optimization, a\nconclusion is drawn and open research questions are\ndiscussed.\n2 Data in machine learning in production\nThe first step to solving a machine learning problem is\nto identify the data that is available. There are different\ntypes of data which will affect the type of analyses that\ncan be used on them. Based on their types, the amount\nof information which data gives can vary considerably\n[11]. Data can be structured in the following ways. Topics\nsuch as data quality, missing data, or details about data\npreprocessing will not be addressed in this work, but may\nbe found, for example, in [35].\n2.1 Qualitative vs. quantitative data\nQualitative data can be divided into nominal data and\nordinal data. Nominal data only gives the name of a category\nto which something belongs like the name of a material\nfor the press hardening of a component [74]. Ordinal data\nindicate the order of something. For example, Neugebauer\net al. [69] divide the quality of gears, which are produced\nby forming, into classes depending on the pitch accuracy.\nQuantitative data can be interval data where there is no\nabsolute zero point such as the tool temperature in a press\nhardening process; and ratio data which can be used to give\ninformation about relative size, such as sheet thickness of a\npress hardened part at a certain point [11, 74].\n2.2 Time series vs. workpiece-related data\nMost commonly, a time series is a sequence or continuous\nsignal with equally spaced points in time like the energy\nconsumption of a machine tool over time (see for example\n[109]). Another possibility is data that is related to\na workpiece such as the workpiece temperature during\nthe heating of the press hardening process [74]. Such\nworkpiece-related data can, however, also be time series\ndata.\n2.3 Controllable vs. uncontrollable data\nAs described in Oh et al. [72], data can also be divided with\nregard to their controllability. Controllable parameters can\nbe adjusted either manually or automatically, while uncon-\ntrollable parameters may not be changed. An uncontrollable\nInt J Adv Manuf Technol (2019) 104:1889\u20131902\n1890\n", []], "Introduction": ["https://doi.org/10.1007/s00170-019-03988-5\nORIGINAL ARTICLE\nA review of machine learning for the optimization of production\nprocesses\nDorina Weichert1 \u00b7 Patrick Link2 \u00b7 Anke Stoll2 \u00b7 Stefan R\u00a8uping1 \u00b7 Ste\ufb00en Ihlenfeldt2 \u00b7 Stefan Wrobel1\nReceived: 14 March 2019 / Accepted: 5 June 2019\n\u00a9 Springer-Verlag London Ltd., part of Springer Nature 2019\nAbstract\nDue to the advances in the digitalization process of the manufacturing industry and the resulting available data, there is\ntremendous progress and large interest in integrating machine learning and optimization methods on the shop floor in order\nto improve production processes. Additionally, a shortage of resources leads to increasing acceptance of new approaches,\nsuch as machine learning to save energy, time, and resources, and avoid waste. After describing possible occurring data types\nin the manufacturing world, this study covers the majority of relevant literature from 2008 to 2018 dealing with machine\nlearning and optimization approaches for product quality or process improvement in the manufacturing industry. The review\nshows that there is hardly any correlation between the used data, the amount of data, the machine learning algorithms, the\nused optimizers, and the respective problem from the production. The detailed correlations between these criteria and the\nrecent progress made in this area as well as the issues that are still unsolved are discussed in this paper.\nKeywords Machine learning \u00b7 Optimization \u00b7 Manufacturing \u00b7 Production\n1 Introduction\nTogether with the rising popularity of machine learning\nresearch and the growth of the available data amounts, the\napplications of the developed methods have found their way\ninto various industrial fields. In this context especially, the\nexploitation of data for optimization in existing production\nlines is of high relevance [35, 53]. Optimization can take\nplace in two different ways: on the one hand, there is the\nimprovement of the product quality itself; on the other hand,\nthe production process can be changed for the better.\nThe utilization of machine learning is motivated by its\nadditional capabilities to spare resources, machining time,\nand energy and increase yield where traditional methods\nThese authors contributed equally to this work.\n\u0002 Dorina Weichert\ndorina.weichert@iais.fraunhofer.de\n\u0002 Patrick Link\npatrick.link@iwu.fraunhofer.de\n1\nFraunhofer IAIS, Institute for Intelligent Analysis\nand Information Systems, St. Augustin, Germany\n2\nFraunhofer IWU, Institute for Machine Tools and Forming\nTechnology, Chemnitz/Dresden, Germany\nsuch as six sigma strategies have reached their limits [53].\nIn the author\u2019s eyes, the term \u201cmachine learning\u201d describes\nalgorithms to identify and extract valuable patterns in the\ndata: from data transformation methods (e.g., PCA), over\ndata exploration methods (e.g., k-means clustering), and\ntraditional methods of supervised learning for regression\nand/or classification (e.g., decision trees) to more recent\nmethods (e.g., Convolutional Neural Networks). These\ncover a broad range of complexities, origins, and recency\nof the algorithms themselves, all having in common the\nextraction and use of specific features of the data useful to\nimproving quality.\nThough an important prerequisite for the application of\nmachine learning for production processes, industry 4.0,\nindustrial analytics and high-performance computing will\nnot be discussed in detail in this manuscript. The initiation\nof smart manufacturing systems in existing plants can be\nrealized by storing and processing of arising data by existing\nand additionally installed sensors. Due to the continuous\ndevelopment of new sensors, processing software, and\nstorages on low-price level as well as the small degree of\nnecessary interventions into a running process, the hurdles\nfor smart manufacturing are set low.\nThe aim of this study is to review machine learn-\ning applications to optimize products and production pro-\ncesses in existing production environments from 2008\nThe International Journal of Advanced Manufacturing Technology (2019) 104:1889\u20131902\n/Published online: 20 June 2019\n", []], "Abstract": ["https://doi.org/10.1007/s00170-019-03988-5\nORIGINAL ARTICLE\nA review of machine learning for the optimization of production\nprocesses\nDorina Weichert1 \u00b7 Patrick Link2 \u00b7 Anke Stoll2 \u00b7 Stefan R\u00a8uping1 \u00b7 Ste\ufb00en Ihlenfeldt2 \u00b7 Stefan Wrobel1\nReceived: 14 March 2019 / Accepted: 5 June 2019\n\u00a9 Springer-Verlag London Ltd., part of Springer Nature 2019\nAbstract\nDue to the advances in the digitalization process of the manufacturing industry and the resulting available data, there is\ntremendous progress and large interest in integrating machine learning and optimization methods on the shop floor in order\nto improve production processes. Additionally, a shortage of resources leads to increasing acceptance of new approaches,\nsuch as machine learning to save energy, time, and resources, and avoid waste. After describing possible occurring data types\nin the manufacturing world, this study covers the majority of relevant literature from 2008 to 2018 dealing with machine\nlearning and optimization approaches for product quality or process improvement in the manufacturing industry. The review\nshows that there is hardly any correlation between the used data, the amount of data, the machine learning algorithms, the\nused optimizers, and the respective problem from the production. The detailed correlations between these criteria and the\nrecent progress made in this area as well as the issues that are still unsolved are discussed in this paper.\nKeywords Machine learning \u00b7 Optimization \u00b7 Manufacturing \u00b7 Production\n1 Introduction\nTogether with the rising popularity of machine learning\nresearch and the growth of the available data amounts, the\napplications of the developed methods have found their way\ninto various industrial fields. In this context especially, the\nexploitation of data for optimization in existing production\nlines is of high relevance [35, 53]. Optimization can take\nplace in two different ways: on the one hand, there is the\nimprovement of the product quality itself; on the other hand,\nthe production process can be changed for the better.\nThe utilization of machine learning is motivated by its\nadditional capabilities to spare resources, machining time,\nand energy and increase yield where traditional methods\nThese authors contributed equally to this work.\n\u0002 Dorina Weichert\ndorina.weichert@iais.fraunhofer.de\n\u0002 Patrick Link\npatrick.link@iwu.fraunhofer.de\n1\nFraunhofer IAIS, Institute for Intelligent Analysis\nand Information Systems, St. Augustin, Germany\n2\nFraunhofer IWU, Institute for Machine Tools and Forming\nTechnology, Chemnitz/Dresden, Germany\nsuch as six sigma strategies have reached their limits [53].\nIn the author\u2019s eyes, the term \u201cmachine learning\u201d describes\nalgorithms to identify and extract valuable patterns in the\ndata: from data transformation methods (e.g., PCA), over\ndata exploration methods (e.g., k-means clustering), and\ntraditional methods of supervised learning for regression\nand/or classification (e.g., decision trees) to more recent\nmethods (e.g., Convolutional Neural Networks). These\ncover a broad range of complexities, origins, and recency\nof the algorithms themselves, all having in common the\nextraction and use of specific features of the data useful to\nimproving quality.\nThough an important prerequisite for the application of\nmachine learning for production processes, industry 4.0,\nindustrial analytics and high-performance computing will\nnot be discussed in detail in this manuscript. The initiation\nof smart manufacturing systems in existing plants can be\nrealized by storing and processing of arising data by existing\nand additionally installed sensors. Due to the continuous\ndevelopment of new sensors, processing software, and\nstorages on low-price level as well as the small degree of\nnecessary interventions into a running process, the hurdles\nfor smart manufacturing are set low.\nThe aim of this study is to review machine learn-\ning applications to optimize products and production pro-\ncesses in existing production environments from 2008\nThe International Journal of Advanced Manufacturing Technology (2019) 104:1889\u20131902\n/Published online: 20 June 2019\n", []], "A review of machine learning for the optimization of production processes": ["https://doi.org/10.1007/s00170-019-03988-5\nORIGINAL ARTICLE\nA review of machine learning for the optimization of production\nprocesses\nDorina Weichert1 \u00b7 Patrick Link2 \u00b7 Anke Stoll2 \u00b7 Stefan R\u00a8uping1 \u00b7 Ste\ufb00en Ihlenfeldt2 \u00b7 Stefan Wrobel1\nReceived: 14 March 2019 / Accepted: 5 June 2019\n\u00a9 Springer-Verlag London Ltd., part of Springer Nature 2019\nAbstract\nDue to the advances in the digitalization process of the manufacturing industry and the resulting available data, there is\ntremendous progress and large interest in integrating machine learning and optimization methods on the shop floor in order\nto improve production processes. Additionally, a shortage of resources leads to increasing acceptance of new approaches,\nsuch as machine learning to save energy, time, and resources, and avoid waste. After describing possible occurring data types\nin the manufacturing world, this study covers the majority of relevant literature from 2008 to 2018 dealing with machine\nlearning and optimization approaches for product quality or process improvement in the manufacturing industry. The review\nshows that there is hardly any correlation between the used data, the amount of data, the machine learning algorithms, the\nused optimizers, and the respective problem from the production. The detailed correlations between these criteria and the\nrecent progress made in this area as well as the issues that are still unsolved are discussed in this paper.\nKeywords Machine learning \u00b7 Optimization \u00b7 Manufacturing \u00b7 Production\n1 Introduction\nTogether with the rising popularity of machine learning\nresearch and the growth of the available data amounts, the\napplications of the developed methods have found their way\ninto various industrial fields. In this context especially, the\nexploitation of data for optimization in existing production\nlines is of high relevance [35, 53]. Optimization can take\nplace in two different ways: on the one hand, there is the\nimprovement of the product quality itself; on the other hand,\nthe production process can be changed for the better.\nThe utilization of machine learning is motivated by its\nadditional capabilities to spare resources, machining time,\nand energy and increase yield where traditional methods\nThese authors contributed equally to this work.\n\u0002 Dorina Weichert\ndorina.weichert@iais.fraunhofer.de\n\u0002 Patrick Link\npatrick.link@iwu.fraunhofer.de\n1\nFraunhofer IAIS, Institute for Intelligent Analysis\nand Information Systems, St. Augustin, Germany\n2\nFraunhofer IWU, Institute for Machine Tools and Forming\nTechnology, Chemnitz/Dresden, Germany\nsuch as six sigma strategies have reached their limits [53].\nIn the author\u2019s eyes, the term \u201cmachine learning\u201d describes\nalgorithms to identify and extract valuable patterns in the\ndata: from data transformation methods (e.g., PCA), over\ndata exploration methods (e.g., k-means clustering), and\ntraditional methods of supervised learning for regression\nand/or classification (e.g., decision trees) to more recent\nmethods (e.g., Convolutional Neural Networks). These\ncover a broad range of complexities, origins, and recency\nof the algorithms themselves, all having in common the\nextraction and use of specific features of the data useful to\nimproving quality.\nThough an important prerequisite for the application of\nmachine learning for production processes, industry 4.0,\nindustrial analytics and high-performance computing will\nnot be discussed in detail in this manuscript. The initiation\nof smart manufacturing systems in existing plants can be\nrealized by storing and processing of arising data by existing\nand additionally installed sensors. Due to the continuous\ndevelopment of new sensors, processing software, and\nstorages on low-price level as well as the small degree of\nnecessary interventions into a running process, the hurdles\nfor smart manufacturing are set low.\nThe aim of this study is to review machine learn-\ning applications to optimize products and production pro-\ncesses in existing production environments from 2008\nThe International Journal of Advanced Manufacturing Technology (2019) 104:1889\u20131902\n/Published online: 20 June 2019\n", []]}