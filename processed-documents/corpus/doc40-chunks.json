{"References": ["algorithm and its hybrid versions to the training of feed-\nforward neural networks for pattern classi\ufb01cation. The\nperformance of the algorithms was evaluated on real-world\ntest problems and compared to specialized algorithms for\nfeed-forward neural network training (namely Backpropa-\ngation and the Levenberg\u2013Marquardt algorithm). In addi-\ntion we compared our algorithms to another general\noptimizer, namely a genetic algorithm. The performance of\nthe stand-alone ACOR was generally worse (with statistical\nsigni\ufb01cane) than the performance of specialized algorithms\nfor neural network training. However, the hybrid between\nACOR\nand the Levenberg-Marquardt algorithm \u00f0i.e.;\nACOR-LM\u00de was especially on the large problem instance\nable to outperform the backpropagation and the Levenberg-\nMarquardt algorithms that are traditionally used for neural\nnetwork training. Finally, when compared to another gen-\neral-purpose algorithm, namely a genetic algorithm from\nthe literature, the ant colony optimization based algorithms\nhave in general advantages. Further research is needed to\nsee how our algorithms perform on more complex prob-\nlems, but the initial results are promising.\nThe current version of ACOR is still a basic ACO var-\niant. In the future, we plan to focus on adding mechanisms\nto ACOR that allow a more ef\ufb01cient exploration of the\nsearch space in order to improve the global optimization\ncapabilities of this algorithm. This will hopefully allow us\nto create an algorithm that achieves results that are at least\ncomparable to the results of state-of-the-art algorithms for\ntraining neural networks.\nAcknowledgments\nThis work was supported by the Spanish CI-\nCYT project OPLINK (grant TIN-2005-08818-C04), and by the\nRamo\u00b4n y Cajal program of the Spanish Ministry of Science and\nTechnology of which Christian Blum is a research fellow. This work\nwas also partially supported by the ANTS project, an Action de\nRecherche Concerte\u00b4e funded by the Scienti\ufb01c Research Directorate of\nthe French Community of Belgium.\nReferences\n1. Alba E, Chicano JF (2004) Training neural networks with GA\nhybrid algorithms. In: Deb K et al. (ed) Proceedings of the ge-\nnetic and evolutionary computation conference\u2014GECCO 2004,\nvolume 3102 of Lecture Notes in Computer Science. Springer,\nBerlin, pp 852\u2013863\n2. Alba E, Marti R (eds) (2006) Metaheuristic procedures for\ntraining neural networks. Springer, Berlin\n3. Bilchev B, Parmee IC (1995) The ant colony metaphor for\nsearching continuous design spaces. In: Proceedings of the AISB\nworkshop on evolutionary computation, volume 993 of Lecture\nNotes in Computer Science, pp 25\u201339\n4. Birattari M (2005) The problem of tuning metaheuristics as seen\nfrom a machine learning perspective. PhD thesis, volume 292\nof Dissertationen zur Ku\u00a8nstlichen Intelligenz. Akademische\nVerlagsgesellschaft Aka GmbH, Berlin, Germany\n5. Birattari M, Stu\u00a8tzle T, Paquete L, Varrentrapp K (2002) A racing\nalgorithm for con\ufb01guring metaheuristics. In: Langdon WB et al.\n(eds) Proceedings of the genetic and evolutionary computation\nconference. Morgan Kaufman, San Francisco, pp 11\u201318\n6. Bishop CM (2005) Neural networks for pattern recognition. MIT\nPress, Cambridge\n7. Blum C, Socha K (2005) Training feed-forward neural networks\nwith ant colony optimization: An application to pattern classi\ufb01-\ncation. In: Nedjah N, Mourelle LM, Vellasco MMBR, Abraham\nA, Ko\u00a8ppen M (eds) Proceedings of the Fifth International Con-\nference on Hybrid Intelligent Systems (HIS). IEEE Computer\nSociety, pp 233\u2013238\n8. Bonabeau E, Dorigo M, Theraulaz G (1999) Swarm Intelligence:\nFrom Natural to Arti\ufb01cial Systems. Oxford University Press, New\nYork\n9. Peter AN (2000) Bosman and Dirk Thierens. Continuous iterated\ndensity estimation evolutionary algorithms within the IDEA\nframework. In: Pelikan M, Mu\u00a8hlenbein H, Rodriguez AO (eds)\nProceedings of OBUPM Workshop at GECCO-2000. Morgan-\nKaufmann Publishers, San Francisco, pp 197\u2013200\n10. Box GEP, Muller ME (1958) A note on the generation of random\nnormal deviates. Ann Math Stat 29(2):610\u2013611\n11. Cotta C, Alba E, Sagarna R, Larran\u02dcaga P (2001) Adjusting\nweights in arti\ufb01cial neural networks using evolutionary algo-\nrithms. In: Larran\u02dcaga P, Lozano JA (eds) Estimation of distri-\nbution algorithms: a new tool for evolutionary computation.\nKluwer Academic Publishers, Boston, pp 361\u2013378\n12. Deneubourg J-L, Aron S, Goss S, Pasteels J-M (1990) The self-\norganizing exploratory pattern of the argentine ant. J Insect\nBehav 3:159\u2013168\n13. Dorigo M (1992) Optimization, Learning and Natural Algorithms\n(in Italian). PhD thesis, Dipartimento di Elettronica, Politecnico\ndi Milano, Italy\n14. Dorigo M, Maniezzo V, Colorni A (1996) Ant System: Optimi-\nzation by a colony of cooperating agents. IEEE Trans Syst Man\nCybernetics \u2013 Part B 26(1):29\u201341\n15. Dorigo M, Stu\u00a8tzle T (2004) Ant Colony Optimization. MIT Press,\nCambridge\n16. Dre\u00b4o J, Siarry P (2002) A new ant colony algorithm using the\nheterarchical concept aimed at optimization of multiminima\ncontinuous functions. In: Dorigo M, Di Caro G, Sampels M (eds)\nProceedings of ANTS 2002 \u2013 from ant colonies to arti\ufb01cial ants:\nthird international workshop on ant algorithms, vol 2463 of\nlecture notes in computer science, Springer, Berlin, pp 216\u2013221\nTable 6 Pair-wise comparison of the results of the ACOR based hybrid algorithms with recent results obtained by two GA-based hybrid\nalgorithms (see [1])\nGA-BP\nACOR-BP\nGA-LM\nACOR-LM\nCancer1\n1.43 (4.87)\n2.14 (1.09)\n0.02 (0.11)\n2.08 (0.68)\nDiabetes1\n36.36 (0.00)\n23.80 (1.73)\n28.29 (1.15)\n24.26 (1.40)\nHeart1\n54.30 (20.03)\n18.29 (1.00)\n22.66 (0.82)\n16.53 (1.37)\nFor each problem-algorithm pair we give the mean of the CEPs (obtained in 50 independent runs), and their standard deviation (in brackets). The\nbest result of each comparison is indicated in bold\n246\nNeural Comput & Applic (2007) 16:235\u2013247\n123\n", []], "Acknowledgments": ["algorithm and its hybrid versions to the training of feed-\nforward neural networks for pattern classi\ufb01cation. The\nperformance of the algorithms was evaluated on real-world\ntest problems and compared to specialized algorithms for\nfeed-forward neural network training (namely Backpropa-\ngation and the Levenberg\u2013Marquardt algorithm). In addi-\ntion we compared our algorithms to another general\noptimizer, namely a genetic algorithm. The performance of\nthe stand-alone ACOR was generally worse (with statistical\nsigni\ufb01cane) than the performance of specialized algorithms\nfor neural network training. However, the hybrid between\nACOR\nand the Levenberg-Marquardt algorithm \u00f0i.e.;\nACOR-LM\u00de was especially on the large problem instance\nable to outperform the backpropagation and the Levenberg-\nMarquardt algorithms that are traditionally used for neural\nnetwork training. Finally, when compared to another gen-\neral-purpose algorithm, namely a genetic algorithm from\nthe literature, the ant colony optimization based algorithms\nhave in general advantages. Further research is needed to\nsee how our algorithms perform on more complex prob-\nlems, but the initial results are promising.\nThe current version of ACOR is still a basic ACO var-\niant. In the future, we plan to focus on adding mechanisms\nto ACOR that allow a more ef\ufb01cient exploration of the\nsearch space in order to improve the global optimization\ncapabilities of this algorithm. This will hopefully allow us\nto create an algorithm that achieves results that are at least\ncomparable to the results of state-of-the-art algorithms for\ntraining neural networks.\nAcknowledgments\nThis work was supported by the Spanish CI-\nCYT project OPLINK (grant TIN-2005-08818-C04), and by the\nRamo\u00b4n y Cajal program of the Spanish Ministry of Science and\nTechnology of which Christian Blum is a research fellow. This work\nwas also partially supported by the ANTS project, an Action de\nRecherche Concerte\u00b4e funded by the Scienti\ufb01c Research Directorate of\nthe French Community of Belgium.\nReferences\n1. Alba E, Chicano JF (2004) Training neural networks with GA\nhybrid algorithms. In: Deb K et al. (ed) Proceedings of the ge-\nnetic and evolutionary computation conference\u2014GECCO 2004,\nvolume 3102 of Lecture Notes in Computer Science. Springer,\nBerlin, pp 852\u2013863\n2. Alba E, Marti R (eds) (2006) Metaheuristic procedures for\ntraining neural networks. Springer, Berlin\n3. Bilchev B, Parmee IC (1995) The ant colony metaphor for\nsearching continuous design spaces. In: Proceedings of the AISB\nworkshop on evolutionary computation, volume 993 of Lecture\nNotes in Computer Science, pp 25\u201339\n4. Birattari M (2005) The problem of tuning metaheuristics as seen\nfrom a machine learning perspective. PhD thesis, volume 292\nof Dissertationen zur Ku\u00a8nstlichen Intelligenz. Akademische\nVerlagsgesellschaft Aka GmbH, Berlin, Germany\n5. Birattari M, Stu\u00a8tzle T, Paquete L, Varrentrapp K (2002) A racing\nalgorithm for con\ufb01guring metaheuristics. In: Langdon WB et al.\n(eds) Proceedings of the genetic and evolutionary computation\nconference. Morgan Kaufman, San Francisco, pp 11\u201318\n6. Bishop CM (2005) Neural networks for pattern recognition. MIT\nPress, Cambridge\n7. Blum C, Socha K (2005) Training feed-forward neural networks\nwith ant colony optimization: An application to pattern classi\ufb01-\ncation. In: Nedjah N, Mourelle LM, Vellasco MMBR, Abraham\nA, Ko\u00a8ppen M (eds) Proceedings of the Fifth International Con-\nference on Hybrid Intelligent Systems (HIS). IEEE Computer\nSociety, pp 233\u2013238\n8. Bonabeau E, Dorigo M, Theraulaz G (1999) Swarm Intelligence:\nFrom Natural to Arti\ufb01cial Systems. Oxford University Press, New\nYork\n9. Peter AN (2000) Bosman and Dirk Thierens. Continuous iterated\ndensity estimation evolutionary algorithms within the IDEA\nframework. In: Pelikan M, Mu\u00a8hlenbein H, Rodriguez AO (eds)\nProceedings of OBUPM Workshop at GECCO-2000. Morgan-\nKaufmann Publishers, San Francisco, pp 197\u2013200\n10. Box GEP, Muller ME (1958) A note on the generation of random\nnormal deviates. Ann Math Stat 29(2):610\u2013611\n11. Cotta C, Alba E, Sagarna R, Larran\u02dcaga P (2001) Adjusting\nweights in arti\ufb01cial neural networks using evolutionary algo-\nrithms. In: Larran\u02dcaga P, Lozano JA (eds) Estimation of distri-\nbution algorithms: a new tool for evolutionary computation.\nKluwer Academic Publishers, Boston, pp 361\u2013378\n12. Deneubourg J-L, Aron S, Goss S, Pasteels J-M (1990) The self-\norganizing exploratory pattern of the argentine ant. J Insect\nBehav 3:159\u2013168\n13. Dorigo M (1992) Optimization, Learning and Natural Algorithms\n(in Italian). PhD thesis, Dipartimento di Elettronica, Politecnico\ndi Milano, Italy\n14. Dorigo M, Maniezzo V, Colorni A (1996) Ant System: Optimi-\nzation by a colony of cooperating agents. IEEE Trans Syst Man\nCybernetics \u2013 Part B 26(1):29\u201341\n15. Dorigo M, Stu\u00a8tzle T (2004) Ant Colony Optimization. MIT Press,\nCambridge\n16. Dre\u00b4o J, Siarry P (2002) A new ant colony algorithm using the\nheterarchical concept aimed at optimization of multiminima\ncontinuous functions. In: Dorigo M, Di Caro G, Sampels M (eds)\nProceedings of ANTS 2002 \u2013 from ant colonies to arti\ufb01cial ants:\nthird international workshop on ant algorithms, vol 2463 of\nlecture notes in computer science, Springer, Berlin, pp 216\u2013221\nTable 6 Pair-wise comparison of the results of the ACOR based hybrid algorithms with recent results obtained by two GA-based hybrid\nalgorithms (see [1])\nGA-BP\nACOR-BP\nGA-LM\nACOR-LM\nCancer1\n1.43 (4.87)\n2.14 (1.09)\n0.02 (0.11)\n2.08 (0.68)\nDiabetes1\n36.36 (0.00)\n23.80 (1.73)\n28.29 (1.15)\n24.26 (1.40)\nHeart1\n54.30 (20.03)\n18.29 (1.00)\n22.66 (0.82)\n16.53 (1.37)\nFor each problem-algorithm pair we give the mean of the CEPs (obtained in 50 independent runs), and their standard deviation (in brackets). The\nbest result of each comparison is indicated in bold\n246\nNeural Comput & Applic (2007) 16:235\u2013247\n123\n", []], "Conclusions": ["outputs. Second, the fact that the Heart1 problem is bigger\nthan the other test problems might increase the probability\nthat the gradient-based algorithms get stuck in local optima\nof the search landscape. Third, it is known from the no free\nlunch theory (see [37]) that it is not possible to create an\nalgorithm that is best on all possible problem instances.\nVery interesting is the performance of the hybrid versions\nof\nACOR;\nnamely\nACOR-BP\nand\nACOR-LM:\nThe\nACOR-BP hybrid outperforms both ACOR and BP with\nstatistical signi\ufb01cane. ACOR-LM outperforms respectively\nACOR and LM with statistical signi\ufb01cance.\nSummarizing, we note that the performance of ACOR\nalone does often not quite reach the performance of the\nderivative based algorithms and the ACOR hybrids. Fur-\nthermore, the results show that hybridizing ACOR with BP\nor LM generally helps to improve the results of the pure\nACOR algorithm. This was especially the case for Heart1,\nwhere ACOR-LM was the overall winner. There also seems\nto be a promising tendency in the results: The bigger the\nproblem instance, the better was the performance of\nACOR-LM in comparison to the other algorithms.\nFinally, we studied if (and to what extend) the\nalgorithms suffer from over\ufb01tting. Table 4 shows for all\nalgorithms the CEP values averaged over all runs and all\ncross-validation experiments. In general, ACOR; BP, and\nRS do not suffer from strong over\ufb01tting, while ACOR-BP\nsuffers from moderate over\ufb01tting on all three test problems.\nThe strongest over\ufb01tting effects can be seen in the results\nof LM and ACOR-LM when applied to problem instances\nCancer1 and Heart1. This suggests that a different divi-\nsion of the data set into a training set and a test set might be\nnecessary in this case.\n3.7 Comparison to a basic GA\nAppart from the comparison to specialized algorithms for\nNN training, it is also interesting to compare the perfor-\nmance of the ACOR based algorithms to another general\noptimizer. The GA-based algorithms from [1] were applied\nto the same three problem instances used in our study.\nAppart from a stand-alone GA, the authors of [1] also\ntested hybrid versions, namely GA-BP and GA-LM.\nMoreover, the GA-based algorithms were applied with the\nsame stopping criterion (that is, 1,000 function evalua-\ntions), and the chosen training/test set division was the\nsame.\nTables 5 and 6 summarize the results obtained by the\nACOR and GA based algorithms.7 Clearly the stand-alone\nACOR performs better than the stand-alone GA for all the\ntest instances. ACOR-BP and ACOR-LM perform respec-\ntively better than GA-BP and GA-LM when applied to the\ntwo more dif\ufb01cult problem instances Diabetes1 and\nHeart1 and worse on Cancer1. For the Heart1 problem\ninstance, the mean performance of any ACOR based\nalgorithm is signi\ufb01cantly better than the best GA based\nalgorithm (which was reported as the state-of-the-art for\nthis problem in 2004).\n4 Conclusions\nWe have presented an ant colony optimization algorithm\n\u00f0i.e.; ACOR\u00de for continuous optimization and applied this\nTable 4 Classi\ufb01cation error percentage (CEP) values averaged for each algorithm over all runs for all cross-validation experiments\nCancer1\nDiabetes1\nHeart1\nTraining\nTest\nTraining\nTest\nTraining\nTest\nACOR\n3.05\n4.02\n23.09\n24.48\n17.58\n20.67\nACOR-BP\n1.90\n3.45\n19.62\n23.96\n10.97\n18\nACOR-LM\n1.14\n4.02\n21.01\n22.92\n3.55\n16.51\nBP\n2.67\n2.87\n21.18\n22.40\n15.65\n18.67\nLM\n1.71\n4.60\n21.01\n23.96\n4.03\n17.62\nRS\n4.19\n4.31\n28.30\n29.69\n26.52\n27.64\nThe results obtained on the training set in comparison to the results obtained on the test set give information on the over\ufb01tting of the algorithms\nTable 5 Pair-wise comparison of the results of ACOR with recent\nresults obtained by a genetic algorithm (see [1])\nGA\nACOR\nCancer1\n16.76 (6.15)\n2.39 (1.15)\nDiabetes1\n36.46 (0.00)\n25.82 (2.59)\nHeart1\n41.50 (14.68)\n21.59 (1.14)\nFor each problem-algorithm pair we give the mean of the CEPs\n(obtained in 50 independent runs), and their standard deviation (in\nbrackets). The best result of each comparison is indicated in bold\n7 Note that Alba and Chicano did not perform a fourfold cross-vali-\ndation. They only performed the \ufb01rst one of our four cross-validation\nexperiments. Therefore, the results of our ACO algorithms in these\ntables refer to the results of the \ufb01rst of our four cross-validation\nexperiments.\nNeural Comput & Applic (2007) 16:235\u2013247\n245\n123\n", []], "Comparison to a basic GA": ["outputs. Second, the fact that the Heart1 problem is bigger\nthan the other test problems might increase the probability\nthat the gradient-based algorithms get stuck in local optima\nof the search landscape. Third, it is known from the no free\nlunch theory (see [37]) that it is not possible to create an\nalgorithm that is best on all possible problem instances.\nVery interesting is the performance of the hybrid versions\nof\nACOR;\nnamely\nACOR-BP\nand\nACOR-LM:\nThe\nACOR-BP hybrid outperforms both ACOR and BP with\nstatistical signi\ufb01cane. ACOR-LM outperforms respectively\nACOR and LM with statistical signi\ufb01cance.\nSummarizing, we note that the performance of ACOR\nalone does often not quite reach the performance of the\nderivative based algorithms and the ACOR hybrids. Fur-\nthermore, the results show that hybridizing ACOR with BP\nor LM generally helps to improve the results of the pure\nACOR algorithm. This was especially the case for Heart1,\nwhere ACOR-LM was the overall winner. There also seems\nto be a promising tendency in the results: The bigger the\nproblem instance, the better was the performance of\nACOR-LM in comparison to the other algorithms.\nFinally, we studied if (and to what extend) the\nalgorithms suffer from over\ufb01tting. Table 4 shows for all\nalgorithms the CEP values averaged over all runs and all\ncross-validation experiments. In general, ACOR; BP, and\nRS do not suffer from strong over\ufb01tting, while ACOR-BP\nsuffers from moderate over\ufb01tting on all three test problems.\nThe strongest over\ufb01tting effects can be seen in the results\nof LM and ACOR-LM when applied to problem instances\nCancer1 and Heart1. This suggests that a different divi-\nsion of the data set into a training set and a test set might be\nnecessary in this case.\n3.7 Comparison to a basic GA\nAppart from the comparison to specialized algorithms for\nNN training, it is also interesting to compare the perfor-\nmance of the ACOR based algorithms to another general\noptimizer. The GA-based algorithms from [1] were applied\nto the same three problem instances used in our study.\nAppart from a stand-alone GA, the authors of [1] also\ntested hybrid versions, namely GA-BP and GA-LM.\nMoreover, the GA-based algorithms were applied with the\nsame stopping criterion (that is, 1,000 function evalua-\ntions), and the chosen training/test set division was the\nsame.\nTables 5 and 6 summarize the results obtained by the\nACOR and GA based algorithms.7 Clearly the stand-alone\nACOR performs better than the stand-alone GA for all the\ntest instances. ACOR-BP and ACOR-LM perform respec-\ntively better than GA-BP and GA-LM when applied to the\ntwo more dif\ufb01cult problem instances Diabetes1 and\nHeart1 and worse on Cancer1. For the Heart1 problem\ninstance, the mean performance of any ACOR based\nalgorithm is signi\ufb01cantly better than the best GA based\nalgorithm (which was reported as the state-of-the-art for\nthis problem in 2004).\n4 Conclusions\nWe have presented an ant colony optimization algorithm\n\u00f0i.e.; ACOR\u00de for continuous optimization and applied this\nTable 4 Classi\ufb01cation error percentage (CEP) values averaged for each algorithm over all runs for all cross-validation experiments\nCancer1\nDiabetes1\nHeart1\nTraining\nTest\nTraining\nTest\nTraining\nTest\nACOR\n3.05\n4.02\n23.09\n24.48\n17.58\n20.67\nACOR-BP\n1.90\n3.45\n19.62\n23.96\n10.97\n18\nACOR-LM\n1.14\n4.02\n21.01\n22.92\n3.55\n16.51\nBP\n2.67\n2.87\n21.18\n22.40\n15.65\n18.67\nLM\n1.71\n4.60\n21.01\n23.96\n4.03\n17.62\nRS\n4.19\n4.31\n28.30\n29.69\n26.52\n27.64\nThe results obtained on the training set in comparison to the results obtained on the test set give information on the over\ufb01tting of the algorithms\nTable 5 Pair-wise comparison of the results of ACOR with recent\nresults obtained by a genetic algorithm (see [1])\nGA\nACOR\nCancer1\n16.76 (6.15)\n2.39 (1.15)\nDiabetes1\n36.46 (0.00)\n25.82 (2.59)\nHeart1\n41.50 (14.68)\n21.59 (1.14)\nFor each problem-algorithm pair we give the mean of the CEPs\n(obtained in 50 independent runs), and their standard deviation (in\nbrackets). The best result of each comparison is indicated in bold\n7 Note that Alba and Chicano did not perform a fourfold cross-vali-\ndation. They only performed the \ufb01rst one of our four cross-validation\nexperiments. Therefore, the results of our ACO algorithms in these\ntables refer to the results of the \ufb01rst of our four cross-validation\nexperiments.\nNeural Comput & Applic (2007) 16:235\u2013247\n245\n123\n", []], "Results": ["performed best.6 The \ufb01nal parameter value settings that we\nused for our \ufb01nal experiments are summarized in Table 2.\nAs a last remark, note that the inclusion of parameter n\n(controlling the convergence speed of ACOR) in the\nparameter tuning ensures that the ACOR algorithms con-\nverge within the given limit of 1,000 solution evaluations.\n3.6 Results\nEach\ncross-validation\nexperiment\nwas\nperformed\nby\napplying each algorithm 50 times to each of the three test\nproblems. Figures 6, 7, and 8 present respectively the\nresults of the fourfold cross-validation obtained for the\ncancer, diabetes, and heart test problems in the form of\nbox-plots. The boxes are drawn between the \ufb01rst and the\nthird quartile of the distribution, while the indentations in\nthe box-plots (or notches) indicate the 95% con\ufb01dence\ninterval for a given distribution [25]. Each \ufb01gure contains\ntwo plots. The left plot shows the distributions of the\nTable 2 Summary of the \ufb01nal parameter values that we chose for our algorithms\nAlg.\nCancer1\nDiabetes1\nHeart1\nk\nn\ng\nb\nk\nn\ng\nb\nk\nn\ng\nb\nACOR\n148\n0.95\n\u2013\n\u2013\n136\n0.8\n\u2013\n\u2013\n230\n0.6\n\u2013\n\u2013\nACOR-BP\n148\n0.98\n0.3\n\u2013\n136\n0.7\n0.1\n\u2013\n230\n0.98\n0.4\n\u2013\nACOR-LM\n148\n0.9\n\u2013\n10\n136\n0.1\n\u2013\n10\n230\n0.1\n\u2013\n10\nBP\n\u2013\n\u2013\n0.002\n\u2013\n\u2013\n\u2013\n0.01\n\u2013\n\u2013\n\u2013\n0.001\n\u2013\nLM\n\u2013\n\u2013\n\u2013\n50\n\u2013\n\u2013\n\u2013\n5\n\u2013\n\u2013\n\u2013\n1.5\nNot included in the table are the parameters common to all ACOR versions, namely q (see Eq. 5) and m (the number of ants per iteration). For\nthese parameters we used the settings q = 0.01, and m = 2. Note that g is the step-size parameter of BP, and b is the adaptation-step parameter of\nLM; and remember that k is the archive size of ACOR; while n is the parameter that controls the convergence speed of ACOR\naco\nacobp\nacolm\nbp\nlm\nrs\n0\n10\n20\n30\nCancer (CEP)\nrs\nlm\nbp\nacolm\nacobp\naco\n0\n200\n400\n600\n800\n1000\n1200\nCancer (ranks)\nFig. 6 Box-plots for Cancer1.\nThe boxes are drawn between\nthe \ufb01rst and the third quartile of\nthe distribution, while the\nindentations in the box-plots (or\nnotches) indicate the 95%\ncon\ufb01dence interval\naco\nacobp\nacolm\nbp\nlm\nrs\n20\n25\n30\n35\n40\nDiabetes (CEP)\nrs\nlm\nbp\nacolm\nacobp\naco\n0\n200\n400\n600\n800\n1000\n1200\nDiabetes (ranks)\nFig. 7 Box-plots for\nDiabetes1. The boxes are\ndrawn between the \ufb01rst and the\nthird quartile of the distribution,\nwhile the indentations in the\nbox-plots (or notches) indicate\nthe 95% con\ufb01dence interval\n6 Due to the limited resources for tuning, the chosen con\ufb01guration for\neach race is not necessarily signi\ufb01cantly better than all the others. The\nlimit of 100 experiments per race did sometimes not allow reaching\nthat level of assurance. However, the chosen con\ufb01guration was de\ufb01-\nnitely not signi\ufb01cantly worse than any of the others.\nNeural Comput & Applic (2007) 16:235\u2013247\n243\n123\n", []], "Parameter tuning": ["need. However, the resulting computation times are in the\nsame order of magnitude.\nFor evaluating the algorithms, we performend a so-\ncalled k-fold cross-validation. Hereby, the set of pattern is\ndivided into k subsets. Then, k experiments are performed\nin which one of the k subsets is used as the test set and the\nremaining k\u20131 subsets are joined to form the training set.\nThen the average CEP value across all k experiments is\ncomputed. The aim of k-fold cross-validation is to average\nout the effects of the training/test set division. The disad-\nvantage of this method is that the training algorithm has to\nbe re-run from scratch k times, which uses quite a lot of\ncomputation time. In this work we perform a fourfold\ncross-validation.\n3.4 Problem instances\nDue to their practical importance, we chose to evaluate the\nperformance of ACOR on classi\ufb01cation problems arising in\nthe medical \ufb01eld. More speci\ufb01cally, we chose three prob-\nlems from the well-known PROBEN1 benchmark set [29],\nnamely Cancer1, Diabetes1, and Heart1. Each of these\nproblems consists of a number of patterns together with\ntheir correct classi\ufb01cation, that is, Cancer1 consists of 699\npatterns from a breast cancer database, Diabetes1 consists\nof 768 patterns concerning diabetes patients, and Heart1 is\nthe biggest of the three data sets, consisting of 920 patterns\ndescribing a heart condition. Each pattern of the three\nproblems is either classi\ufb01ed as pathological, or as normal.\nFurthermore, each pattern consists of a number of mea-\nsurements (i.e., numerical values): 9 measurements in the\ncase of Cancer1, 8 in the case of Diabetes1, and 35 in the\ncase of Heart1. The goal consists in generating a classi\ufb01er\nthat takes the measurements of a pattern as input, and\nprovides its correct classi\ufb01cation as output.\nConcerning the structure of the feed-forward NNs that\nwe used, we took inspiration from the literature. More\nspeci\ufb01cally we used the same NN structures that were used\nin [1]: one hidden layer with six neurons. Table 1 gives an\noverview of the number of neurons (columns two, three,\nand four) and the resulting number of NN weights (last\ntable column), for each of the three problem instances. The\nnumber of NN weights is obtained by the following for-\nmula:\nnh\u00f0ni \u00fe 1\u00de \u00fe n0\u00f0nh \u00fe 1\u00de;\n\u00f011\u00de\nwhere ni, nh, and n0 are respectively the numbers of input,\nhidden, and output neurons. Note that the additional input\nfor each neuron of the hidden layer and the output layer\nrepresents the bias inputs.\n3.5 Parameter tuning\nAll our algorithms (with the exception of RS) require\ncertain parameter values to be determined before they can\nbe applied. While algorithms such as BP or LM have very\nfew parameters, ACOR (as well as its hybridized versions)\nhave more. In general, in order to ensure a fair comparison\nof algorithms, an equal amount of effort has to be spent in\nthe parameter tuning process for each of them. It has also\nbeen shown in the literature that the stopping condition for\nthe parameter tuning runs should be identical to the one\nused in the actual experiments, as otherwise the danger of\nchoosing suboptimal parameter values increases [34]. We\nhave hence used a common parameter tuning methodology\nfor all our algorithms, with the same stopping condition\nthat we used for the \ufb01nal experiments (that is, 1,000\nsolution evaluations).\nThe methodology that we used is known as the F-RACE\nmethodology [4, 5]. In particular we used the RACE\npackage for R. It allows running a race of different con-\n\ufb01gurations of algorithms against each other on a set of test\ninstances. After each round, the non-parametric Friedman\ntest is used to compare the performance of different con-\n\ufb01gurations. Con\ufb01gurations are being dropped from the race\nas soon as suf\ufb01cient statistical evidence has been gathered\nagainst them. For more information on the F-RACE\nmethodology, we refer the interested reader to [4].\nSince we wanted to tune each algorithm for each\nproblem instance seperately, we had to generate from each\nproblem instance an arti\ufb01cial set of tuning instances. This\nwas done by splitting the training set of the \ufb01rst cross-\nvalidation experiment (consisting of 75% of the total\namount of pattern) into a training set for tuning (two-third\nof these pattern), and a test set for tuning (one-third of\nthese pattern). Each tuning instance was generated by do-\ning this division randomly.\nFor the tuning we determined ten different con\ufb01gura-\ntions of parameter values for each of our algorithms. Then,\nwe applied F-RACE to each problem instance, allowing not\nmore than 100 experiments in each race. Each of the\nparameter tuning races returned one con\ufb01guration that\nTable 1 Overview of the NN structures used for the three problem\ninstances\nData set\nInput\nlayer\nHidden\nlayer\nOutput\nlayer\nNo. of\nweights\nCancer1\n9\n6\n2\n74\nDiabetes1\n8\n6\n2\n68\nHeart1\n35\n6\n2\n230\nColumns two, three, and four show the number of neurons of the\ninput, hidden, and output layer, respectively. In the last table column\nis given the resulting number of NN weights\n242\nNeural Comput & Applic (2007) 16:235\u2013247\n123\n", []], "Problem instances": ["need. However, the resulting computation times are in the\nsame order of magnitude.\nFor evaluating the algorithms, we performend a so-\ncalled k-fold cross-validation. Hereby, the set of pattern is\ndivided into k subsets. Then, k experiments are performed\nin which one of the k subsets is used as the test set and the\nremaining k\u20131 subsets are joined to form the training set.\nThen the average CEP value across all k experiments is\ncomputed. The aim of k-fold cross-validation is to average\nout the effects of the training/test set division. The disad-\nvantage of this method is that the training algorithm has to\nbe re-run from scratch k times, which uses quite a lot of\ncomputation time. In this work we perform a fourfold\ncross-validation.\n3.4 Problem instances\nDue to their practical importance, we chose to evaluate the\nperformance of ACOR on classi\ufb01cation problems arising in\nthe medical \ufb01eld. More speci\ufb01cally, we chose three prob-\nlems from the well-known PROBEN1 benchmark set [29],\nnamely Cancer1, Diabetes1, and Heart1. Each of these\nproblems consists of a number of patterns together with\ntheir correct classi\ufb01cation, that is, Cancer1 consists of 699\npatterns from a breast cancer database, Diabetes1 consists\nof 768 patterns concerning diabetes patients, and Heart1 is\nthe biggest of the three data sets, consisting of 920 patterns\ndescribing a heart condition. Each pattern of the three\nproblems is either classi\ufb01ed as pathological, or as normal.\nFurthermore, each pattern consists of a number of mea-\nsurements (i.e., numerical values): 9 measurements in the\ncase of Cancer1, 8 in the case of Diabetes1, and 35 in the\ncase of Heart1. The goal consists in generating a classi\ufb01er\nthat takes the measurements of a pattern as input, and\nprovides its correct classi\ufb01cation as output.\nConcerning the structure of the feed-forward NNs that\nwe used, we took inspiration from the literature. More\nspeci\ufb01cally we used the same NN structures that were used\nin [1]: one hidden layer with six neurons. Table 1 gives an\noverview of the number of neurons (columns two, three,\nand four) and the resulting number of NN weights (last\ntable column), for each of the three problem instances. The\nnumber of NN weights is obtained by the following for-\nmula:\nnh\u00f0ni \u00fe 1\u00de \u00fe n0\u00f0nh \u00fe 1\u00de;\n\u00f011\u00de\nwhere ni, nh, and n0 are respectively the numbers of input,\nhidden, and output neurons. Note that the additional input\nfor each neuron of the hidden layer and the output layer\nrepresents the bias inputs.\n3.5 Parameter tuning\nAll our algorithms (with the exception of RS) require\ncertain parameter values to be determined before they can\nbe applied. While algorithms such as BP or LM have very\nfew parameters, ACOR (as well as its hybridized versions)\nhave more. In general, in order to ensure a fair comparison\nof algorithms, an equal amount of effort has to be spent in\nthe parameter tuning process for each of them. It has also\nbeen shown in the literature that the stopping condition for\nthe parameter tuning runs should be identical to the one\nused in the actual experiments, as otherwise the danger of\nchoosing suboptimal parameter values increases [34]. We\nhave hence used a common parameter tuning methodology\nfor all our algorithms, with the same stopping condition\nthat we used for the \ufb01nal experiments (that is, 1,000\nsolution evaluations).\nThe methodology that we used is known as the F-RACE\nmethodology [4, 5]. In particular we used the RACE\npackage for R. It allows running a race of different con-\n\ufb01gurations of algorithms against each other on a set of test\ninstances. After each round, the non-parametric Friedman\ntest is used to compare the performance of different con-\n\ufb01gurations. Con\ufb01gurations are being dropped from the race\nas soon as suf\ufb01cient statistical evidence has been gathered\nagainst them. For more information on the F-RACE\nmethodology, we refer the interested reader to [4].\nSince we wanted to tune each algorithm for each\nproblem instance seperately, we had to generate from each\nproblem instance an arti\ufb01cial set of tuning instances. This\nwas done by splitting the training set of the \ufb01rst cross-\nvalidation experiment (consisting of 75% of the total\namount of pattern) into a training set for tuning (two-third\nof these pattern), and a test set for tuning (one-third of\nthese pattern). Each tuning instance was generated by do-\ning this division randomly.\nFor the tuning we determined ten different con\ufb01gura-\ntions of parameter values for each of our algorithms. Then,\nwe applied F-RACE to each problem instance, allowing not\nmore than 100 experiments in each race. Each of the\nparameter tuning races returned one con\ufb01guration that\nTable 1 Overview of the NN structures used for the three problem\ninstances\nData set\nInput\nlayer\nHidden\nlayer\nOutput\nlayer\nNo. of\nweights\nCancer1\n9\n6\n2\n74\nDiabetes1\n8\n6\n2\n68\nHeart1\n35\n6\n2\n230\nColumns two, three, and four show the number of neurons of the\ninput, hidden, and output layer, respectively. In the last table column\nis given the resulting number of NN weights\n242\nNeural Comput & Applic (2007) 16:235\u2013247\n123\n", []], "Experimental setup": ["neuron. The output layer consists of as many neurons as the\ndata set has classes, i.e., if the patterns of a medical data set\nbelong to either the class normal or to the class patho-\nlogical, the output layer consists of two neurons. Given the\nweights of all the neuron connections, in order to classify a\npattern, one provides its measurements as input to the input\nneurons, propagates the output signals from layer to layer\nuntil the output signals of the output neurons are obtained.\nEach output neuron is identi\ufb01ed with one of the possible\nclasses. The output neuron that produces the highest output\nsignal classi\ufb01es the respective pattern.\nThe process of generating a NN classi\ufb01er (that is, the\nNN con\ufb01guration problem) consists of determining the\nweights of the connections between the neurons such that\nthe NN classi\ufb01er shows a high performance. Since the\nweights are real-valued, this is a continuous optimization\nproblem of the following form: Given are n decision\nvariables {X1,...,Xn} with continuous domains. As these\ndomains are not restricted, each real number is feasible\n\u00f0i.e.; Xi 2 R\u00de: Furthermore, the problem is unconstrained,\nwhich means that the variable settings do not depend on\neach other. Sought is a solution that minimizes the clas-\nsi\ufb01cation error percentage (CEP), that is, the percentage of\nwrongly classi\ufb01ed patterns. Note that we will use the CEP\nin order to evaluate the results of our algorithm. However,\nwhen performing the NN training, the use of CEP as an\nobjective function has disadvantages. For example, CEP\ninduces a \ufb01tness landscape that is characterized by many\nplateaus, that is, areas in the search space in which the\nsolutions have the same CEP value. In general, this is not a\ndesirable property of an objective function. Therefore, for\nthe NN training process we use a different objective\nfunction called square error percentage (SEP):\nSEP \u00bc 100omax \u0003 omin\nn0np\nX\nnp\np\u00bc1\nX\nn0\ni\u00bc1\ntp\ni \u0003 op\ni\n\u00f0\n\u00de2;\n\u00f010\u00de\nwhere omax and omin are respectively the maximum and\nminimum values of the output signals of the output neurons\n(depending on the neuron transfer function), np represents\nthe number of patterns, n0 is the number of output neurons,\nand ti\np and oi\np represent respectively the expected and actual\nvalues of output neuron i for pattern p.\n3.2 Algorithms compared\nIn addition to the ACOR algorithm outlined in Sect. 2, we\nwill deal with the following algorithms in our experimental\nstudy:\n\u2022\nBP: This is the standard backpropagation algorithm\n[30]; without acceleration techniques and without\nregularization techniques such as weight decay or early\nstopping for avoiding over\ufb01tting. The reason for not\nusing these techniques is that we wanted to compare\nbasic algorithm versions.\n\u2022\nLM: The standard Levenberg\u2013Marquardt algorithm\n[20].\n\u2022\nACOR-BP (or simply acobp): This algorithm is\nobtained by applying to each solution generated by\nACOR one improving iteration of BP.\n\u2022\nACOR-LM (or simply acolm): This algorithm is\nobtained by applying to each solution generated by\nACOR one improving iteration of LM.\n\u2022\nRandom search (RS): This algorithm generates at each\niteration a random solution (that is, a random weight\nsettings). Since we used a sigmoidal neuron transfer\nfunction, it was not restrictive to limit the range of\nweight values to the interval [\u20135,5] for RS.\nFinally, note that all our algorithms were implemented\nusing the R programming language5 (a free alternative to\nS+).\n3.3 Experimental setup\nIn order to ensure a reasonably fair comparison, we al-\nlowed for each application of the 6 algorithms the same\nnumber of solution evaluations (namely 1,000 evaluations).\nNote that this does not mean that they spend exactly the\nsame amount of computation time: apart from evaluating\nsolutions, each of these algorithms (with the exception of\nRS) conducts calculations that the other algorithms do not\n(a)\n(b)\nFig. 5 a Feed-forward NN with one hidden layer of neurons. Note\nthat each neuron of a certain layer is connected to each neuron of the\nnext layer. b One single neuron (from either the hidden layer, or the\noutput layer). The neuron receives inputs (i.e., signals il, weighted by\nweights wl) from each neuron of the previous layer. Additionally, it\nreceives a so-called bias input ibias with weight wbias. The transfer\nfunction f(R) of a neuron transforms the sum of all the weighted\ninputs into an output signal, which serves as input for all the neurons\nof the following layer. Input signals, output signals, biases and\nweights are real values\n5 http://www.r-project.org\nNeural Comput & Applic (2007) 16:235\u2013247\n241\n123\n", []], "Algorithms compared": ["neuron. The output layer consists of as many neurons as the\ndata set has classes, i.e., if the patterns of a medical data set\nbelong to either the class normal or to the class patho-\nlogical, the output layer consists of two neurons. Given the\nweights of all the neuron connections, in order to classify a\npattern, one provides its measurements as input to the input\nneurons, propagates the output signals from layer to layer\nuntil the output signals of the output neurons are obtained.\nEach output neuron is identi\ufb01ed with one of the possible\nclasses. The output neuron that produces the highest output\nsignal classi\ufb01es the respective pattern.\nThe process of generating a NN classi\ufb01er (that is, the\nNN con\ufb01guration problem) consists of determining the\nweights of the connections between the neurons such that\nthe NN classi\ufb01er shows a high performance. Since the\nweights are real-valued, this is a continuous optimization\nproblem of the following form: Given are n decision\nvariables {X1,...,Xn} with continuous domains. As these\ndomains are not restricted, each real number is feasible\n\u00f0i.e.; Xi 2 R\u00de: Furthermore, the problem is unconstrained,\nwhich means that the variable settings do not depend on\neach other. Sought is a solution that minimizes the clas-\nsi\ufb01cation error percentage (CEP), that is, the percentage of\nwrongly classi\ufb01ed patterns. Note that we will use the CEP\nin order to evaluate the results of our algorithm. However,\nwhen performing the NN training, the use of CEP as an\nobjective function has disadvantages. For example, CEP\ninduces a \ufb01tness landscape that is characterized by many\nplateaus, that is, areas in the search space in which the\nsolutions have the same CEP value. In general, this is not a\ndesirable property of an objective function. Therefore, for\nthe NN training process we use a different objective\nfunction called square error percentage (SEP):\nSEP \u00bc 100omax \u0003 omin\nn0np\nX\nnp\np\u00bc1\nX\nn0\ni\u00bc1\ntp\ni \u0003 op\ni\n\u00f0\n\u00de2;\n\u00f010\u00de\nwhere omax and omin are respectively the maximum and\nminimum values of the output signals of the output neurons\n(depending on the neuron transfer function), np represents\nthe number of patterns, n0 is the number of output neurons,\nand ti\np and oi\np represent respectively the expected and actual\nvalues of output neuron i for pattern p.\n3.2 Algorithms compared\nIn addition to the ACOR algorithm outlined in Sect. 2, we\nwill deal with the following algorithms in our experimental\nstudy:\n\u2022\nBP: This is the standard backpropagation algorithm\n[30]; without acceleration techniques and without\nregularization techniques such as weight decay or early\nstopping for avoiding over\ufb01tting. The reason for not\nusing these techniques is that we wanted to compare\nbasic algorithm versions.\n\u2022\nLM: The standard Levenberg\u2013Marquardt algorithm\n[20].\n\u2022\nACOR-BP (or simply acobp): This algorithm is\nobtained by applying to each solution generated by\nACOR one improving iteration of BP.\n\u2022\nACOR-LM (or simply acolm): This algorithm is\nobtained by applying to each solution generated by\nACOR one improving iteration of LM.\n\u2022\nRandom search (RS): This algorithm generates at each\niteration a random solution (that is, a random weight\nsettings). Since we used a sigmoidal neuron transfer\nfunction, it was not restrictive to limit the range of\nweight values to the interval [\u20135,5] for RS.\nFinally, note that all our algorithms were implemented\nusing the R programming language5 (a free alternative to\nS+).\n3.3 Experimental setup\nIn order to ensure a reasonably fair comparison, we al-\nlowed for each application of the 6 algorithms the same\nnumber of solution evaluations (namely 1,000 evaluations).\nNote that this does not mean that they spend exactly the\nsame amount of computation time: apart from evaluating\nsolutions, each of these algorithms (with the exception of\nRS) conducts calculations that the other algorithms do not\n(a)\n(b)\nFig. 5 a Feed-forward NN with one hidden layer of neurons. Note\nthat each neuron of a certain layer is connected to each neuron of the\nnext layer. b One single neuron (from either the hidden layer, or the\noutput layer). The neuron receives inputs (i.e., signals il, weighted by\nweights wl) from each neuron of the previous layer. Additionally, it\nreceives a so-called bias input ibias with weight wbias. The transfer\nfunction f(R) of a neuron transforms the sum of all the weighted\ninputs into an output signal, which serves as input for all the neurons\nof the following layer. Input signals, output signals, biases and\nweights are real values\n5 http://www.r-project.org\nNeural Comput & Applic (2007) 16:235\u2013247\n241\n123\n", []], "Feed-forward neural networks for pattern classification": ["far away from the solution sl chosen earlier as the mean of\nthe PDF. Then, the vector sl su becomes the chosen\ndirection. The probability of choosing solution su at step i\n(having chosen earlier solution sl as the mean of the PDF)\nis the following:\np\u00f0sujsl\u00dei \u00bc\nd\u00f0su; sl\u00de4\ni\nPk\nr\u00bc1 d\u00f0sr; sl\u00de4\ni\n;\n\u00f09\u00de\nwhere the function d(\u0001,\u0001)i returns the Euclidean distance\nconcerning the (n\u2013i + 1)-dimensional search sub-space4\nbetween two members of the solution archive T. Once this\nvector is chosen, the new orthogonal basis for the ant\u2019s\ncoordinate system is created using the Gram-Schmidt\nprocess [18]. It takes as input all the (already orthogonal)\ndirections chosen in earlier ant\u2019s steps and the newly\nchosen vector. The remaining missing vectors (for the\nremaining dimensions) are chosen randomly. Then, all the\ncurrent coordinates of all the solutions in the archive are\nrotated and recalculated according to this new orthogonal\nbase resulting in the set of new temporary variables Zi,\ni = 1,...,n.\nAt the end of the solution construction process, the\nchosen values of the temporary variables Zi, i = 1,...,n are\nconverted back into the original coordinate system, giving\nrise to a set of values for the original decision variables Xi,\ni = 1,...,n.\n2.4 Improvement mechanisms\nThe fact that general optimization methods such as ACOR\ndo not consider any gradient information\u2014even though it\nmight be available\u2014may give them a disadvantage when\ncompared to methods that use this information. In order to\navoid this disadvantage, some iterations of gradient-based\nalgorithms might be applied to all solutions generated by\nthe ants.\n3 An application of ACOR : the NN training test case\nAs a test case for the evaluation of ACOR we chose the\ntraining of feed-forward NNs for the purpose of pattern\nclassi\ufb01cation. First, we will shortly present the concept of\nfeed-forward NNs for pattern classi\ufb01cation. Then, we are\ngoing to present the problem instances chosen for the\nexperimental evaluation, the tuning of the algorithms, and\nthe results obtained. In addition to the experimental eval-\nuation of our (re-)implemented algorithms, we will also\nprovide a comparison to some results from the literature. In\nparticular, we compare our approaches to a basic genetic\nalgorithm as well as to hybrids of this genetic algorithm\nconcerning the BP and LM algorithm.\n3.1 Feed-forward neural networks for pattern\nclassi\ufb01cation\nA data set for pattern classi\ufb01cation consists of a number of\npatterns together with their correct classi\ufb01cation. Each\npattern consists of a number of measurements (i.e.,\nnumerical values). The goal consists in generating a clas-\nsi\ufb01er that takes the measurements of a pattern as input, and\nprovides its correct classi\ufb01cation as output. A popular type\nof classi\ufb01er are feed-forward NNs [6].\nA feed-forward NN consists of an input layer of neu-\nrons, an arbitrary number of hidden layers, and an output\nlayer (for an example, see Fig. 5). Feed-forward NNs for\npattern classi\ufb01cation purposes consist of as many input\nneurons as the patterns of the data set have measurements,\ni.e., for each measurement there exists exactly one input\nEllipsoid\n\u22122\n\u22121\n0\n1\n2\n\u22122\n\u22121\n0\n1\n2\nRotated Ellipsoid\n\u22122\n\u22121\n0\n1\n2\n\u22122\n\u22121\n0\n1\n2\nFig. 4 Example of the Ellipsoid function: not rotated (left graphic),\nand rotated by 45\u0002 (right graphic). The function is shown by means of\n10,000 points of which only the best 1,000 points are visible. Note\nthat the darker a point the higher its rank (or quality). The original\ncoordinate system is marked in bold. In addition, the optimal one is\nindicated in the right plot. Also, the examples of the Gaussian kernel\nPDFs as generated using the default coordinate system are given on\nthe right and above each plot\n4 At step i, only dimensions i through n are used.\n240\nNeural Comput & Applic (2007) 16:235\u2013247\n123\n", []], "An application of {\\bf\\hbox{ACO}_{\\mathbb{R}}}: the NN training test case": ["far away from the solution sl chosen earlier as the mean of\nthe PDF. Then, the vector sl su becomes the chosen\ndirection. The probability of choosing solution su at step i\n(having chosen earlier solution sl as the mean of the PDF)\nis the following:\np\u00f0sujsl\u00dei \u00bc\nd\u00f0su; sl\u00de4\ni\nPk\nr\u00bc1 d\u00f0sr; sl\u00de4\ni\n;\n\u00f09\u00de\nwhere the function d(\u0001,\u0001)i returns the Euclidean distance\nconcerning the (n\u2013i + 1)-dimensional search sub-space4\nbetween two members of the solution archive T. Once this\nvector is chosen, the new orthogonal basis for the ant\u2019s\ncoordinate system is created using the Gram-Schmidt\nprocess [18]. It takes as input all the (already orthogonal)\ndirections chosen in earlier ant\u2019s steps and the newly\nchosen vector. The remaining missing vectors (for the\nremaining dimensions) are chosen randomly. Then, all the\ncurrent coordinates of all the solutions in the archive are\nrotated and recalculated according to this new orthogonal\nbase resulting in the set of new temporary variables Zi,\ni = 1,...,n.\nAt the end of the solution construction process, the\nchosen values of the temporary variables Zi, i = 1,...,n are\nconverted back into the original coordinate system, giving\nrise to a set of values for the original decision variables Xi,\ni = 1,...,n.\n2.4 Improvement mechanisms\nThe fact that general optimization methods such as ACOR\ndo not consider any gradient information\u2014even though it\nmight be available\u2014may give them a disadvantage when\ncompared to methods that use this information. In order to\navoid this disadvantage, some iterations of gradient-based\nalgorithms might be applied to all solutions generated by\nthe ants.\n3 An application of ACOR : the NN training test case\nAs a test case for the evaluation of ACOR we chose the\ntraining of feed-forward NNs for the purpose of pattern\nclassi\ufb01cation. First, we will shortly present the concept of\nfeed-forward NNs for pattern classi\ufb01cation. Then, we are\ngoing to present the problem instances chosen for the\nexperimental evaluation, the tuning of the algorithms, and\nthe results obtained. In addition to the experimental eval-\nuation of our (re-)implemented algorithms, we will also\nprovide a comparison to some results from the literature. In\nparticular, we compare our approaches to a basic genetic\nalgorithm as well as to hybrids of this genetic algorithm\nconcerning the BP and LM algorithm.\n3.1 Feed-forward neural networks for pattern\nclassi\ufb01cation\nA data set for pattern classi\ufb01cation consists of a number of\npatterns together with their correct classi\ufb01cation. Each\npattern consists of a number of measurements (i.e.,\nnumerical values). The goal consists in generating a clas-\nsi\ufb01er that takes the measurements of a pattern as input, and\nprovides its correct classi\ufb01cation as output. A popular type\nof classi\ufb01er are feed-forward NNs [6].\nA feed-forward NN consists of an input layer of neu-\nrons, an arbitrary number of hidden layers, and an output\nlayer (for an example, see Fig. 5). Feed-forward NNs for\npattern classi\ufb01cation purposes consist of as many input\nneurons as the patterns of the data set have measurements,\ni.e., for each measurement there exists exactly one input\nEllipsoid\n\u22122\n\u22121\n0\n1\n2\n\u22122\n\u22121\n0\n1\n2\nRotated Ellipsoid\n\u22122\n\u22121\n0\n1\n2\n\u22122\n\u22121\n0\n1\n2\nFig. 4 Example of the Ellipsoid function: not rotated (left graphic),\nand rotated by 45\u0002 (right graphic). The function is shown by means of\n10,000 points of which only the best 1,000 points are visible. Note\nthat the darker a point the higher its rank (or quality). The original\ncoordinate system is marked in bold. In addition, the optimal one is\nindicated in the right plot. Also, the examples of the Gaussian kernel\nPDFs as generated using the default coordinate system are given on\nthe right and above each plot\n4 At step i, only dimensions i through n are used.\n240\nNeural Comput & Applic (2007) 16:235\u2013247\n123\n", []], "Improvement mechanisms": ["far away from the solution sl chosen earlier as the mean of\nthe PDF. Then, the vector sl su becomes the chosen\ndirection. The probability of choosing solution su at step i\n(having chosen earlier solution sl as the mean of the PDF)\nis the following:\np\u00f0sujsl\u00dei \u00bc\nd\u00f0su; sl\u00de4\ni\nPk\nr\u00bc1 d\u00f0sr; sl\u00de4\ni\n;\n\u00f09\u00de\nwhere the function d(\u0001,\u0001)i returns the Euclidean distance\nconcerning the (n\u2013i + 1)-dimensional search sub-space4\nbetween two members of the solution archive T. Once this\nvector is chosen, the new orthogonal basis for the ant\u2019s\ncoordinate system is created using the Gram-Schmidt\nprocess [18]. It takes as input all the (already orthogonal)\ndirections chosen in earlier ant\u2019s steps and the newly\nchosen vector. The remaining missing vectors (for the\nremaining dimensions) are chosen randomly. Then, all the\ncurrent coordinates of all the solutions in the archive are\nrotated and recalculated according to this new orthogonal\nbase resulting in the set of new temporary variables Zi,\ni = 1,...,n.\nAt the end of the solution construction process, the\nchosen values of the temporary variables Zi, i = 1,...,n are\nconverted back into the original coordinate system, giving\nrise to a set of values for the original decision variables Xi,\ni = 1,...,n.\n2.4 Improvement mechanisms\nThe fact that general optimization methods such as ACOR\ndo not consider any gradient information\u2014even though it\nmight be available\u2014may give them a disadvantage when\ncompared to methods that use this information. In order to\navoid this disadvantage, some iterations of gradient-based\nalgorithms might be applied to all solutions generated by\nthe ants.\n3 An application of ACOR : the NN training test case\nAs a test case for the evaluation of ACOR we chose the\ntraining of feed-forward NNs for the purpose of pattern\nclassi\ufb01cation. First, we will shortly present the concept of\nfeed-forward NNs for pattern classi\ufb01cation. Then, we are\ngoing to present the problem instances chosen for the\nexperimental evaluation, the tuning of the algorithms, and\nthe results obtained. In addition to the experimental eval-\nuation of our (re-)implemented algorithms, we will also\nprovide a comparison to some results from the literature. In\nparticular, we compare our approaches to a basic genetic\nalgorithm as well as to hybrids of this genetic algorithm\nconcerning the BP and LM algorithm.\n3.1 Feed-forward neural networks for pattern\nclassi\ufb01cation\nA data set for pattern classi\ufb01cation consists of a number of\npatterns together with their correct classi\ufb01cation. Each\npattern consists of a number of measurements (i.e.,\nnumerical values). The goal consists in generating a clas-\nsi\ufb01er that takes the measurements of a pattern as input, and\nprovides its correct classi\ufb01cation as output. A popular type\nof classi\ufb01er are feed-forward NNs [6].\nA feed-forward NN consists of an input layer of neu-\nrons, an arbitrary number of hidden layers, and an output\nlayer (for an example, see Fig. 5). Feed-forward NNs for\npattern classi\ufb01cation purposes consist of as many input\nneurons as the patterns of the data set have measurements,\ni.e., for each measurement there exists exactly one input\nEllipsoid\n\u22122\n\u22121\n0\n1\n2\n\u22122\n\u22121\n0\n1\n2\nRotated Ellipsoid\n\u22122\n\u22121\n0\n1\n2\n\u22122\n\u22121\n0\n1\n2\nFig. 4 Example of the Ellipsoid function: not rotated (left graphic),\nand rotated by 45\u0002 (right graphic). The function is shown by means of\n10,000 points of which only the best 1,000 points are visible. Note\nthat the darker a point the higher its rank (or quality). The original\ncoordinate system is marked in bold. In addition, the optimal one is\nindicated in the right plot. Also, the examples of the Gaussian kernel\nPDFs as generated using the default coordinate system are given on\nthe right and above each plot\n4 At step i, only dimensions i through n are used.\n240\nNeural Comput & Applic (2007) 16:235\u2013247\n123\n", []], "Exploiting correlations between decision variables": ["generate random numbers according to a parametrized\nnormal distribution, or by using a uniform random gener-\nator in conjunction with, for instance, the Box-Muller\nmethod [10]. This two-phase sampling is equivalent to\nsampling the Gaussian kernel PDF Gi(x) as de\ufb01ned in\nEq. 4.\nIt is clear that at construction step i, the standard devi-\nation needs only to be known for the single Gaussian\nfunction gl\ni(x) chosen in phase one. Hence, we do not cal-\nculate the whole vector of standard deviations ri; but only\nthe entry rl\ni that is needed.\nThe choice of the lth Gaussian function is done only\nonce per ant and iteration. This means that an ant uses the\nGaussian functions associated with the chosen solution\nsl\u2014that is, functions gl\ni, i = 1,...,n\u2014for constructing the\nwhole solution in a given iteration. This allows exploiting\nthe correlation between the variables, which is explained in\ndetail in Sect. 3. Of course, the actual Gaussian function\nsampled differs at each construction step, as for step\ni, ll\ni = sl\ni, and rl\ni is calculated dynamically, as follows.\nIn order to establish the value of the standard deviation\nrl\ni at construction step i, we calculate the average distance\nfrom the chosen solution sl to other solutions in the archive,\nand we multiply it by the parameter n:\nri\nl \u00bc n\nX\nk\ne\u00bc1\njxi\ne \u0003 xi\nlj\nk \u0003 1 :\n\u00f07\u00de\nThe parameter n > 0, which is the same for all the\ndimensions, has an effect similar to that of the pheromone\nevaporation rate in ACO for combinatorial optimization.\nThe higher the value of n, the lower the convergence speed\nof the algorithm. While the pheromone evaporation rate in\nACO in\ufb02uences the long term memory\u2014i.e., lower quality\nsolutions are forgotten faster\u2014n in ACOR in\ufb02uences the\nway the long term memory is used\u2014i.e., lower quality\nsolutions have on average a lower in\ufb02uence when con-\nstructing new solutions.\nAs mentioned before, this whole process is done for each\ndimension i = 1,...,n in turn, and each time the average\ndistance rl\ni is calculated only with the use of the single\ndimension i. This ensures that the algorithm is able to adapt\nto linear transformation of the considered problem (e.g.,\nmoving from a sphere model to an ellipsoid, or rotating an\nellipsoid).\n2.3 Exploiting correlations between decision variables\nACO algorithms in general do not exploit correlation\ninformation between different decision variables. In ACOR;\ndue to the use of the solution archive, it is in fact possible to\ntake into account the correlation between the decision\nvariables. Consider Fig. 4, where the two-dimensional\nEllipsoid test function\nfEL\u00f0x\u00de \u00bc\nX\nn\ni\u00bc1\n100\ni\u00031\nn\u00031xi\n\u0002\n\u00032\n; n \u00bc 2\n\u00f08\u00de\nis shown\u2014not rotated (left), and then randomly rotated\n(right). The test function is presented from the view point\nof the ACOR algorithm, namely as a set of points repre-\nsenting different solutions found by the ants and stored in\nthe solution archive. The darker a point, the higher the\nquality of the correpsonding solution (and the higher its\nrank). While in the left plot the variables are not correlated\n(i.e., for good solutions, the value of one coordinate does\nnot depend on the value of the other coordinate), on the\nright plot they are highly correlated.\nThe default coordinate system that corresponds to the set\nof the original decision variables Xi, i = 1,2, is marked in\nbold. It is clear that the axes of that coordinate system align\nwell with the scaling of the test function in the left plot.\nThe Gaussian kernel PDFs for both dimensions are indi-\ncated on the right and above the plot. Clearly, a new\nsolution generated by these Gaussian kernel PDFS has a\nhigh probability to be in the promising region. In contrast,\nin the case of the rotated Ellipsoid function presented in the\nright plot, the PDFs created with the default coordinate\nsystem cover basically the whole search space (here D =\n[\u20132,2]2). This means that sampled solutions would be\nscattered all over the search space. In order to avoid this,\nthe other coordinate system indicated in the right plot\nshould be used. When using this other coordinate system,\nthe sampling would be as ef\ufb01cient as in the case of the non-\nrotated Ellipsoid function on the right.\nIn fact, ACOR dynamically adapts the coordinate system\nused by each ant in order to minimize the correlation be-\ntween different decision variables. The adaptation of the\ncoordinate system is accomplished by expressing the set of\ndecision variables X with temporary variables Zi, i = 1,...,n\nthat are linear combinations of Xi, i = 1,...,n. The following\nparagraphs shortly present how this is done.\nOne possible technique for adapting the coordinate\nsystem to the distribution of the solutions in the archive is\nknown as principal component analysis (PCA) (see, for\nexample, [22]). PCA works by performing a statistical\nanalysis of the solutions in the archive in order to distin-\nguish the principal components. However, due to the fact\nthat PCA is deterministic, for most non-trivial problems it\nis not robust enough and often leads to stagnation.\nThe mechanism that we designed instead, is relatively\nsimple. Each ant at each step of the construction process\nchooses a direction in the search space. The direction is\nchosen by randomly selecting a solution su that is reasonably\nNeural Comput & Applic (2007) 16:235\u2013247\n239\n123\n", []], "Probabilistic solution construction": ["ACOR algorithm are schematically shown in Fig. 1. In the\nfollowing we outline the components of ACOR in more\ndetail.\n2.1 Archive structure, initialization, and update\nACOR keeps a history of its search process by means of\nstoring solutions in a solution archive T. Given an n-\ndimensional optimization problem and a solution sl, ACOR\nstores in T the values of the solutions\u2019 n variables and the\nvalue of the objective function denoted by f(sl). The value\nof the ith variable of lth solution hereby denoted by sl\ni. The\nstructure of the solution archive T is presented in Fig. 2.\nWe denote the number of solutions memorized in the\narchive by k. This parameter in\ufb02uences the complexity of\nthe algorithm.2 Before the start of the algorithm, the ar-\nchive is initialized with k random solutions. Even though\nthe domains of the decision variables are\u2014in the case of\nfeed-forward NN training\u2014not restricted, we used the\ninitial interval [\u20131,1] for the sake of simplicity. At each\nalgorithm iteration, a set of m solutions is probabilistically\ngenerated and added to T. The same number of the worst\nsolutions are removed from T. This biases the search pro-\ncess towards the best solutions found during the search.\n2.2 Probabilistic solution construction\nFor the probabilistic construction of solutions, ACOR uses\nso-called probability density functions (PDFs). Before\ndescribing the solution construction mechanism, we \ufb01rst\ndiscuss certain characteristics of PDFs. In principle, a PDF\nmay be any function P\u00f0x\u00de : R 3 x ! P\u00f0x\u00de 2 R such that:\nZ1\n\u00031\nP\u00f0x\u00dedx \u00bc 1\n\u00f01\u00de\nFor a given probability density function P(x), an associated\ncumulative distribution function (CDF) D(x) may be de\ufb01ned,\nwhich is often useful when sampling the corresponding PDF.\nThe CDF D(x) associated with PDF P(x) is de\ufb01ned as\nfollows:\nD\u00f0x\u00de \u00bc\nZx\n\u00031\nP\u00f0t\u00dedt\n\u00f02\u00de\nThe general approach to sampling PDF P(x) is to use the\ninverse of its CDF, D\u20131(x). When using the inverse of the\nCDF, it is suf\ufb01cient to have a pseudo-random number\ngenerator that produces uniformly distributed real num-\nbers.3 However, it is important to note that for an arbitrarily\nchosen PDF P(x), it is not always straightforward to \ufb01nd\nD\u20131(x).\nOne of the most popular functions that is used as a PDF\nis the Gaussian function. It has some clear advantages\n(outlined below) but it also has some disadvantages. For\nexample, a single Gaussian function is not able to describe\na situation in which two disjoint areas of the search space\nare promising. This is because it only has one maximum.\nDue to this fact, ACOR uses a PDF based on Gaussian\nfunctions, but slightly enhanced\u2014a Gaussian kernel PDF.\nSimilar constructs have been used before [9], but not ex-\nactly in the same way. A Gaussian kernel is de\ufb01ned as a\nweighted sum of several one-dimensional Gaussian func-\ntions gl\ni(x):\nGi\u00f0x\u00de \u00bc\nX\nk\nl\u00bc1\nxlgi\nl\u00f0x\u00de \u00bc\nX\nk\nl\u00bc1\nxl\n1\nri\nl\n\ufb03\ufb03\ufb03\ufb03\ufb03\ufb03\n2p\np\ne\n\u0003\n\u00f0x\u0003li\nl\u00de2\n2ri\nl\n2 ;\n\u00f03\u00de\nFig. 1 The working of ACOR:\nFirst, the solution archive must\nbe initialized. Then, at each\niteration a number of solutions\nare probabilistically\nconstructed. These solutions\nmay be improved by any\nimprovement mechanism (for\nexample, local search or a\ngradient technique). Finally, the\nsolution archive is updated with\nthe generated solutions\n2 Note that k can not be smaller than the number of dimensions of the\nproblem being solved. This is due to the explicit handling of corre-\nlation among variables as explained in Sect. 3: In order to be able\nto rotate the coordinate system properly, the number of solutions\navailable has to be at least equal to the number of dimensions.\n3 Such pseudo-random number generators are routinely available for\nmost programming languages.\nNeural Comput & Applic (2007) 16:235\u2013247\n237\n123\n", []], "Archive structure, initialization, and update": ["ACOR algorithm are schematically shown in Fig. 1. In the\nfollowing we outline the components of ACOR in more\ndetail.\n2.1 Archive structure, initialization, and update\nACOR keeps a history of its search process by means of\nstoring solutions in a solution archive T. Given an n-\ndimensional optimization problem and a solution sl, ACOR\nstores in T the values of the solutions\u2019 n variables and the\nvalue of the objective function denoted by f(sl). The value\nof the ith variable of lth solution hereby denoted by sl\ni. The\nstructure of the solution archive T is presented in Fig. 2.\nWe denote the number of solutions memorized in the\narchive by k. This parameter in\ufb02uences the complexity of\nthe algorithm.2 Before the start of the algorithm, the ar-\nchive is initialized with k random solutions. Even though\nthe domains of the decision variables are\u2014in the case of\nfeed-forward NN training\u2014not restricted, we used the\ninitial interval [\u20131,1] for the sake of simplicity. At each\nalgorithm iteration, a set of m solutions is probabilistically\ngenerated and added to T. The same number of the worst\nsolutions are removed from T. This biases the search pro-\ncess towards the best solutions found during the search.\n2.2 Probabilistic solution construction\nFor the probabilistic construction of solutions, ACOR uses\nso-called probability density functions (PDFs). Before\ndescribing the solution construction mechanism, we \ufb01rst\ndiscuss certain characteristics of PDFs. In principle, a PDF\nmay be any function P\u00f0x\u00de : R 3 x ! P\u00f0x\u00de 2 R such that:\nZ1\n\u00031\nP\u00f0x\u00dedx \u00bc 1\n\u00f01\u00de\nFor a given probability density function P(x), an associated\ncumulative distribution function (CDF) D(x) may be de\ufb01ned,\nwhich is often useful when sampling the corresponding PDF.\nThe CDF D(x) associated with PDF P(x) is de\ufb01ned as\nfollows:\nD\u00f0x\u00de \u00bc\nZx\n\u00031\nP\u00f0t\u00dedt\n\u00f02\u00de\nThe general approach to sampling PDF P(x) is to use the\ninverse of its CDF, D\u20131(x). When using the inverse of the\nCDF, it is suf\ufb01cient to have a pseudo-random number\ngenerator that produces uniformly distributed real num-\nbers.3 However, it is important to note that for an arbitrarily\nchosen PDF P(x), it is not always straightforward to \ufb01nd\nD\u20131(x).\nOne of the most popular functions that is used as a PDF\nis the Gaussian function. It has some clear advantages\n(outlined below) but it also has some disadvantages. For\nexample, a single Gaussian function is not able to describe\na situation in which two disjoint areas of the search space\nare promising. This is because it only has one maximum.\nDue to this fact, ACOR uses a PDF based on Gaussian\nfunctions, but slightly enhanced\u2014a Gaussian kernel PDF.\nSimilar constructs have been used before [9], but not ex-\nactly in the same way. A Gaussian kernel is de\ufb01ned as a\nweighted sum of several one-dimensional Gaussian func-\ntions gl\ni(x):\nGi\u00f0x\u00de \u00bc\nX\nk\nl\u00bc1\nxlgi\nl\u00f0x\u00de \u00bc\nX\nk\nl\u00bc1\nxl\n1\nri\nl\n\ufb03\ufb03\ufb03\ufb03\ufb03\ufb03\n2p\np\ne\n\u0003\n\u00f0x\u0003li\nl\u00de2\n2ri\nl\n2 ;\n\u00f03\u00de\nFig. 1 The working of ACOR:\nFirst, the solution archive must\nbe initialized. Then, at each\niteration a number of solutions\nare probabilistically\nconstructed. These solutions\nmay be improved by any\nimprovement mechanism (for\nexample, local search or a\ngradient technique). Finally, the\nsolution archive is updated with\nthe generated solutions\n2 Note that k can not be smaller than the number of dimensions of the\nproblem being solved. This is due to the explicit handling of corre-\nlation among variables as explained in Sect. 3: In order to be able\nto rotate the coordinate system properly, the number of solutions\navailable has to be at least equal to the number of dimensions.\n3 Such pseudo-random number generators are routinely available for\nmost programming languages.\nNeural Comput & Applic (2007) 16:235\u2013247\n237\n123\n", []], "ACO for continuous optimization ({\\bf\\hbox{ACO}_{\\mathbb{R}}})": ["1.1 The goal of this work\nIn this work we choose as a test case for ACOR the\nproblem of feed-forward neural network (NN) training for\npattern classi\ufb01cation, which is an important real-world\nproblem. Feed-forward NNs are commonly used for the\ntask of pattern classi\ufb01cation [6], but they require prior\ncon\ufb01guration. Generally, the con\ufb01guration problem con-\nsists of two parts: First, the structure of the feed-forward\nNN has to be determined. Second, the numerical weights of\nthe neuron connections have to be determined such that the\nresulting classi\ufb01er is as correct as possible. In this work we\nfocus only on the second part, namely the optimization of\nthe connection weights. We adopt the NN structures from\nearlier works on the same subject. Readers interested in the\nevolution of NN structures might refer, for example, to [17,\n35, 38].\nWe want to state clearly at this point, that ACOR is still\na quite basic algorithm. For example, it does not include\npossible techniques for a more ef\ufb01cient exploration of the\nsearch space such as the use of multiple colonies. This is\nthe reason why we compare ACOR only to basic versions\nof other algorithms including gradient-based techniques as\nwell as general purpose optimizers. We intentially do not\ncompare to highly specialized algorithms, neither do we\nintent to improve the state-of-the-art results for the three\nbenchmark instances that we tackle. This is left for future\nwork. The important aspect of this work is the comparison\nof ACOR with other basic algorithms under the same\nconditions.1\n1.2 Prior work on bio-inspired techniques for NN\ntraining\nDuring the last 20 years, numerous bio-inspired algorithms\nhave been developed for the problem of NN training. In\nparticular the evolutionary computation community has\nproduced a vast number of works on this topic. Repre-\nsentative examples are genetic algorithms [1, 28], evolu-\ntion strategies [24], or estimation of distribution algorithms\n[11]. Recent developments from the swarm intelligence\n\ufb01eld include the particle swarm optimization algorithm\nproposed in [26]. For an overview, the interested reader\nmight refer to [2]. ACOR has inevitably similarities with\nalready existing techniques; in particular with some esti-\nmation of distribution algorithms [23], or with evolution\nstrategies that employ the covariance matrix adaptation\n(CMA) method [21]. However, an advantage of our\nalgorithm is that it originates from a different \ufb01eld with a\ndifferent point of view. This means that possibly our\nalgorithm can bene\ufb01t from techniques for guiding the\nsearch process or for making the search process more\nef\ufb01cient other than the ones available in evolutionary\ncomputation. This can prove bene\ufb01cial for our algorithm in\nthe future.\nThe outline of our work is as follows. In Sect. 2 we\npresent the ACOR algorithm for continuous optimization.\nIn Sect. 3 we describe the test case of neural network\ntraining, including the hybridizations of ACOR with\nbackpropagation (BP) and the Levenberg\u2013Marquardt (LM)\nalgorithm. Furthermore, we present the experimental\nevaluation of our algorithms. Finally, in Sect. 4 we offer\nconclusions and a glimpse of future work.\n2 ACO for continuous optimization (ACOR\u00de\nIn general, the ACO approach attempts to solve an opti-\nmization problem by iterating the following two steps:\n1.\nCandidate solutions are constructed in a probabilistic\nway by using a probability distribution over the search\nspace.\n2.\nThe candidate solutions are used to modify the prob-\nability distribution in a way that is deemed to bias\nfuture sampling toward high quality solutions.\nACO algorithms for combinatorial optimization prob-\nlems make use of a pheromone model in order to proba-\nbilistically construct solutions. A pheromone model is a set\nof so-called pheromone trail parameters. The numerical\nvalues of these pheromone trail parameters (that is, the\npheromone values) re\ufb02ect the search experience of the\nalgorithm. They are used to bias the solution construction\nover time to regions of the search space containing high\nquality solutions.\nHowever, instead of solving a combinatorial problem,\nlet us assume that we want to minimize a continuous\nfunction\nf : S \u0002 Rn7!R:\nThe search space S can hereby be modelled by a set of n\ndecision variables Xi (i = 1,..., n) with continuous domains.\nIn order to tackle this problem, ACOR uses a solution ar-\nchive for the derivation of a probability distribution over\nthe search space. While a pheromone model can be seen as\nan implicit memory of the search history, a solution archive\nis an explicit memory. A similar idea was proposed by\nGuntsch and Middendorf in [19] for combinatorial opti-\nmization problems. This related approach is called Popu-\nlation-Based ACO (PB-ACO). The components of the\n1 Note that this paper is an extension of the work published in [7, 32].\nThe extension consists in a more detailed explanation of the algorithm\nitself, the conduction of a fourfold cross-validation for all applications\nto test instances, and the conduction of tests for determining the\nstatistical signi\ufb01cance of the obtained results.\n236\nNeural Comput & Applic (2007) 16:235\u2013247\n123\n", []], "Prior work on bio-inspired techniques for NN training": ["1.1 The goal of this work\nIn this work we choose as a test case for ACOR the\nproblem of feed-forward neural network (NN) training for\npattern classi\ufb01cation, which is an important real-world\nproblem. Feed-forward NNs are commonly used for the\ntask of pattern classi\ufb01cation [6], but they require prior\ncon\ufb01guration. Generally, the con\ufb01guration problem con-\nsists of two parts: First, the structure of the feed-forward\nNN has to be determined. Second, the numerical weights of\nthe neuron connections have to be determined such that the\nresulting classi\ufb01er is as correct as possible. In this work we\nfocus only on the second part, namely the optimization of\nthe connection weights. We adopt the NN structures from\nearlier works on the same subject. Readers interested in the\nevolution of NN structures might refer, for example, to [17,\n35, 38].\nWe want to state clearly at this point, that ACOR is still\na quite basic algorithm. For example, it does not include\npossible techniques for a more ef\ufb01cient exploration of the\nsearch space such as the use of multiple colonies. This is\nthe reason why we compare ACOR only to basic versions\nof other algorithms including gradient-based techniques as\nwell as general purpose optimizers. We intentially do not\ncompare to highly specialized algorithms, neither do we\nintent to improve the state-of-the-art results for the three\nbenchmark instances that we tackle. This is left for future\nwork. The important aspect of this work is the comparison\nof ACOR with other basic algorithms under the same\nconditions.1\n1.2 Prior work on bio-inspired techniques for NN\ntraining\nDuring the last 20 years, numerous bio-inspired algorithms\nhave been developed for the problem of NN training. In\nparticular the evolutionary computation community has\nproduced a vast number of works on this topic. Repre-\nsentative examples are genetic algorithms [1, 28], evolu-\ntion strategies [24], or estimation of distribution algorithms\n[11]. Recent developments from the swarm intelligence\n\ufb01eld include the particle swarm optimization algorithm\nproposed in [26]. For an overview, the interested reader\nmight refer to [2]. ACOR has inevitably similarities with\nalready existing techniques; in particular with some esti-\nmation of distribution algorithms [23], or with evolution\nstrategies that employ the covariance matrix adaptation\n(CMA) method [21]. However, an advantage of our\nalgorithm is that it originates from a different \ufb01eld with a\ndifferent point of view. This means that possibly our\nalgorithm can bene\ufb01t from techniques for guiding the\nsearch process or for making the search process more\nef\ufb01cient other than the ones available in evolutionary\ncomputation. This can prove bene\ufb01cial for our algorithm in\nthe future.\nThe outline of our work is as follows. In Sect. 2 we\npresent the ACOR algorithm for continuous optimization.\nIn Sect. 3 we describe the test case of neural network\ntraining, including the hybridizations of ACOR with\nbackpropagation (BP) and the Levenberg\u2013Marquardt (LM)\nalgorithm. Furthermore, we present the experimental\nevaluation of our algorithms. Finally, in Sect. 4 we offer\nconclusions and a glimpse of future work.\n2 ACO for continuous optimization (ACOR\u00de\nIn general, the ACO approach attempts to solve an opti-\nmization problem by iterating the following two steps:\n1.\nCandidate solutions are constructed in a probabilistic\nway by using a probability distribution over the search\nspace.\n2.\nThe candidate solutions are used to modify the prob-\nability distribution in a way that is deemed to bias\nfuture sampling toward high quality solutions.\nACO algorithms for combinatorial optimization prob-\nlems make use of a pheromone model in order to proba-\nbilistically construct solutions. A pheromone model is a set\nof so-called pheromone trail parameters. The numerical\nvalues of these pheromone trail parameters (that is, the\npheromone values) re\ufb02ect the search experience of the\nalgorithm. They are used to bias the solution construction\nover time to regions of the search space containing high\nquality solutions.\nHowever, instead of solving a combinatorial problem,\nlet us assume that we want to minimize a continuous\nfunction\nf : S \u0002 Rn7!R:\nThe search space S can hereby be modelled by a set of n\ndecision variables Xi (i = 1,..., n) with continuous domains.\nIn order to tackle this problem, ACOR uses a solution ar-\nchive for the derivation of a probability distribution over\nthe search space. While a pheromone model can be seen as\nan implicit memory of the search history, a solution archive\nis an explicit memory. A similar idea was proposed by\nGuntsch and Middendorf in [19] for combinatorial opti-\nmization problems. This related approach is called Popu-\nlation-Based ACO (PB-ACO). The components of the\n1 Note that this paper is an extension of the work published in [7, 32].\nThe extension consists in a more detailed explanation of the algorithm\nitself, the conduction of a fourfold cross-validation for all applications\nto test instances, and the conduction of tests for determining the\nstatistical signi\ufb01cance of the obtained results.\n236\nNeural Comput & Applic (2007) 16:235\u2013247\n123\n", []], "The goal of this work": ["1.1 The goal of this work\nIn this work we choose as a test case for ACOR the\nproblem of feed-forward neural network (NN) training for\npattern classi\ufb01cation, which is an important real-world\nproblem. Feed-forward NNs are commonly used for the\ntask of pattern classi\ufb01cation [6], but they require prior\ncon\ufb01guration. Generally, the con\ufb01guration problem con-\nsists of two parts: First, the structure of the feed-forward\nNN has to be determined. Second, the numerical weights of\nthe neuron connections have to be determined such that the\nresulting classi\ufb01er is as correct as possible. In this work we\nfocus only on the second part, namely the optimization of\nthe connection weights. We adopt the NN structures from\nearlier works on the same subject. Readers interested in the\nevolution of NN structures might refer, for example, to [17,\n35, 38].\nWe want to state clearly at this point, that ACOR is still\na quite basic algorithm. For example, it does not include\npossible techniques for a more ef\ufb01cient exploration of the\nsearch space such as the use of multiple colonies. This is\nthe reason why we compare ACOR only to basic versions\nof other algorithms including gradient-based techniques as\nwell as general purpose optimizers. We intentially do not\ncompare to highly specialized algorithms, neither do we\nintent to improve the state-of-the-art results for the three\nbenchmark instances that we tackle. This is left for future\nwork. The important aspect of this work is the comparison\nof ACOR with other basic algorithms under the same\nconditions.1\n1.2 Prior work on bio-inspired techniques for NN\ntraining\nDuring the last 20 years, numerous bio-inspired algorithms\nhave been developed for the problem of NN training. In\nparticular the evolutionary computation community has\nproduced a vast number of works on this topic. Repre-\nsentative examples are genetic algorithms [1, 28], evolu-\ntion strategies [24], or estimation of distribution algorithms\n[11]. Recent developments from the swarm intelligence\n\ufb01eld include the particle swarm optimization algorithm\nproposed in [26]. For an overview, the interested reader\nmight refer to [2]. ACOR has inevitably similarities with\nalready existing techniques; in particular with some esti-\nmation of distribution algorithms [23], or with evolution\nstrategies that employ the covariance matrix adaptation\n(CMA) method [21]. However, an advantage of our\nalgorithm is that it originates from a different \ufb01eld with a\ndifferent point of view. This means that possibly our\nalgorithm can bene\ufb01t from techniques for guiding the\nsearch process or for making the search process more\nef\ufb01cient other than the ones available in evolutionary\ncomputation. This can prove bene\ufb01cial for our algorithm in\nthe future.\nThe outline of our work is as follows. In Sect. 2 we\npresent the ACOR algorithm for continuous optimization.\nIn Sect. 3 we describe the test case of neural network\ntraining, including the hybridizations of ACOR with\nbackpropagation (BP) and the Levenberg\u2013Marquardt (LM)\nalgorithm. Furthermore, we present the experimental\nevaluation of our algorithms. Finally, in Sect. 4 we offer\nconclusions and a glimpse of future work.\n2 ACO for continuous optimization (ACOR\u00de\nIn general, the ACO approach attempts to solve an opti-\nmization problem by iterating the following two steps:\n1.\nCandidate solutions are constructed in a probabilistic\nway by using a probability distribution over the search\nspace.\n2.\nThe candidate solutions are used to modify the prob-\nability distribution in a way that is deemed to bias\nfuture sampling toward high quality solutions.\nACO algorithms for combinatorial optimization prob-\nlems make use of a pheromone model in order to proba-\nbilistically construct solutions. A pheromone model is a set\nof so-called pheromone trail parameters. The numerical\nvalues of these pheromone trail parameters (that is, the\npheromone values) re\ufb02ect the search experience of the\nalgorithm. They are used to bias the solution construction\nover time to regions of the search space containing high\nquality solutions.\nHowever, instead of solving a combinatorial problem,\nlet us assume that we want to minimize a continuous\nfunction\nf : S \u0002 Rn7!R:\nThe search space S can hereby be modelled by a set of n\ndecision variables Xi (i = 1,..., n) with continuous domains.\nIn order to tackle this problem, ACOR uses a solution ar-\nchive for the derivation of a probability distribution over\nthe search space. While a pheromone model can be seen as\nan implicit memory of the search history, a solution archive\nis an explicit memory. A similar idea was proposed by\nGuntsch and Middendorf in [19] for combinatorial opti-\nmization problems. This related approach is called Popu-\nlation-Based ACO (PB-ACO). The components of the\n1 Note that this paper is an extension of the work published in [7, 32].\nThe extension consists in a more detailed explanation of the algorithm\nitself, the conduction of a fourfold cross-validation for all applications\nto test instances, and the conduction of tests for determining the\nstatistical signi\ufb01cance of the obtained results.\n236\nNeural Comput & Applic (2007) 16:235\u2013247\n123\n", []], "Introduction": ["ORIGINAL ARTICLE\nAn ant colony optimization algorithm for continuous\noptimization: application to feed-forward neural network training\nKrzysztof Socha \u00c6 Christian Blum\nReceived: 1 December 2006 / Accepted: 21 December 2006 / Published online: 2 March 2007\n\u0001 Springer-Verlag London Limited 2007\nAbstract\nAnt colony optimization (ACO) is an optimi-\nzation technique that was inspired by the foraging behav-\niour of real ant colonies. Originally, the method was\nintroduced for the application to discrete optimization\nproblems. Recently we proposed a \ufb01rst ACO variant for\ncontinuous optimization. In this work we choose the\ntraining of feed-forward neural networks for pattern clas-\nsi\ufb01cation as a test case for this algorithm. In addition, we\npropose hybrid algorithm variants that incorporate short\nruns of classical gradient techniques such as backpropa-\ngation. For evaluating our algorithms we apply them to\nclassi\ufb01cation problems from the medical \ufb01eld, and com-\npare the results to some basic algorithms from the litera-\nture. The results show, \ufb01rst, that the best of our algorithms\nare comparable to gradient-based algorithms for neural\nnetwork training, and second, that our algorithms compare\nfavorably with a basic genetic algorithm.\nKeywords\nAnt colony optimization \u0001 Continuous\noptimization \u0001 Feed-forward neural network training\n1 Introduction\nAnt colony optimization (ACO) is an optimization tech-\nnique that was introduced for the application to discrete\noptimization problems in the early 1990s by Dorigo et al.\n[13\u201315]. The origins of ant colony optimization are in a\n\ufb01eld called swarm intelligence [8] which studies the use of\ncertain properties of social insects, \ufb02ocks of birds, or \ufb01sh\nschools, for tasks such as optimization. The inspiring\nsource of ACO is the foraging behaviour of real ant colo-\nnies. When searching for food, ants initially explore the\narea surrounding their nest in a random manner. While\nmoving, ants leave a chemical pheromone trail on the\nground. As soon as an ant \ufb01nds a food source, it evaluates\nthe quantity and the quality of the food and carries some of\nit back to the nest. During the return trip, the quantity of\npheromone that an ant leaves on the ground may depend on\nthe quantity and quality of the food. The pheromone trails\nguide other ants to the food source. It has been shown in\n[12] that the indirect communication between the ants via\npheromone trails enables them to \ufb01nd shortest paths be-\ntween their nest and food sources. The shortest path \ufb01nding\ncapabilities of real ant colonies are exploited in arti\ufb01cial\nant colonies for solving optimization problems.\nWhile ACO algorithms were originally introduced to\nsolve discrete optimization (i.e., combinatorial) problems,\ntheir adaptation to solve continuous optimization prob-\nlems enjoys an increasing attention. Early applications\nof the ants metaphor to continuous optimization include\nalgorithms such as Continuous ACO (CACO) [3], the API\nalgorithm [27], and Continuous Interacting Ant Colony\n(CIAC) [16]. However, all these approaches do not follow\nthe original ACO framework. The latest approach\u2014called\nACOR \u2014was proposed in [31, 33]. Up to now, ACOR is the\nACO variant that is closest to the spirit of ACO for combi-\nnatorial problems. In [31, 33] it was shown that ACOR\nhas clear advantages over the existing ACO variants when\napplied to continuous benchmark functions.\nK. Socha (&)\nIRIDIA, CoDE, Universite\u00b4 Libre de Bruxelles,\nBrussels, Belgium\ne-mail: ksocha@ulb.ac.be\nC. Blum\nALBCOM, LSI, Universitat Polite`cnica de Catalunya,\nBarcelona, Spain\ne-mail: cblum@lsi.upc.edu\n123\nNeural Comput & Applic (2007) 16:235\u2013247\nDOI 10.1007/s00521-007-0084-z\n", []], "Abstract": ["ORIGINAL ARTICLE\nAn ant colony optimization algorithm for continuous\noptimization: application to feed-forward neural network training\nKrzysztof Socha \u00c6 Christian Blum\nReceived: 1 December 2006 / Accepted: 21 December 2006 / Published online: 2 March 2007\n\u0001 Springer-Verlag London Limited 2007\nAbstract\nAnt colony optimization (ACO) is an optimi-\nzation technique that was inspired by the foraging behav-\niour of real ant colonies. Originally, the method was\nintroduced for the application to discrete optimization\nproblems. Recently we proposed a \ufb01rst ACO variant for\ncontinuous optimization. In this work we choose the\ntraining of feed-forward neural networks for pattern clas-\nsi\ufb01cation as a test case for this algorithm. In addition, we\npropose hybrid algorithm variants that incorporate short\nruns of classical gradient techniques such as backpropa-\ngation. For evaluating our algorithms we apply them to\nclassi\ufb01cation problems from the medical \ufb01eld, and com-\npare the results to some basic algorithms from the litera-\nture. The results show, \ufb01rst, that the best of our algorithms\nare comparable to gradient-based algorithms for neural\nnetwork training, and second, that our algorithms compare\nfavorably with a basic genetic algorithm.\nKeywords\nAnt colony optimization \u0001 Continuous\noptimization \u0001 Feed-forward neural network training\n1 Introduction\nAnt colony optimization (ACO) is an optimization tech-\nnique that was introduced for the application to discrete\noptimization problems in the early 1990s by Dorigo et al.\n[13\u201315]. The origins of ant colony optimization are in a\n\ufb01eld called swarm intelligence [8] which studies the use of\ncertain properties of social insects, \ufb02ocks of birds, or \ufb01sh\nschools, for tasks such as optimization. The inspiring\nsource of ACO is the foraging behaviour of real ant colo-\nnies. When searching for food, ants initially explore the\narea surrounding their nest in a random manner. While\nmoving, ants leave a chemical pheromone trail on the\nground. As soon as an ant \ufb01nds a food source, it evaluates\nthe quantity and the quality of the food and carries some of\nit back to the nest. During the return trip, the quantity of\npheromone that an ant leaves on the ground may depend on\nthe quantity and quality of the food. The pheromone trails\nguide other ants to the food source. It has been shown in\n[12] that the indirect communication between the ants via\npheromone trails enables them to \ufb01nd shortest paths be-\ntween their nest and food sources. The shortest path \ufb01nding\ncapabilities of real ant colonies are exploited in arti\ufb01cial\nant colonies for solving optimization problems.\nWhile ACO algorithms were originally introduced to\nsolve discrete optimization (i.e., combinatorial) problems,\ntheir adaptation to solve continuous optimization prob-\nlems enjoys an increasing attention. Early applications\nof the ants metaphor to continuous optimization include\nalgorithms such as Continuous ACO (CACO) [3], the API\nalgorithm [27], and Continuous Interacting Ant Colony\n(CIAC) [16]. However, all these approaches do not follow\nthe original ACO framework. The latest approach\u2014called\nACOR \u2014was proposed in [31, 33]. Up to now, ACOR is the\nACO variant that is closest to the spirit of ACO for combi-\nnatorial problems. In [31, 33] it was shown that ACOR\nhas clear advantages over the existing ACO variants when\napplied to continuous benchmark functions.\nK. Socha (&)\nIRIDIA, CoDE, Universite\u00b4 Libre de Bruxelles,\nBrussels, Belgium\ne-mail: ksocha@ulb.ac.be\nC. Blum\nALBCOM, LSI, Universitat Polite`cnica de Catalunya,\nBarcelona, Spain\ne-mail: cblum@lsi.upc.edu\n123\nNeural Comput & Applic (2007) 16:235\u2013247\nDOI 10.1007/s00521-007-0084-z\n", []], "An ant colony optimization algorithm for continuous optimization: application to feed-forward neural network training": ["ORIGINAL ARTICLE\nAn ant colony optimization algorithm for continuous\noptimization: application to feed-forward neural network training\nKrzysztof Socha \u00c6 Christian Blum\nReceived: 1 December 2006 / Accepted: 21 December 2006 / Published online: 2 March 2007\n\u0001 Springer-Verlag London Limited 2007\nAbstract\nAnt colony optimization (ACO) is an optimi-\nzation technique that was inspired by the foraging behav-\niour of real ant colonies. Originally, the method was\nintroduced for the application to discrete optimization\nproblems. Recently we proposed a \ufb01rst ACO variant for\ncontinuous optimization. In this work we choose the\ntraining of feed-forward neural networks for pattern clas-\nsi\ufb01cation as a test case for this algorithm. In addition, we\npropose hybrid algorithm variants that incorporate short\nruns of classical gradient techniques such as backpropa-\ngation. For evaluating our algorithms we apply them to\nclassi\ufb01cation problems from the medical \ufb01eld, and com-\npare the results to some basic algorithms from the litera-\nture. The results show, \ufb01rst, that the best of our algorithms\nare comparable to gradient-based algorithms for neural\nnetwork training, and second, that our algorithms compare\nfavorably with a basic genetic algorithm.\nKeywords\nAnt colony optimization \u0001 Continuous\noptimization \u0001 Feed-forward neural network training\n1 Introduction\nAnt colony optimization (ACO) is an optimization tech-\nnique that was introduced for the application to discrete\noptimization problems in the early 1990s by Dorigo et al.\n[13\u201315]. The origins of ant colony optimization are in a\n\ufb01eld called swarm intelligence [8] which studies the use of\ncertain properties of social insects, \ufb02ocks of birds, or \ufb01sh\nschools, for tasks such as optimization. The inspiring\nsource of ACO is the foraging behaviour of real ant colo-\nnies. When searching for food, ants initially explore the\narea surrounding their nest in a random manner. While\nmoving, ants leave a chemical pheromone trail on the\nground. As soon as an ant \ufb01nds a food source, it evaluates\nthe quantity and the quality of the food and carries some of\nit back to the nest. During the return trip, the quantity of\npheromone that an ant leaves on the ground may depend on\nthe quantity and quality of the food. The pheromone trails\nguide other ants to the food source. It has been shown in\n[12] that the indirect communication between the ants via\npheromone trails enables them to \ufb01nd shortest paths be-\ntween their nest and food sources. The shortest path \ufb01nding\ncapabilities of real ant colonies are exploited in arti\ufb01cial\nant colonies for solving optimization problems.\nWhile ACO algorithms were originally introduced to\nsolve discrete optimization (i.e., combinatorial) problems,\ntheir adaptation to solve continuous optimization prob-\nlems enjoys an increasing attention. Early applications\nof the ants metaphor to continuous optimization include\nalgorithms such as Continuous ACO (CACO) [3], the API\nalgorithm [27], and Continuous Interacting Ant Colony\n(CIAC) [16]. However, all these approaches do not follow\nthe original ACO framework. The latest approach\u2014called\nACOR \u2014was proposed in [31, 33]. Up to now, ACOR is the\nACO variant that is closest to the spirit of ACO for combi-\nnatorial problems. In [31, 33] it was shown that ACOR\nhas clear advantages over the existing ACO variants when\napplied to continuous benchmark functions.\nK. Socha (&)\nIRIDIA, CoDE, Universite\u00b4 Libre de Bruxelles,\nBrussels, Belgium\ne-mail: ksocha@ulb.ac.be\nC. Blum\nALBCOM, LSI, Universitat Polite`cnica de Catalunya,\nBarcelona, Spain\ne-mail: cblum@lsi.upc.edu\n123\nNeural Comput & Applic (2007) 16:235\u2013247\nDOI 10.1007/s00521-007-0084-z\n", []]}