{"References": ["1520\nM. Mavrovouniotis, S. Yang\nTable 6 Comparison of the CEP results with their standard deviation of the proposed ACO training on a several benchmark datasets with the results\nof other bio-inspired training algorithms obtained from Ozturk and Karaboga (2009)\nProblem\nACO\nGA\nPSO\nABC\nDE\nBP\nLM\nCancer\n1.42 \u00b1 1.05\n1.35 \u00b1 0.28\n2.01 \u00b1 0.86\n1.14 \u00b1 0.00\n1.19 \u00b1 0.28\n1.89 \u00b1 0.43\n8.18 \u00b1 10.29\nDiabetes\n24.43 \u00b1 4.65\n26.51 \u00b1 1.21\n27.50 \u00b1 2.05\n25.22 \u00b1 0.97\n24.84 \u00b1 1.32\n28.27 \u00b1 6.30\n29.80 \u00b1 3.77\nHeart\n20.02 \u00b1 1.60\n20.60 \u00b1 0.68\n21.87 \u00b1 1.45\n19.48 \u00b1 1.41\n20.33 \u00b1 1.29\n21.44 \u00b1 0.55\n24.96 \u00b1 7.40\nThyroid\n6.31 \u00b1 0.09\n7.09 \u00b1 0.03\n7.27 \u00b1 0.02\n6.95 \u00b1 0.01\n7.08 \u00b1 0.95\n7.26 \u00b1 0.00\n2.61 \u00b1 1.81\nGene\n30.05 \u00b1 1.89\n31.02 \u00b1 0.71\n36.30 \u00b1 2.10\n29.50 \u00b1 1.88\n31.18 \u00b1 2.18\n11.37 \u00b1 1.15\n14.35 \u00b1 2.48\nHorse\n27.56 \u00b1 6.22\n29.12 \u00b1 2.84\n31.14 \u00b1 3.94\n28.63 \u00b1 2.61\n29.29 \u00b1 2.72\n27.84 \u00b1 2.12\n33.79 \u00b1 4.50\nCard\n12.90 \u00b1 3.01\n13.56 \u00b1 1.21\n15.58 \u00b1 1.59\n13.53 \u00b1 1.17\n13.90 \u00b1 1.26\n13.86 \u00b1 0.47\n21.59 \u00b1 7.98\nGlass\n45.77 \u00b1 8.25\n50.18 \u00b1 3.15\n52.49 \u00b1 7.14\n45.62 \u00b1 3.11\n44.90 \u00b1 2.84\n59.09 \u00b1 9.52\n42.99 \u00b1 11.55\nSoybean\n36.42 \u00b1 6.84\n40.39 \u00b1 4.93\n60.50 \u00b1 8.50\n38.63 \u00b1 3.18\n74.90 \u00b1 2.10\n61.16 \u00b1 19.18\n25.51 \u00b1 9.89\nThe best value among all algorithms for each problem is indicated in bold\nGenerally speaking, among the bio-inspired training algo-\nrithms the proposed ACO training algorithm achieves the\nbest result for more datasets than its competitors, closely fol-\nlowed by the ABC training algorithm. Although ACO has\nbetter performance than ABC, the latter has better robust-\nness than ACO. This can be observed from the experimental\nresults, where ABC maintains lower standard deviation but\nhigher CEP, whereas ACO maintains higher standard devia-\ntion but lower CEP. Finally, LM and ACO training algorithms\nachieve the best results for three datasets among all training\nalgorithms, whereas ABC achieves the best results for the\nremaining two datasets.\n5 Conclusions\nThe connection weights in feed-forward neural networks are\nusually adjusted using gradient descent methods. Often such\nmethods may get trapped to local optima of the search land-\nscape. In this paper, an ACO training is proposed where a\npopulation of ants select different combinations for connec-\ntion weight values. A standalone ACO and a hybrid ACO-\nBP training are applied to train feed-forward neural net-\nworks for pattern classi\ufb01cation. Several real-world bench-\nmark problems are selected as test problems in the exper-\niments. The performance of ACO and ACO-BP training is\ncompared against: two traditional training methods (i.e., BP\nand LM), an ACO training without pheromone consideration\n(i.e., RCH), a standalone ACO and a hybrid ACO from the lit-\nerature (Socha and Blum 2007) (i.e., ACOR and ACOR-BP),\nrespectively, and four other nature-inspired training methods\n(i.e., GA, PSO, ABC and DE) from the literature (Ozturk and\nKaraboga 2009).\nFromtheexperimentalresults,severalconcludingremarks\ncan be drawn. First, ACO is a good choice for selecting\ngood values for the BP. The standalone ACO training is\noutperformed by the standalone ACOR training whereas the\nhybrid ACO-BP shows superior performance, especially on\nlarge problem instances. Second, the performance of gradient\ndescent methods is degraded as the problem size increases\nwhen compared with the hybrid ACO-BP training algorithm.\nThird, gradient descent methods usually have better perfor-\nmance than a standalone metaheuristic training, including\nACO training. This is because gradient descent methods are\nmore accurate than metaheuristic methods in terms of search-\ning. Finally, ACO has a relatively good performance when\ncompared with other metaheuristics in network training for\npattern classi\ufb01cation. However, different metaheuristics per-\nform better on different problem instances due to the problem\ndependency issue.\nIn general, the ACO metaheuristic can be a useful tech-\nnique in neural network training for pattern classi\ufb01cation\nespecially when it is hybridized with gradient descent train-\ning.\nFor future work, it will be interesting to apply LM as\na local search improvement with ACO, or even apply both\nBM and LM as local search improvements. Moreover, it will\nbe interesting to investigate ACO\u2019s training adaptability to a\ndynamic environment (Rakitianskaia and Engelbrecht 2012).\nAcknowledgments\nThe authors would like to thank the anonymous\nreviewers for their thoughtful suggestions and constructive comments.\nThis work was supported by the Engineering and Physical Sciences\nResearch Council (EPSRC) of UK under Grant EP/K001310/1.\nReferences\nAlba E, Chicano J (2004) Training neural networks with ga hybrid\nalgorithms. In: Deb K (ed) Proceedings of the 2004 Genetic and\nEvolutionary Computation Conference, vol 3102. LNCS, Springer,\nBerlin, pp 852\u2013863\nAlba E, Marti R (eds) (2006) Metaheuristic procedures for training\nneural networks. Springer, New York\nBache K, Lichman M (2013) UCI machine learning repository. http://\narchive.ics.uci.edu/ml\n123\n", []], "Acknowledgments": ["1520\nM. Mavrovouniotis, S. Yang\nTable 6 Comparison of the CEP results with their standard deviation of the proposed ACO training on a several benchmark datasets with the results\nof other bio-inspired training algorithms obtained from Ozturk and Karaboga (2009)\nProblem\nACO\nGA\nPSO\nABC\nDE\nBP\nLM\nCancer\n1.42 \u00b1 1.05\n1.35 \u00b1 0.28\n2.01 \u00b1 0.86\n1.14 \u00b1 0.00\n1.19 \u00b1 0.28\n1.89 \u00b1 0.43\n8.18 \u00b1 10.29\nDiabetes\n24.43 \u00b1 4.65\n26.51 \u00b1 1.21\n27.50 \u00b1 2.05\n25.22 \u00b1 0.97\n24.84 \u00b1 1.32\n28.27 \u00b1 6.30\n29.80 \u00b1 3.77\nHeart\n20.02 \u00b1 1.60\n20.60 \u00b1 0.68\n21.87 \u00b1 1.45\n19.48 \u00b1 1.41\n20.33 \u00b1 1.29\n21.44 \u00b1 0.55\n24.96 \u00b1 7.40\nThyroid\n6.31 \u00b1 0.09\n7.09 \u00b1 0.03\n7.27 \u00b1 0.02\n6.95 \u00b1 0.01\n7.08 \u00b1 0.95\n7.26 \u00b1 0.00\n2.61 \u00b1 1.81\nGene\n30.05 \u00b1 1.89\n31.02 \u00b1 0.71\n36.30 \u00b1 2.10\n29.50 \u00b1 1.88\n31.18 \u00b1 2.18\n11.37 \u00b1 1.15\n14.35 \u00b1 2.48\nHorse\n27.56 \u00b1 6.22\n29.12 \u00b1 2.84\n31.14 \u00b1 3.94\n28.63 \u00b1 2.61\n29.29 \u00b1 2.72\n27.84 \u00b1 2.12\n33.79 \u00b1 4.50\nCard\n12.90 \u00b1 3.01\n13.56 \u00b1 1.21\n15.58 \u00b1 1.59\n13.53 \u00b1 1.17\n13.90 \u00b1 1.26\n13.86 \u00b1 0.47\n21.59 \u00b1 7.98\nGlass\n45.77 \u00b1 8.25\n50.18 \u00b1 3.15\n52.49 \u00b1 7.14\n45.62 \u00b1 3.11\n44.90 \u00b1 2.84\n59.09 \u00b1 9.52\n42.99 \u00b1 11.55\nSoybean\n36.42 \u00b1 6.84\n40.39 \u00b1 4.93\n60.50 \u00b1 8.50\n38.63 \u00b1 3.18\n74.90 \u00b1 2.10\n61.16 \u00b1 19.18\n25.51 \u00b1 9.89\nThe best value among all algorithms for each problem is indicated in bold\nGenerally speaking, among the bio-inspired training algo-\nrithms the proposed ACO training algorithm achieves the\nbest result for more datasets than its competitors, closely fol-\nlowed by the ABC training algorithm. Although ACO has\nbetter performance than ABC, the latter has better robust-\nness than ACO. This can be observed from the experimental\nresults, where ABC maintains lower standard deviation but\nhigher CEP, whereas ACO maintains higher standard devia-\ntion but lower CEP. Finally, LM and ACO training algorithms\nachieve the best results for three datasets among all training\nalgorithms, whereas ABC achieves the best results for the\nremaining two datasets.\n5 Conclusions\nThe connection weights in feed-forward neural networks are\nusually adjusted using gradient descent methods. Often such\nmethods may get trapped to local optima of the search land-\nscape. In this paper, an ACO training is proposed where a\npopulation of ants select different combinations for connec-\ntion weight values. A standalone ACO and a hybrid ACO-\nBP training are applied to train feed-forward neural net-\nworks for pattern classi\ufb01cation. Several real-world bench-\nmark problems are selected as test problems in the exper-\niments. The performance of ACO and ACO-BP training is\ncompared against: two traditional training methods (i.e., BP\nand LM), an ACO training without pheromone consideration\n(i.e., RCH), a standalone ACO and a hybrid ACO from the lit-\nerature (Socha and Blum 2007) (i.e., ACOR and ACOR-BP),\nrespectively, and four other nature-inspired training methods\n(i.e., GA, PSO, ABC and DE) from the literature (Ozturk and\nKaraboga 2009).\nFromtheexperimentalresults,severalconcludingremarks\ncan be drawn. First, ACO is a good choice for selecting\ngood values for the BP. The standalone ACO training is\noutperformed by the standalone ACOR training whereas the\nhybrid ACO-BP shows superior performance, especially on\nlarge problem instances. Second, the performance of gradient\ndescent methods is degraded as the problem size increases\nwhen compared with the hybrid ACO-BP training algorithm.\nThird, gradient descent methods usually have better perfor-\nmance than a standalone metaheuristic training, including\nACO training. This is because gradient descent methods are\nmore accurate than metaheuristic methods in terms of search-\ning. Finally, ACO has a relatively good performance when\ncompared with other metaheuristics in network training for\npattern classi\ufb01cation. However, different metaheuristics per-\nform better on different problem instances due to the problem\ndependency issue.\nIn general, the ACO metaheuristic can be a useful tech-\nnique in neural network training for pattern classi\ufb01cation\nespecially when it is hybridized with gradient descent train-\ning.\nFor future work, it will be interesting to apply LM as\na local search improvement with ACO, or even apply both\nBM and LM as local search improvements. Moreover, it will\nbe interesting to investigate ACO\u2019s training adaptability to a\ndynamic environment (Rakitianskaia and Engelbrecht 2012).\nAcknowledgments\nThe authors would like to thank the anonymous\nreviewers for their thoughtful suggestions and constructive comments.\nThis work was supported by the Engineering and Physical Sciences\nResearch Council (EPSRC) of UK under Grant EP/K001310/1.\nReferences\nAlba E, Chicano J (2004) Training neural networks with ga hybrid\nalgorithms. In: Deb K (ed) Proceedings of the 2004 Genetic and\nEvolutionary Computation Conference, vol 3102. LNCS, Springer,\nBerlin, pp 852\u2013863\nAlba E, Marti R (eds) (2006) Metaheuristic procedures for training\nneural networks. Springer, New York\nBache K, Lichman M (2013) UCI machine learning repository. http://\narchive.ics.uci.edu/ml\n123\n", []], "5 Conclusions": ["1520\nM. Mavrovouniotis, S. Yang\nTable 6 Comparison of the CEP results with their standard deviation of the proposed ACO training on a several benchmark datasets with the results\nof other bio-inspired training algorithms obtained from Ozturk and Karaboga (2009)\nProblem\nACO\nGA\nPSO\nABC\nDE\nBP\nLM\nCancer\n1.42 \u00b1 1.05\n1.35 \u00b1 0.28\n2.01 \u00b1 0.86\n1.14 \u00b1 0.00\n1.19 \u00b1 0.28\n1.89 \u00b1 0.43\n8.18 \u00b1 10.29\nDiabetes\n24.43 \u00b1 4.65\n26.51 \u00b1 1.21\n27.50 \u00b1 2.05\n25.22 \u00b1 0.97\n24.84 \u00b1 1.32\n28.27 \u00b1 6.30\n29.80 \u00b1 3.77\nHeart\n20.02 \u00b1 1.60\n20.60 \u00b1 0.68\n21.87 \u00b1 1.45\n19.48 \u00b1 1.41\n20.33 \u00b1 1.29\n21.44 \u00b1 0.55\n24.96 \u00b1 7.40\nThyroid\n6.31 \u00b1 0.09\n7.09 \u00b1 0.03\n7.27 \u00b1 0.02\n6.95 \u00b1 0.01\n7.08 \u00b1 0.95\n7.26 \u00b1 0.00\n2.61 \u00b1 1.81\nGene\n30.05 \u00b1 1.89\n31.02 \u00b1 0.71\n36.30 \u00b1 2.10\n29.50 \u00b1 1.88\n31.18 \u00b1 2.18\n11.37 \u00b1 1.15\n14.35 \u00b1 2.48\nHorse\n27.56 \u00b1 6.22\n29.12 \u00b1 2.84\n31.14 \u00b1 3.94\n28.63 \u00b1 2.61\n29.29 \u00b1 2.72\n27.84 \u00b1 2.12\n33.79 \u00b1 4.50\nCard\n12.90 \u00b1 3.01\n13.56 \u00b1 1.21\n15.58 \u00b1 1.59\n13.53 \u00b1 1.17\n13.90 \u00b1 1.26\n13.86 \u00b1 0.47\n21.59 \u00b1 7.98\nGlass\n45.77 \u00b1 8.25\n50.18 \u00b1 3.15\n52.49 \u00b1 7.14\n45.62 \u00b1 3.11\n44.90 \u00b1 2.84\n59.09 \u00b1 9.52\n42.99 \u00b1 11.55\nSoybean\n36.42 \u00b1 6.84\n40.39 \u00b1 4.93\n60.50 \u00b1 8.50\n38.63 \u00b1 3.18\n74.90 \u00b1 2.10\n61.16 \u00b1 19.18\n25.51 \u00b1 9.89\nThe best value among all algorithms for each problem is indicated in bold\nGenerally speaking, among the bio-inspired training algo-\nrithms the proposed ACO training algorithm achieves the\nbest result for more datasets than its competitors, closely fol-\nlowed by the ABC training algorithm. Although ACO has\nbetter performance than ABC, the latter has better robust-\nness than ACO. This can be observed from the experimental\nresults, where ABC maintains lower standard deviation but\nhigher CEP, whereas ACO maintains higher standard devia-\ntion but lower CEP. Finally, LM and ACO training algorithms\nachieve the best results for three datasets among all training\nalgorithms, whereas ABC achieves the best results for the\nremaining two datasets.\n5 Conclusions\nThe connection weights in feed-forward neural networks are\nusually adjusted using gradient descent methods. Often such\nmethods may get trapped to local optima of the search land-\nscape. In this paper, an ACO training is proposed where a\npopulation of ants select different combinations for connec-\ntion weight values. A standalone ACO and a hybrid ACO-\nBP training are applied to train feed-forward neural net-\nworks for pattern classi\ufb01cation. Several real-world bench-\nmark problems are selected as test problems in the exper-\niments. The performance of ACO and ACO-BP training is\ncompared against: two traditional training methods (i.e., BP\nand LM), an ACO training without pheromone consideration\n(i.e., RCH), a standalone ACO and a hybrid ACO from the lit-\nerature (Socha and Blum 2007) (i.e., ACOR and ACOR-BP),\nrespectively, and four other nature-inspired training methods\n(i.e., GA, PSO, ABC and DE) from the literature (Ozturk and\nKaraboga 2009).\nFromtheexperimentalresults,severalconcludingremarks\ncan be drawn. First, ACO is a good choice for selecting\ngood values for the BP. The standalone ACO training is\noutperformed by the standalone ACOR training whereas the\nhybrid ACO-BP shows superior performance, especially on\nlarge problem instances. Second, the performance of gradient\ndescent methods is degraded as the problem size increases\nwhen compared with the hybrid ACO-BP training algorithm.\nThird, gradient descent methods usually have better perfor-\nmance than a standalone metaheuristic training, including\nACO training. This is because gradient descent methods are\nmore accurate than metaheuristic methods in terms of search-\ning. Finally, ACO has a relatively good performance when\ncompared with other metaheuristics in network training for\npattern classi\ufb01cation. However, different metaheuristics per-\nform better on different problem instances due to the problem\ndependency issue.\nIn general, the ACO metaheuristic can be a useful tech-\nnique in neural network training for pattern classi\ufb01cation\nespecially when it is hybridized with gradient descent train-\ning.\nFor future work, it will be interesting to apply LM as\na local search improvement with ACO, or even apply both\nBM and LM as local search improvements. Moreover, it will\nbe interesting to investigate ACO\u2019s training adaptability to a\ndynamic environment (Rakitianskaia and Engelbrecht 2012).\nAcknowledgments\nThe authors would like to thank the anonymous\nreviewers for their thoughtful suggestions and constructive comments.\nThis work was supported by the Engineering and Physical Sciences\nResearch Council (EPSRC) of UK under Grant EP/K001310/1.\nReferences\nAlba E, Chicano J (2004) Training neural networks with ga hybrid\nalgorithms. In: Deb K (ed) Proceedings of the 2004 Genetic and\nEvolutionary Computation Conference, vol 3102. LNCS, Springer,\nBerlin, pp 852\u2013863\nAlba E, Marti R (eds) (2006) Metaheuristic procedures for training\nneural networks. Springer, New York\nBache K, Lichman M (2013) UCI machine learning repository. http://\narchive.ics.uci.edu/ml\n123\n", []], "4.4 Comparison with other bio-inspired and gradient descent training algorithms": ["Training neural networks with ACO algorithms for pattern classi\ufb01cation\n1519\nACO-BP algorithm outperforms both gradient descent tech-\nniques. This may be due to the dimension of the Heart data,\nwhich is signi\ufb01cantly larger than the other two datasets, and\nthus, the probability of an algorithm to get stuck in a local\noptima of the search landscape increases signi\ufb01cantly.\nGenerally speaking, the standalone BP training technique\nis usually outperformed by the hybrid ACO-BP training,\nespecially in the Heart dataset. This is probably because\nthe selected initial weights of the BP may lead to a poor\nlocal optimum as it was observed previously in Liu et al.\n(2006) and Mavrovouniotis and Yang (2013). It is interest-\ning to observe that the pheromone trail mechanism is use-\nful and improves the training process of the network. This\ncan be supported from the fact that the ACO training (with\npheromone trails) signi\ufb01cantly outperforms the RCH train-\ning (without pheromone trails) in all problems. Furthermore,\nthe standalone ACO training is outperformed by BP and LM\ntraining techniques since ACO does not perform trajectory\nsearching. Therefore, it is dif\ufb01cult to locate the optimum in a\nspeci\ufb01c neighbourhood accurately because it performs large-\nstep jumps in the search landscape. In contrast, ACO-BP\noutperforms both the standalone BP and ACO training tech-\nniques since it has less risk to get trapped in a local optima\nand improves the searching accuracy, simultaneously.\nFinally, if the CEP results of the testing over the training\ndatasets are compared, it can be seen that all the algorithms do\nnot suffer from strong over-\ufb01tting except LM in the Cancer\nand Heart datasets. ACO-BP suffers from slight over-\ufb01tting\nespecially in the Heart dataset. Probably, a different number\nof cross-validation experiments or different divisions of the\ndataset into training and testing sets may be necessary to\navoidover-\ufb01tting.Infact,theCEPresultsmaybefurthermore\nimproved when over-\ufb01tting is avoided.\n4.3 Comparison with other ACO training algorithms\nIt is interesting to compare the performance of the stand-\nalone ACO and hybrid ACO-BP training algorithms for\nneural networks with the corresponding continuous ACO\nvariations, denoted ACOR and ACOR-BP (Socha and Blum\n2007), respectively. The two existing training algorithms\nwere applied with the same stopping criteria (i.e., 1000 func-\ntion evaluations) and performed the same fourfold cross-\nvalidation with the proposed training algorithms.\nTable 5 summarizes the results obtained from ACOR and\nACOR-BP (Socha and Blum 2007) and pair-wisely compares\nthem with the proposed ACO and ACO-BP, respectively. The\nstandalone ACO has better performance than the standalone\nACOR in the Cancer problem instance, whereas the latter\nalgorithm has better performance than the former algorithm\nin the Diabetes and Heart problem instances, either signi\ufb01-\ncantly or insigni\ufb01cantly. In contrast, the hybrid ACO-BP has\nTable 5 Pairwise comparison of the CEP results of the proposed ACO\nand ACO-BP with the results of another existing ACO-based training\nobtained from Socha and Blum (2007)\nACO\nACOR\nACO-BP\nACOR-BP\nCancer\n3.66\n4.02\n2.87\n3.45\nDiabetes\n25.75\n24.48\n22.81\n23.96\nHeart\n21.68\n20.67\n16.78\n18.00\nThe best value from each pair (i.e., ACO with ACOR and ACO-BP with\nACOR-BP) for each problem is indicated in bold\nbetter performance than the hybrid ACOR-BP in all problem\ninstances.\n4.4 Comparison with other bio-inspired and gradient\ndescent training algorithms\nThe proposed ACO training is further compared with other\ntraining algorithms inspired from nature, such as the GA,\nPSO, ABC and DE algorithms and gradient descent training\nalgorithms, such as BP and LM. The aforementioned algo-\nrithms used for network training were applied with a different\nstopping criterion in Ozturk and Karaboga (2009), i.e., max-\nimum 2,000 function evaluations or when SEP \u22640.01 for\n50 runs.1 The same settings were applied to the proposed\nACO training for a fair comparison. Table 6 summarizes the\nresults of the training algorithms obtained from Ozturk and\nKaraboga (2009) together with our ACO training results. All\nthe algorithms are applied on a complete set of benchmark\ninstances described previously in Sect.4.1.1 and they use the\nsame network\u2019s architecture given in Table 1.\nACO performs better than the other bio-inspired algo-\nrithms on the Diabetes, Thyroid, Horse, Card and Soy-\nbean datasets. ABC outperforms its competitors on Cancer,\nHeart and Gene datasets, whereas DE obtains the best result\non Glass datasets. ACO performs better than the gradient\ndescent algorithms on the Diabetes, Horse and Card datasets,\nwhereas LM performs better on the Thyroid, Glass and Soy-\nbean datasets.\nOn most problems, the results are relatively close in\nterms of CEP, expect on Gene, Horse, Glass and Soybean\ndatasets. It is interesting to observe that most of these prob-\nlem instances, e.g., Gene, Horse and Soybean, are among the\nlargest problem instances according to the dimensions of the\nnetworks shown in Table 1. This further supports our obser-\nvation above that large problem instances are often dif\ufb01cult\nto classify due to the many possible local optima they might\ncontain.\n1 Ozturk and Karaboga (2009) performed only the \ufb01rst cross-validation\nof our fourfold cross-validation experiments. Therefore, the results of\nthe proposed ACO refer only to the \ufb01rst cross-validation dataset divi-\nsion.\n123\n", []], "4.3 Comparison with other ACO training algorithms": ["Training neural networks with ACO algorithms for pattern classi\ufb01cation\n1519\nACO-BP algorithm outperforms both gradient descent tech-\nniques. This may be due to the dimension of the Heart data,\nwhich is signi\ufb01cantly larger than the other two datasets, and\nthus, the probability of an algorithm to get stuck in a local\noptima of the search landscape increases signi\ufb01cantly.\nGenerally speaking, the standalone BP training technique\nis usually outperformed by the hybrid ACO-BP training,\nespecially in the Heart dataset. This is probably because\nthe selected initial weights of the BP may lead to a poor\nlocal optimum as it was observed previously in Liu et al.\n(2006) and Mavrovouniotis and Yang (2013). It is interest-\ning to observe that the pheromone trail mechanism is use-\nful and improves the training process of the network. This\ncan be supported from the fact that the ACO training (with\npheromone trails) signi\ufb01cantly outperforms the RCH train-\ning (without pheromone trails) in all problems. Furthermore,\nthe standalone ACO training is outperformed by BP and LM\ntraining techniques since ACO does not perform trajectory\nsearching. Therefore, it is dif\ufb01cult to locate the optimum in a\nspeci\ufb01c neighbourhood accurately because it performs large-\nstep jumps in the search landscape. In contrast, ACO-BP\noutperforms both the standalone BP and ACO training tech-\nniques since it has less risk to get trapped in a local optima\nand improves the searching accuracy, simultaneously.\nFinally, if the CEP results of the testing over the training\ndatasets are compared, it can be seen that all the algorithms do\nnot suffer from strong over-\ufb01tting except LM in the Cancer\nand Heart datasets. ACO-BP suffers from slight over-\ufb01tting\nespecially in the Heart dataset. Probably, a different number\nof cross-validation experiments or different divisions of the\ndataset into training and testing sets may be necessary to\navoidover-\ufb01tting.Infact,theCEPresultsmaybefurthermore\nimproved when over-\ufb01tting is avoided.\n4.3 Comparison with other ACO training algorithms\nIt is interesting to compare the performance of the stand-\nalone ACO and hybrid ACO-BP training algorithms for\nneural networks with the corresponding continuous ACO\nvariations, denoted ACOR and ACOR-BP (Socha and Blum\n2007), respectively. The two existing training algorithms\nwere applied with the same stopping criteria (i.e., 1000 func-\ntion evaluations) and performed the same fourfold cross-\nvalidation with the proposed training algorithms.\nTable 5 summarizes the results obtained from ACOR and\nACOR-BP (Socha and Blum 2007) and pair-wisely compares\nthem with the proposed ACO and ACO-BP, respectively. The\nstandalone ACO has better performance than the standalone\nACOR in the Cancer problem instance, whereas the latter\nalgorithm has better performance than the former algorithm\nin the Diabetes and Heart problem instances, either signi\ufb01-\ncantly or insigni\ufb01cantly. In contrast, the hybrid ACO-BP has\nTable 5 Pairwise comparison of the CEP results of the proposed ACO\nand ACO-BP with the results of another existing ACO-based training\nobtained from Socha and Blum (2007)\nACO\nACOR\nACO-BP\nACOR-BP\nCancer\n3.66\n4.02\n2.87\n3.45\nDiabetes\n25.75\n24.48\n22.81\n23.96\nHeart\n21.68\n20.67\n16.78\n18.00\nThe best value from each pair (i.e., ACO with ACOR and ACO-BP with\nACOR-BP) for each problem is indicated in bold\nbetter performance than the hybrid ACOR-BP in all problem\ninstances.\n4.4 Comparison with other bio-inspired and gradient\ndescent training algorithms\nThe proposed ACO training is further compared with other\ntraining algorithms inspired from nature, such as the GA,\nPSO, ABC and DE algorithms and gradient descent training\nalgorithms, such as BP and LM. The aforementioned algo-\nrithms used for network training were applied with a different\nstopping criterion in Ozturk and Karaboga (2009), i.e., max-\nimum 2,000 function evaluations or when SEP \u22640.01 for\n50 runs.1 The same settings were applied to the proposed\nACO training for a fair comparison. Table 6 summarizes the\nresults of the training algorithms obtained from Ozturk and\nKaraboga (2009) together with our ACO training results. All\nthe algorithms are applied on a complete set of benchmark\ninstances described previously in Sect.4.1.1 and they use the\nsame network\u2019s architecture given in Table 1.\nACO performs better than the other bio-inspired algo-\nrithms on the Diabetes, Thyroid, Horse, Card and Soy-\nbean datasets. ABC outperforms its competitors on Cancer,\nHeart and Gene datasets, whereas DE obtains the best result\non Glass datasets. ACO performs better than the gradient\ndescent algorithms on the Diabetes, Horse and Card datasets,\nwhereas LM performs better on the Thyroid, Glass and Soy-\nbean datasets.\nOn most problems, the results are relatively close in\nterms of CEP, expect on Gene, Horse, Glass and Soybean\ndatasets. It is interesting to observe that most of these prob-\nlem instances, e.g., Gene, Horse and Soybean, are among the\nlargest problem instances according to the dimensions of the\nnetworks shown in Table 1. This further supports our obser-\nvation above that large problem instances are often dif\ufb01cult\nto classify due to the many possible local optima they might\ncontain.\n1 Ozturk and Karaboga (2009) performed only the \ufb01rst cross-validation\nof our fourfold cross-validation experiments. Therefore, the results of\nthe proposed ACO refer only to the \ufb01rst cross-validation dataset divi-\nsion.\n123\n", []], "4.2 Analysis of the ACO training results": ["Training neural networks with ACO algorithms for pattern classi\ufb01cation\n1517\nTable 2 Parameter settings for the algorithms investigated on three datasets from the medical \ufb01eld used in the basic experiments\nAlgorithm\nCancer\nDiabetes\nHeart\nm\nq\n\u03c1\n\u03b7\n\u03b2\nm\nq\n\u03c1\n\u03b7\n\u03b2\nm\nq\n\u03c1\n\u03b7\n\u03b2\nACO\n2\n0.05\n0.3\n\u2013\n\u2013\n2\n0.05\n0.3\n\u2013\n\u2013\n2\n0.05\n0.3\n\u2013\n\u2013\nACO-BP\n2\n0.05\n0.3\n0.01\n\u2013\n2\n0.05\n0.3\n0.01\n\u2013\n2\n0.05\n0.3\n0.01\n\u2013\nBP\n\u2013\n\u2013\n\u2013\n0.002\n\u2013\n\u2013\n\u2013\n\u2013\n0.01\n\u2013\n\u2013\n\u2013\n\u2013\n0.001\n\u2013\nLM\n\u2013\n\u2013\n\u2013\n\u2013\n50\n\u2013\n\u2013\n\u2013\n\u2013\n5\n\u2013\n\u2013\n\u2013\n\u2013\n1.5\nRCH\n2\n0.0\n\u2013\n\u2013\n\u2013\n2\n0.0\n\u2013\n\u2013\n\u2013\n2\n0.0\n\u2013\n\u2013\n\u2013\nThe data contain 314 patterns, each of which consists of\n58 inputs and 3 outputs.\n\u2013 Card: Contains real credit card application (unexplained\nfor con\ufb01dence reasons) used to predict whether the bank\ngranted the credit card or not. It contains 690 patterns,\neach of which consists of 51 inputs and 2 outputs.\n\u2013 Glass: Based on the results of a chemical analysis of\nglass splinters which is used to classify different glass\ntypes, e.g., building windows, vehicle windows, and so\non. It consists of 214 patterns, each of which consists\nof 9 inputs and 6 outputs. The number of patterns that\nrepresent different classes are not even, since the sizes of\nthe six classes are 70, 76, 17, 13, 9 and 29, respectively.\n\u2013 Soybean: Based on a description of the bean, the plant\nand the plant\u2019s life. For example, whether the bean size\nand colour are normal or whether the seed of the plant\nwas treated, and so on. It consists of 683 patterns, each\nof which consists of 35 inputs and 19 outputs.\nSince cross-validation is used, the \ufb01rst 75% patterns of a\ndataset is used as the training dataset and the remaining 25%\nis used as the testing dataset. Table 1 indicates the division\nof the training and testing dataset. For each experiment in\ncross-validation, the same sizes of the datasets are used.\n4.1.2 Parameter settings\nThe structure of the networks is inspired by the literature\n(Socha and Blum 2007; Alba and Chicano 2004; Ozturk and\nKaraboga 2009; Mavrovouniotis and Yang 2013) and is given\nin Table 1. The network architecture for each benchmark\nproblem consists of one input layer, one hidden layer, and\none output layer. The number of sigmoid units for each layer\nis shown in the format input\u2013hidden\u2013output. The dimension\nde\ufb01nes the number of connection weights within a network\ncalculated in Eq. 4. The reason that the speci\ufb01c structures are\nused is for the convenience to later on compare the results\nof the proposed algorithms with the results of another ACO\ntraining algorithm (Socha and Blum 2007) and other bio-\ninspired training algorithms (Ozturk and Karaboga 2009),\nwhich have used the same network architectures on the same\ncross-validation experiments. Therefore, a fair comparison\nbetween the results of the proposed ACO training algorithm\nwith other existing results can be given.\nThe parameters of the aforementioned algorithms used\nfor the three benchmark problems, i.e., Cancer, Diabetes\nand Heart, were mainly inspired by the literature (Socha and\nBlum 2007; Mavrovouniotis and Yang 2013). They are pre-\nsentedinTable2, wherem is theant populationsize,q de\ufb01nes\nthe exploration of the solution construction and \u03c1 is the evap-\noration rate for ACO-based algorithms, \u03b7 is the learning rate\nfor BP, and \u03b2 is the factor for LM. Not included in the table\nis the parameter d for ACO, ACO-BP and RCH, which is\nset to d = 30 for all problems and de\ufb01nes the number of\ndiscrete points for connection weights. Note that RCH does\nnot have an evaporation rate because pheromone trails are\nnot considered during the solution construction.\n4.2 Analysis of the ACO training results\nThe experimental results of the algorithms on three bench-\nmark problems taken from the medical \ufb01eld regarding CEP\nare presented in box-plots in Fig. 4a\u2013c, for the datasets Can-\ncer, Diabetes, and Heart, respectively. Each \ufb01gure illustrates\nthe distribution of the CEP values, averaged for all four-\nfold cross-validation experiments, between the \ufb01rst and third\nquartiles. The corresponding Wilcoxon rank sum statistical\nresults (with Bonferroni correction) of the algorithms on\nthe testing datasets are presented in Table 3. Finally, the\nCEP results on both testing and training datasets, for each\nalgorithm of all fourfold cross-validation experiments, are\npresented in Table 4. From the experimental results several\nobservations can be drawn.\nThe Cancer problem (see Fig. 4a; Table 3) appears to be an\neasy dataset to classify. All algorithms, including the RCH\ntraining method, have good performance. The fact that RCH\nhas reasonably good CEP, even if it is the worst perform-\ning algorithm, supports the claim that the dataset is easy to\nclassify. However, none of the algorithms was able to clas-\nsify all the patterns from the testing dataset correctly, which\nis probably due to the limited size of the training set. The\nbest performing algorithm is ACO-BP, which signi\ufb01cantly\n123\n", []], "4.1.2 Parameter settings": ["Training neural networks with ACO algorithms for pattern classi\ufb01cation\n1517\nTable 2 Parameter settings for the algorithms investigated on three datasets from the medical \ufb01eld used in the basic experiments\nAlgorithm\nCancer\nDiabetes\nHeart\nm\nq\n\u03c1\n\u03b7\n\u03b2\nm\nq\n\u03c1\n\u03b7\n\u03b2\nm\nq\n\u03c1\n\u03b7\n\u03b2\nACO\n2\n0.05\n0.3\n\u2013\n\u2013\n2\n0.05\n0.3\n\u2013\n\u2013\n2\n0.05\n0.3\n\u2013\n\u2013\nACO-BP\n2\n0.05\n0.3\n0.01\n\u2013\n2\n0.05\n0.3\n0.01\n\u2013\n2\n0.05\n0.3\n0.01\n\u2013\nBP\n\u2013\n\u2013\n\u2013\n0.002\n\u2013\n\u2013\n\u2013\n\u2013\n0.01\n\u2013\n\u2013\n\u2013\n\u2013\n0.001\n\u2013\nLM\n\u2013\n\u2013\n\u2013\n\u2013\n50\n\u2013\n\u2013\n\u2013\n\u2013\n5\n\u2013\n\u2013\n\u2013\n\u2013\n1.5\nRCH\n2\n0.0\n\u2013\n\u2013\n\u2013\n2\n0.0\n\u2013\n\u2013\n\u2013\n2\n0.0\n\u2013\n\u2013\n\u2013\nThe data contain 314 patterns, each of which consists of\n58 inputs and 3 outputs.\n\u2013 Card: Contains real credit card application (unexplained\nfor con\ufb01dence reasons) used to predict whether the bank\ngranted the credit card or not. It contains 690 patterns,\neach of which consists of 51 inputs and 2 outputs.\n\u2013 Glass: Based on the results of a chemical analysis of\nglass splinters which is used to classify different glass\ntypes, e.g., building windows, vehicle windows, and so\non. It consists of 214 patterns, each of which consists\nof 9 inputs and 6 outputs. The number of patterns that\nrepresent different classes are not even, since the sizes of\nthe six classes are 70, 76, 17, 13, 9 and 29, respectively.\n\u2013 Soybean: Based on a description of the bean, the plant\nand the plant\u2019s life. For example, whether the bean size\nand colour are normal or whether the seed of the plant\nwas treated, and so on. It consists of 683 patterns, each\nof which consists of 35 inputs and 19 outputs.\nSince cross-validation is used, the \ufb01rst 75% patterns of a\ndataset is used as the training dataset and the remaining 25%\nis used as the testing dataset. Table 1 indicates the division\nof the training and testing dataset. For each experiment in\ncross-validation, the same sizes of the datasets are used.\n4.1.2 Parameter settings\nThe structure of the networks is inspired by the literature\n(Socha and Blum 2007; Alba and Chicano 2004; Ozturk and\nKaraboga 2009; Mavrovouniotis and Yang 2013) and is given\nin Table 1. The network architecture for each benchmark\nproblem consists of one input layer, one hidden layer, and\none output layer. The number of sigmoid units for each layer\nis shown in the format input\u2013hidden\u2013output. The dimension\nde\ufb01nes the number of connection weights within a network\ncalculated in Eq. 4. The reason that the speci\ufb01c structures are\nused is for the convenience to later on compare the results\nof the proposed algorithms with the results of another ACO\ntraining algorithm (Socha and Blum 2007) and other bio-\ninspired training algorithms (Ozturk and Karaboga 2009),\nwhich have used the same network architectures on the same\ncross-validation experiments. Therefore, a fair comparison\nbetween the results of the proposed ACO training algorithm\nwith other existing results can be given.\nThe parameters of the aforementioned algorithms used\nfor the three benchmark problems, i.e., Cancer, Diabetes\nand Heart, were mainly inspired by the literature (Socha and\nBlum 2007; Mavrovouniotis and Yang 2013). They are pre-\nsentedinTable2, wherem is theant populationsize,q de\ufb01nes\nthe exploration of the solution construction and \u03c1 is the evap-\noration rate for ACO-based algorithms, \u03b7 is the learning rate\nfor BP, and \u03b2 is the factor for LM. Not included in the table\nis the parameter d for ACO, ACO-BP and RCH, which is\nset to d = 30 for all problems and de\ufb01nes the number of\ndiscrete points for connection weights. Note that RCH does\nnot have an evaporation rate because pheromone trails are\nnot considered during the solution construction.\n4.2 Analysis of the ACO training results\nThe experimental results of the algorithms on three bench-\nmark problems taken from the medical \ufb01eld regarding CEP\nare presented in box-plots in Fig. 4a\u2013c, for the datasets Can-\ncer, Diabetes, and Heart, respectively. Each \ufb01gure illustrates\nthe distribution of the CEP values, averaged for all four-\nfold cross-validation experiments, between the \ufb01rst and third\nquartiles. The corresponding Wilcoxon rank sum statistical\nresults (with Bonferroni correction) of the algorithms on\nthe testing datasets are presented in Table 3. Finally, the\nCEP results on both testing and training datasets, for each\nalgorithm of all fourfold cross-validation experiments, are\npresented in Table 4. From the experimental results several\nobservations can be drawn.\nThe Cancer problem (see Fig. 4a; Table 3) appears to be an\neasy dataset to classify. All algorithms, including the RCH\ntraining method, have good performance. The fact that RCH\nhas reasonably good CEP, even if it is the worst perform-\ning algorithm, supports the claim that the dataset is easy to\nclassify. However, none of the algorithms was able to clas-\nsify all the patterns from the testing dataset correctly, which\nis probably due to the limited size of the training set. The\nbest performing algorithm is ACO-BP, which signi\ufb01cantly\n123\n", []], "4.1.1 Benchmark problems": ["1516\nM. Mavrovouniotis, S. Yang\nTable 1 Structure and dimension of feed-forward neural networks\ntogether with the set division of the different benchmark problems used\nin the experiments\nProblem\nStructure\nDimension\nTraining\nTesting\nCancer\n9-6-2\n74\n525\n174\nDiabetes\n8-6-2\n68\n576\n192\nHeart\n35-6-2\n230\n690\n230\nThyroid\n21-6-3\n153\n5400\n1800\nGene\n120-6-3\n747\n2382\n793\nHorse\n58-6-3\n375\n273\n91\nCard\n51-6-2\n326\n518\n172\nGlass\n9-6-6\n102\n161\n53\nSoybean\n82-6-19\n631\n513\n170\n4. Random constructive heuristic (RCH): this algorithm\nconstructs solutions at each iteration in the same way\nas ACO but without any pheromone trail reinforcement.\nNext, the second part of the experimental study (see\nSubsect. 4.3) is used to compare the proposed ACO training\nwith ACOR (Socha and Blum 2007), an existing ACO\ntraining from the literature that does not follow the original\nACO framework. The aim of these two experimental studies\nis to investigate the effect of pheromone trails on the train-\ning of feed-forward neural networks. Hence, a partial set\ncontaining the most commonly used benchmark instances\nis used. Finally, the third part of the experimental study\n(see Subsect. 4.4) is used to compare the proposed ACO\ntraining against other nature-inspired metaheuristics used\nfor training feed-forward neural networks on the complete\nset of benchmark instances.\nAll the algorithms perform 1,000 function evaluations to\nhave a fair comparison. A fourfold cross-validation is used,\nwhere a set of patterns is divided into four equal subsets.\nThen, four experiments are performed where one subset is\nused as the testing dataset (patterns that the network has never\nseen before) and the remaining subsets are used as the train-\ning dataset.\nThe classi\ufb01cation error percentage (CEP) for a single\nexperiment from the four cross-validation experiments is\ncomputed as follows:\nCEP = 100# of misclassi\ufb01ed patterns\n# of testing patterns\n(10)\nand the result of the set division between the training and\ntesting dataset is averaged over 50 independent runs on a set\nof different random seeds.\n4.1.1 Benchmark problems\nThe aim of classi\ufb01cation problems is to determine the class\nthat a certain pattern belongs to. Each pattern within a prob-\nlem instance consists of an input and an output vector formed\nby real numbers. To interpret the output of the classi\ufb01ca-\ntion problem, the winner-takes-all method is used. More pre-\ncisely, an output unit is associated with each different class.\nTherefore, when an input vector is pushed in the neural net-\nwork, the network\u2019s classi\ufb01cation result is pulled out from\nthe output unit with the larger value.\nDifferent real-world benchmark datasets taken from the\nUCIrepository(BacheandLichman2013;Prechelt1994)are\nused in this study. The \ufb01rst six benchmark problems rise from\nthe medical \ufb01eld whereas the remaining three from other\nscienti\ufb01c \ufb01elds. They are described as follows:\n\u2013 Cancer: Taken from a database of diagnostics of breast\ncancer obtained by Dr. William H. Wolberg from the Uni-\nversity of Wisconsin Hospitals, Madison (Bennett and\nMangasarian 1992; Mangasarian et al. 1990; Wolberg\n1990; 1990). It consists of 699 patterns, each of which\nconsists of 9 inputs and 2 outputs.\n\u2013 Diabetes: Based on personal data and medical examina-\ntions which decide whether a Pima Indian is diabetes or\nnot. The dataset contains a redundancy of senseless 0\nvalues that most probably indicate missing or noisy data.\nIt consists of 768 patterns, each of which consists of 8\ninputs and 2 outputs.\n\u2013 Heart: Based on medical examinations which predict\nheart disease obtained from four different sources: (1)\nHungarian Institute of Cardiology, Budapest (Andras\nJanosi, M.D.); (2) University Hospital, Zurich, Switzer-\nland (William Steinbrunn, M.D.); (3) University Hospi-\ntal, Basel, Switzerland (Matthias P\ufb01sterer, M.D.); and (4)\nV.A. Medical Center, Long Beach and Cleveland Clinic\nFoundation (Robert Detrano, M.D., Ph.D.) (Detrano et al.\n1989; Gennari et al. 1989). More precisely, the dataset\ndecides whether at least one of four major vessels is\nreduced in diameter by more than 50%. It consists of\n920 patterns, each of which consists of 35 inputs and 2\noutputs.\n\u2013 Thyroid: Based on patient query and patient examina-\ntion data. This dataset is used to diagnose thyroid hyper-\nor hypo-function. It consists of 7200 patterns, each of\nwhich has 21 inputs and 3 outputs representing whether\nthe patient\u2019s thyroid has overfunction, normal function,\nor underfunction.\n\u2013 Gene: Contains data from a window of 60 DNA sequence\nelements and has two different classes, i.e., donor or\nacceptor. It is used to predict whether the middle of the\nsequence is a donor, an acceptor, or none of these. It\nconsists of 3,175 patterns, each of which consists of 120\ninput and 3 outputs.\n\u2013 Horse: Based on the veterinary examination results of\na horse having a colic. This dataset is used to predict\nwhether the horse will survive, die, or be euthanized.\n123\n", []], "4.1 Experimental setup": ["Training neural networks with ACO algorithms for pattern classi\ufb01cation\n1515\nFig. 3 Solution construction of an ant that has already selected values\nai1h and ai2h for connection weights wi1 and wi2, respectively, which\nare stored in the ant\u2019s memory\npoints is repeated until all ants have selected values for all l\nconnection weights.\n3.3 Pheromone update policy\nWhen all ants choose a value for each connection weight,\nincluding the bias weight, the pheromone update procedure\nstarts. Only the best ant retraces its values selected for each\nweight in the construction phase and deposits pheromone as:\n\u03c4i jh \u2190\u03c4i jh + \u0004\u03c4 best\ni jh ,\n\u2200ai jh \u2208T best,\n(7)\nwhere T best is the combination of discrete points selected by\nthe best-so-far ant and \u0004\u03c4 best\ni jh is the amount of pheromone to\nbe deposited, which is de\ufb01ned as follows:\n\u0004\u03c4 best\ni jh = 1/Ebest,\n(8)\nwhere Ebest is the network error of the T best combination,\nas de\ufb01ned in Eq. 2. Hence, the less network error, the more\npheromone is deposited since the inverse of the network error\nis considered.\nFurthermore, pheromone evaporation is applied to reduce\nall pheromone trails as follows:\n\u03c4i jh \u2190(1 \u2212\u03c1)\u03c4i jh,\n\u2200ai jh,\n(9)\nwhere \u03c1 \u2208(0, 1) is a constant that de\ufb01nes the pheromone\nevaporation rate. The pheromone evaporation helps to elim-\ninate bad decisions made in the past.\nWithin\nthe\nproposed\nACO\ntraining,\nthe\npossible\npheromone trail values are limited to the range [\u03c4min, \u03c4max],\nwhere \u03c4max = 1/(\u03c1Ebest) is the maximum pheromone trail\nlimit, \u03c1 is de\ufb01ned in Eq. 9, Ebest is the network error of\nthe best combination, \u03c4min = \u03c4max/(2l) is the minimum\npheromone trail limit, and l is as de\ufb01ned in Eq. 4.\nThe differences between the proposed ACO training and\nthe one described in Liu et al. (2006) are (a) only the best-so-\nfar ant is allowed to deposit pheromone and (b) pheromone\ntrail limits are imposed. It is very important to keep the max-\nimum and minimum pheromone trail values at a closer range\nto eliminate the high intensity of pheromone trails that may\nbias ants to search at non-promising areas. In fact, the experi-\nments in Mavrovouniotis and Yang (2013) support this claim.\n3.4 Local search improvements\nMetaheuristics (such as ACO), which do not consider any\ngradient descent information when training a network, may\nnot be as accurate as those methods that use this informa-\ntion. Therefore, when an ant constructs a solution, a gradient\ndescent approach can be applied to improve the accuracy of\nACO training.\nGradient descent methods perform small step jumps to a\nneighbourhood of the search landscape and, thus, can locate\nthe optimum nearby. However, the (local) optimum located\nmay be far from the global optimum. In contrast, ACO per-\nforms large-step jumps and is more dif\ufb01cult to reach the opti-\nmum in a neighbourhood. However, ACO is more likely to\ndiscover different neighbourhoods than a gradient descent\nmethod due to its stochastic components.\nConsidering both aspects, a hybrid training method can be\napplied:theACOtrainingcanbeusedtodiscoverapromising\nneighbourhood, possibly containing the global optimum, in\nthe search space, and the gradient descent training can be\nused to locate the optimum in that speci\ufb01c neighbourhood.\n4 Experimental study\n4.1 Experimental setup\nTo evaluate the performance of the proposed ACO training\nalgorithm, it is compared with other algorithms in training\nfeed-forward neural networks for solving different bench-\nmark classi\ufb01cation problems (Prechelt 1994). The details\nregarding the con\ufb01guration of the networks and datasets used\nfordifferentproblemsareshowninTable1.Theexperimental\nstudy is divided into three parts. The algorithms implemented\nand compared in the \ufb01rst part of the experimental study (see\nSubsect. 4.2) include the following:\n1. Back-propagation (BP) (Rumelhart et al. 1986): the basic\nback-propagation training without any acceleration or\nother tweaking techniques such as momentum and so on.\n2. Levenberg\u2013Marquardt (LM) (Hagan and Menhaj 1994):\nthe standard Levenberg\u2013Marquardt training, which is\nanother gradient descent algorithm.\n3. ACO-BP: the proposed ACO training algorithm with the\ncombination of back-propagation, where each solution\nconstructed by ACO undergoes a local search improve-\nment by back-propagation.\n123\n", [169]], "4 Experimental study": ["Training neural networks with ACO algorithms for pattern classi\ufb01cation\n1515\nFig. 3 Solution construction of an ant that has already selected values\nai1h and ai2h for connection weights wi1 and wi2, respectively, which\nare stored in the ant\u2019s memory\npoints is repeated until all ants have selected values for all l\nconnection weights.\n3.3 Pheromone update policy\nWhen all ants choose a value for each connection weight,\nincluding the bias weight, the pheromone update procedure\nstarts. Only the best ant retraces its values selected for each\nweight in the construction phase and deposits pheromone as:\n\u03c4i jh \u2190\u03c4i jh + \u0004\u03c4 best\ni jh ,\n\u2200ai jh \u2208T best,\n(7)\nwhere T best is the combination of discrete points selected by\nthe best-so-far ant and \u0004\u03c4 best\ni jh is the amount of pheromone to\nbe deposited, which is de\ufb01ned as follows:\n\u0004\u03c4 best\ni jh = 1/Ebest,\n(8)\nwhere Ebest is the network error of the T best combination,\nas de\ufb01ned in Eq. 2. Hence, the less network error, the more\npheromone is deposited since the inverse of the network error\nis considered.\nFurthermore, pheromone evaporation is applied to reduce\nall pheromone trails as follows:\n\u03c4i jh \u2190(1 \u2212\u03c1)\u03c4i jh,\n\u2200ai jh,\n(9)\nwhere \u03c1 \u2208(0, 1) is a constant that de\ufb01nes the pheromone\nevaporation rate. The pheromone evaporation helps to elim-\ninate bad decisions made in the past.\nWithin\nthe\nproposed\nACO\ntraining,\nthe\npossible\npheromone trail values are limited to the range [\u03c4min, \u03c4max],\nwhere \u03c4max = 1/(\u03c1Ebest) is the maximum pheromone trail\nlimit, \u03c1 is de\ufb01ned in Eq. 9, Ebest is the network error of\nthe best combination, \u03c4min = \u03c4max/(2l) is the minimum\npheromone trail limit, and l is as de\ufb01ned in Eq. 4.\nThe differences between the proposed ACO training and\nthe one described in Liu et al. (2006) are (a) only the best-so-\nfar ant is allowed to deposit pheromone and (b) pheromone\ntrail limits are imposed. It is very important to keep the max-\nimum and minimum pheromone trail values at a closer range\nto eliminate the high intensity of pheromone trails that may\nbias ants to search at non-promising areas. In fact, the experi-\nments in Mavrovouniotis and Yang (2013) support this claim.\n3.4 Local search improvements\nMetaheuristics (such as ACO), which do not consider any\ngradient descent information when training a network, may\nnot be as accurate as those methods that use this informa-\ntion. Therefore, when an ant constructs a solution, a gradient\ndescent approach can be applied to improve the accuracy of\nACO training.\nGradient descent methods perform small step jumps to a\nneighbourhood of the search landscape and, thus, can locate\nthe optimum nearby. However, the (local) optimum located\nmay be far from the global optimum. In contrast, ACO per-\nforms large-step jumps and is more dif\ufb01cult to reach the opti-\nmum in a neighbourhood. However, ACO is more likely to\ndiscover different neighbourhoods than a gradient descent\nmethod due to its stochastic components.\nConsidering both aspects, a hybrid training method can be\napplied:theACOtrainingcanbeusedtodiscoverapromising\nneighbourhood, possibly containing the global optimum, in\nthe search space, and the gradient descent training can be\nused to locate the optimum in that speci\ufb01c neighbourhood.\n4 Experimental study\n4.1 Experimental setup\nTo evaluate the performance of the proposed ACO training\nalgorithm, it is compared with other algorithms in training\nfeed-forward neural networks for solving different bench-\nmark classi\ufb01cation problems (Prechelt 1994). The details\nregarding the con\ufb01guration of the networks and datasets used\nfordifferentproblemsareshowninTable1.Theexperimental\nstudy is divided into three parts. The algorithms implemented\nand compared in the \ufb01rst part of the experimental study (see\nSubsect. 4.2) include the following:\n1. Back-propagation (BP) (Rumelhart et al. 1986): the basic\nback-propagation training without any acceleration or\nother tweaking techniques such as momentum and so on.\n2. Levenberg\u2013Marquardt (LM) (Hagan and Menhaj 1994):\nthe standard Levenberg\u2013Marquardt training, which is\nanother gradient descent algorithm.\n3. ACO-BP: the proposed ACO training algorithm with the\ncombination of back-propagation, where each solution\nconstructed by ACO undergoes a local search improve-\nment by back-propagation.\n123\n", [169]], "3.4 Local search improvements": ["Training neural networks with ACO algorithms for pattern classi\ufb01cation\n1515\nFig. 3 Solution construction of an ant that has already selected values\nai1h and ai2h for connection weights wi1 and wi2, respectively, which\nare stored in the ant\u2019s memory\npoints is repeated until all ants have selected values for all l\nconnection weights.\n3.3 Pheromone update policy\nWhen all ants choose a value for each connection weight,\nincluding the bias weight, the pheromone update procedure\nstarts. Only the best ant retraces its values selected for each\nweight in the construction phase and deposits pheromone as:\n\u03c4i jh \u2190\u03c4i jh + \u0004\u03c4 best\ni jh ,\n\u2200ai jh \u2208T best,\n(7)\nwhere T best is the combination of discrete points selected by\nthe best-so-far ant and \u0004\u03c4 best\ni jh is the amount of pheromone to\nbe deposited, which is de\ufb01ned as follows:\n\u0004\u03c4 best\ni jh = 1/Ebest,\n(8)\nwhere Ebest is the network error of the T best combination,\nas de\ufb01ned in Eq. 2. Hence, the less network error, the more\npheromone is deposited since the inverse of the network error\nis considered.\nFurthermore, pheromone evaporation is applied to reduce\nall pheromone trails as follows:\n\u03c4i jh \u2190(1 \u2212\u03c1)\u03c4i jh,\n\u2200ai jh,\n(9)\nwhere \u03c1 \u2208(0, 1) is a constant that de\ufb01nes the pheromone\nevaporation rate. The pheromone evaporation helps to elim-\ninate bad decisions made in the past.\nWithin\nthe\nproposed\nACO\ntraining,\nthe\npossible\npheromone trail values are limited to the range [\u03c4min, \u03c4max],\nwhere \u03c4max = 1/(\u03c1Ebest) is the maximum pheromone trail\nlimit, \u03c1 is de\ufb01ned in Eq. 9, Ebest is the network error of\nthe best combination, \u03c4min = \u03c4max/(2l) is the minimum\npheromone trail limit, and l is as de\ufb01ned in Eq. 4.\nThe differences between the proposed ACO training and\nthe one described in Liu et al. (2006) are (a) only the best-so-\nfar ant is allowed to deposit pheromone and (b) pheromone\ntrail limits are imposed. It is very important to keep the max-\nimum and minimum pheromone trail values at a closer range\nto eliminate the high intensity of pheromone trails that may\nbias ants to search at non-promising areas. In fact, the experi-\nments in Mavrovouniotis and Yang (2013) support this claim.\n3.4 Local search improvements\nMetaheuristics (such as ACO), which do not consider any\ngradient descent information when training a network, may\nnot be as accurate as those methods that use this informa-\ntion. Therefore, when an ant constructs a solution, a gradient\ndescent approach can be applied to improve the accuracy of\nACO training.\nGradient descent methods perform small step jumps to a\nneighbourhood of the search landscape and, thus, can locate\nthe optimum nearby. However, the (local) optimum located\nmay be far from the global optimum. In contrast, ACO per-\nforms large-step jumps and is more dif\ufb01cult to reach the opti-\nmum in a neighbourhood. However, ACO is more likely to\ndiscover different neighbourhoods than a gradient descent\nmethod due to its stochastic components.\nConsidering both aspects, a hybrid training method can be\napplied:theACOtrainingcanbeusedtodiscoverapromising\nneighbourhood, possibly containing the global optimum, in\nthe search space, and the gradient descent training can be\nused to locate the optimum in that speci\ufb01c neighbourhood.\n4 Experimental study\n4.1 Experimental setup\nTo evaluate the performance of the proposed ACO training\nalgorithm, it is compared with other algorithms in training\nfeed-forward neural networks for solving different bench-\nmark classi\ufb01cation problems (Prechelt 1994). The details\nregarding the con\ufb01guration of the networks and datasets used\nfordifferentproblemsareshowninTable1.Theexperimental\nstudy is divided into three parts. The algorithms implemented\nand compared in the \ufb01rst part of the experimental study (see\nSubsect. 4.2) include the following:\n1. Back-propagation (BP) (Rumelhart et al. 1986): the basic\nback-propagation training without any acceleration or\nother tweaking techniques such as momentum and so on.\n2. Levenberg\u2013Marquardt (LM) (Hagan and Menhaj 1994):\nthe standard Levenberg\u2013Marquardt training, which is\nanother gradient descent algorithm.\n3. ACO-BP: the proposed ACO training algorithm with the\ncombination of back-propagation, where each solution\nconstructed by ACO undergoes a local search improve-\nment by back-propagation.\n123\n", [169]], "3.3 Pheromone update policy": ["Training neural networks with ACO algorithms for pattern classi\ufb01cation\n1515\nFig. 3 Solution construction of an ant that has already selected values\nai1h and ai2h for connection weights wi1 and wi2, respectively, which\nare stored in the ant\u2019s memory\npoints is repeated until all ants have selected values for all l\nconnection weights.\n3.3 Pheromone update policy\nWhen all ants choose a value for each connection weight,\nincluding the bias weight, the pheromone update procedure\nstarts. Only the best ant retraces its values selected for each\nweight in the construction phase and deposits pheromone as:\n\u03c4i jh \u2190\u03c4i jh + \u0004\u03c4 best\ni jh ,\n\u2200ai jh \u2208T best,\n(7)\nwhere T best is the combination of discrete points selected by\nthe best-so-far ant and \u0004\u03c4 best\ni jh is the amount of pheromone to\nbe deposited, which is de\ufb01ned as follows:\n\u0004\u03c4 best\ni jh = 1/Ebest,\n(8)\nwhere Ebest is the network error of the T best combination,\nas de\ufb01ned in Eq. 2. Hence, the less network error, the more\npheromone is deposited since the inverse of the network error\nis considered.\nFurthermore, pheromone evaporation is applied to reduce\nall pheromone trails as follows:\n\u03c4i jh \u2190(1 \u2212\u03c1)\u03c4i jh,\n\u2200ai jh,\n(9)\nwhere \u03c1 \u2208(0, 1) is a constant that de\ufb01nes the pheromone\nevaporation rate. The pheromone evaporation helps to elim-\ninate bad decisions made in the past.\nWithin\nthe\nproposed\nACO\ntraining,\nthe\npossible\npheromone trail values are limited to the range [\u03c4min, \u03c4max],\nwhere \u03c4max = 1/(\u03c1Ebest) is the maximum pheromone trail\nlimit, \u03c1 is de\ufb01ned in Eq. 9, Ebest is the network error of\nthe best combination, \u03c4min = \u03c4max/(2l) is the minimum\npheromone trail limit, and l is as de\ufb01ned in Eq. 4.\nThe differences between the proposed ACO training and\nthe one described in Liu et al. (2006) are (a) only the best-so-\nfar ant is allowed to deposit pheromone and (b) pheromone\ntrail limits are imposed. It is very important to keep the max-\nimum and minimum pheromone trail values at a closer range\nto eliminate the high intensity of pheromone trails that may\nbias ants to search at non-promising areas. In fact, the experi-\nments in Mavrovouniotis and Yang (2013) support this claim.\n3.4 Local search improvements\nMetaheuristics (such as ACO), which do not consider any\ngradient descent information when training a network, may\nnot be as accurate as those methods that use this informa-\ntion. Therefore, when an ant constructs a solution, a gradient\ndescent approach can be applied to improve the accuracy of\nACO training.\nGradient descent methods perform small step jumps to a\nneighbourhood of the search landscape and, thus, can locate\nthe optimum nearby. However, the (local) optimum located\nmay be far from the global optimum. In contrast, ACO per-\nforms large-step jumps and is more dif\ufb01cult to reach the opti-\nmum in a neighbourhood. However, ACO is more likely to\ndiscover different neighbourhoods than a gradient descent\nmethod due to its stochastic components.\nConsidering both aspects, a hybrid training method can be\napplied:theACOtrainingcanbeusedtodiscoverapromising\nneighbourhood, possibly containing the global optimum, in\nthe search space, and the gradient descent training can be\nused to locate the optimum in that speci\ufb01c neighbourhood.\n4 Experimental study\n4.1 Experimental setup\nTo evaluate the performance of the proposed ACO training\nalgorithm, it is compared with other algorithms in training\nfeed-forward neural networks for solving different bench-\nmark classi\ufb01cation problems (Prechelt 1994). The details\nregarding the con\ufb01guration of the networks and datasets used\nfordifferentproblemsareshowninTable1.Theexperimental\nstudy is divided into three parts. The algorithms implemented\nand compared in the \ufb01rst part of the experimental study (see\nSubsect. 4.2) include the following:\n1. Back-propagation (BP) (Rumelhart et al. 1986): the basic\nback-propagation training without any acceleration or\nother tweaking techniques such as momentum and so on.\n2. Levenberg\u2013Marquardt (LM) (Hagan and Menhaj 1994):\nthe standard Levenberg\u2013Marquardt training, which is\nanother gradient descent algorithm.\n3. ACO-BP: the proposed ACO training algorithm with the\ncombination of back-propagation, where each solution\nconstructed by ACO undergoes a local search improve-\nment by back-propagation.\n123\n", [169]], "3.2 Probabilistic solution construction": ["1514\nM. Mavrovouniotis, S. Yang\nprocess can be considered as a continuous optimization\nprocess (Blum and Socha 2005; Socha and Blum 2007).\nACOR utilizes the continuous probability density function.\nMore precisely, a solution archive is maintained in which\nthe worst solutions are replaced in every iteration. The solu-\ntions are constructed by sampling several probability den-\nsity functions which are derived from the solution archive.\nThe results of ACOR showed that a standalone ACO train-\ning algorithm is outperformed by gradient descent train-\ning, whereas a hybrid ACOR with back-propagation or\nLevenberg\u2013Marquardt training outperforms gradient descent\ntraining.\nA different ACO training was proposed in Liu et al. (2006)\nthat uses a framework that is close to the original ACO frame-\nwork rather than the ACOR framework. The key idea is\nto apply ACO training to \ufb01nd good initial weights for the\nback-propagation which is applied when ACO training is\nterminated. Their results showed that the ACO with back-\npropagation hybrid training is more effective and ef\ufb01cient\nthan the standalone back-propagation algorithm. Later on,\nthe above ACO training was improved by imposing limits to\nthe pheromone trails (Mavrovouniotis and Yang 2013).\nIn this paper, the ACO training based on the framework\nproposed in Mavrovouniotis and Yang (2013) is extended\nand furthermore investigated. The new framework is as\nshown in Fig. 2. The main extension is that back-propagation\ntraining is applied after each ACO iteration rather than\nwhen the ACO training terminates. In the following sub-\nsections, the proposed ACO training is described in more\ndetails.\nFig. 2 Framework of the ACO training for feed-forward neural net-\nworks\n3.1 Initialization\nFor ACO training, the optimal combination of connection\nweight values needs to be found. Given a neural network, the\nnumber of connection weights l is calculated as:\nl = nh(ni + 1) + no(nh + 1),\n(4)\nwhere nh, ni and no are the number of hidden, input, and\noutput units, respectively. The additional units represents the\nbias inputs of the units. Hence, ACO becomes a suf\ufb01cient\nchoice to select good combinations due to its good perfor-\nmance on different combinatorial optimization problems.\nThe key idea is to split the value range of each con-\nnection weight wi j from unit i to unit j into d discrete\npoints ai jh (h = 1, 2, . . . , d), which are generated from a\nnormal distribution. Each connection weight point ai jh is\nassigned a pheromone value \u03c4i jh in the pheromone table.\nThe pheromone table is initialized with an equal amount of\npheromone for all trails in the table as follows:\n\u03c4i jh \u21901/(ni + nh + no),\n\u2200ai jh,\n(5)\nwhere ni, nh and no are as de\ufb01ned in Eq. 4.\n3.2 Probabilistic solution construction\nIn the probabilistic solution construction, each ant selects\none and only one discrete point for each connection weight.\nAll the selected points of the previously visited connection\nweights are stored in the ant\u2019s (partial) memory. The dimen-\nsion of an ant\u2019s memory is determined by the number of\nconnection weights in the network, i.e., l, as de\ufb01ned in Eq. 4.\nMore precisely, with a probability 1 \u2212q, where q (0 \u2264\nq \u22641) is a parameter of the decision rule, an ant chooses a\nvalue for wi j from the set of discrete points probabilistically\nas follows:\npi jh =\n\u03c4i jh\n\u0007d\nk=1 \u03c4i jk\n,\n(6)\nwhere pi jh is the probability of selecting ai jh for wi j, d rep-\nresents the number of discrete points, and \u03c4i jh represents the\nexisting pheromone trail assigned with ai jh.\nFigure 3 illustrates how an ant selects values for the con-\nnection weights of unit i. For example, the values ai1h and\nai2h have been selected for connection weights wi1 and wi2,\nrespectively. Next, the ant needs to decide either with the\nprobability 1 \u2212q to select a value for wi3 according to\nthe existing pheromone trails or with the probability q to\nchoose the value with the maximum amount of pheromone.\nNote that the parameter q is used to tune the exploration\nand exploitation of the algorithm. The selection of discrete\n123\n", [169]], "3.1 Initialization": ["1514\nM. Mavrovouniotis, S. Yang\nprocess can be considered as a continuous optimization\nprocess (Blum and Socha 2005; Socha and Blum 2007).\nACOR utilizes the continuous probability density function.\nMore precisely, a solution archive is maintained in which\nthe worst solutions are replaced in every iteration. The solu-\ntions are constructed by sampling several probability den-\nsity functions which are derived from the solution archive.\nThe results of ACOR showed that a standalone ACO train-\ning algorithm is outperformed by gradient descent train-\ning, whereas a hybrid ACOR with back-propagation or\nLevenberg\u2013Marquardt training outperforms gradient descent\ntraining.\nA different ACO training was proposed in Liu et al. (2006)\nthat uses a framework that is close to the original ACO frame-\nwork rather than the ACOR framework. The key idea is\nto apply ACO training to \ufb01nd good initial weights for the\nback-propagation which is applied when ACO training is\nterminated. Their results showed that the ACO with back-\npropagation hybrid training is more effective and ef\ufb01cient\nthan the standalone back-propagation algorithm. Later on,\nthe above ACO training was improved by imposing limits to\nthe pheromone trails (Mavrovouniotis and Yang 2013).\nIn this paper, the ACO training based on the framework\nproposed in Mavrovouniotis and Yang (2013) is extended\nand furthermore investigated. The new framework is as\nshown in Fig. 2. The main extension is that back-propagation\ntraining is applied after each ACO iteration rather than\nwhen the ACO training terminates. In the following sub-\nsections, the proposed ACO training is described in more\ndetails.\nFig. 2 Framework of the ACO training for feed-forward neural net-\nworks\n3.1 Initialization\nFor ACO training, the optimal combination of connection\nweight values needs to be found. Given a neural network, the\nnumber of connection weights l is calculated as:\nl = nh(ni + 1) + no(nh + 1),\n(4)\nwhere nh, ni and no are the number of hidden, input, and\noutput units, respectively. The additional units represents the\nbias inputs of the units. Hence, ACO becomes a suf\ufb01cient\nchoice to select good combinations due to its good perfor-\nmance on different combinatorial optimization problems.\nThe key idea is to split the value range of each con-\nnection weight wi j from unit i to unit j into d discrete\npoints ai jh (h = 1, 2, . . . , d), which are generated from a\nnormal distribution. Each connection weight point ai jh is\nassigned a pheromone value \u03c4i jh in the pheromone table.\nThe pheromone table is initialized with an equal amount of\npheromone for all trails in the table as follows:\n\u03c4i jh \u21901/(ni + nh + no),\n\u2200ai jh,\n(5)\nwhere ni, nh and no are as de\ufb01ned in Eq. 4.\n3.2 Probabilistic solution construction\nIn the probabilistic solution construction, each ant selects\none and only one discrete point for each connection weight.\nAll the selected points of the previously visited connection\nweights are stored in the ant\u2019s (partial) memory. The dimen-\nsion of an ant\u2019s memory is determined by the number of\nconnection weights in the network, i.e., l, as de\ufb01ned in Eq. 4.\nMore precisely, with a probability 1 \u2212q, where q (0 \u2264\nq \u22641) is a parameter of the decision rule, an ant chooses a\nvalue for wi j from the set of discrete points probabilistically\nas follows:\npi jh =\n\u03c4i jh\n\u0007d\nk=1 \u03c4i jk\n,\n(6)\nwhere pi jh is the probability of selecting ai jh for wi j, d rep-\nresents the number of discrete points, and \u03c4i jh represents the\nexisting pheromone trail assigned with ai jh.\nFigure 3 illustrates how an ant selects values for the con-\nnection weights of unit i. For example, the values ai1h and\nai2h have been selected for connection weights wi1 and wi2,\nrespectively. Next, the ant needs to decide either with the\nprobability 1 \u2212q to select a value for wi3 according to\nthe existing pheromone trails or with the probability q to\nchoose the value with the maximum amount of pheromone.\nNote that the parameter q is used to tune the exploration\nand exploitation of the algorithm. The selection of discrete\n123\n", []], "3 The ant colony optimization training algorithm": ["Training neural networks with ACO algorithms for pattern classi\ufb01cation\n1513\nis associated with a single unit from the input layer and each\ndifferent class is associated with a single unit from the output\nlayer. The target parameter is used to calculate the network\nerror, i.e., the difference between the actual and target outputs\nwhen training is performed. The squared error percentage\n(SEP) is used to measure the network error, which is de\ufb01ned\nas follows:\nSEP = 100omax \u2212omin\nnonp\nE,\n(2)\nwhere omax and omin are the maximum and minimum output\nvalues of the output unit, respectively, np and no represent the\nnumber of patterns and the number of output units, respec-\ntively, and E is the squared error, de\ufb01ned as follows:\nE =\nn p\n\u0004\np=1\nno\n\u0004\ni=1\n(t p\ni \u2212op\ni )2,\n(3)\nwhere t p\ni and op\ni are the target and actual values of output\nunit i, respectively.\nGenerally, the aim of training a neural network is to min-\nimize the error, e.g., the SEP, of the network by adjust-\ning the connection weights to generate a classi\ufb01er that\ntakes patterns as input and provides their correct classi\ufb01-\ncation as output. Traditional training algorithms, such as the\nback-propagation algorithm (Rumelhart et al. 1986) and the\nLevenberg\u2013Marquardt algorithm (Hagan and Menhaj 1994;\nLevenberg 1944; Marquardt 1963), have been successfully\napplied to train neural networks (Hinton 1989; Lang et al.\n1990; Fels and Hinton 1993). The former algorithm is based\nongradientdescentandapproximatestheerrorofthenetwork\nwith a \ufb01rst-order expression, whereas the latter algorithm is\nbased on the Newton method and approximates the error of\nthe network with a second-order expression.\nBoth back-propagation and Levenberg\u2013Marquardt algo-\nrithms have a drawback because they often get trapped in\nlocal optima of the search landscape since they are local\noptimization algorithms (Sutton 1986; Whitley et al. 1990).\nOne way to avoid this drawback is to evolve the connection\nweights. Evolutionary algorithms, such as GAs (Alba and\nChicano 2004; Montana and Davis 1989), evolution strate-\ngies (Mandischer 2002), and estimation of distribution algo-\nrithms (Cotta et al. 2001), are typically used to perform the\nevolution process in the networks.\nDifferent from traditional training algorithms, evolution-\nary algorithms are global optimization methods, and thus, are\nless likely to get trapped in a local optimum. A comprehen-\nsive survey regarding evolutionary neural networks is avail-\nable in Yao (1999). Recently, swarm intelligence techniques,\nincluding PSO (Mendes et al. 2002; Carvalho and Ludermir\n2006), ABC (Karaboga et al. 2007; Ozturk and Karaboga\n2009) and ACO (Socha and Blum 2007), were also used to\ntrain neural networks. A review for other metaheuristics used\nfor training neural networks is available in Alba and Marti\n(2006).\nThere is a trade-off on whether training via metaheuristic\nis more ef\ufb01cient than training via gradient descent (Bullinaria\n2005). Some researchers have demonstrated that standalone\nevolutionary training is faster than gradient descent train-\ning (Montana and Davis 1989), whereas other researchers\nhave demonstrated that there is no any signi\ufb01cant differ-\nence between the two types of training and the difference\nreally depends on the problem (Socha and Blum 2007). How-\never, hybrid training with a GA (Alba and Chicano 2004) or\nACO (Liu et al. 2006; Socha and Blum 2007; Mavrovouni-\notis and Yang 2013) usually performs better than standalone\nmetaheuristics or gradient descent algorithms. This is due\nto the fact that metaheuristics are global optimization algo-\nrithms and they are less sensitive on the initial condition of\ntraining whereas local optimization algorithms \ufb01nd the local\noptimum in the neighbourhood of the initial weights given.\nFor example, in many cases the initial weights selected for\nback-propagation may lead to a very poor local optimum. To\naddress this issue, some hybrid training algorithms use the\nbest values obtained from ACO training as the initial weights\nfor back-propagation training (Liu et al. 2006; Mavrovouni-\notis and Yang 2013). The idea is to select a promising neigh-\nbourhood by ACO training and then search for the optimum\nby gradient descent training.\nFurthermore, it was discussed that simple training algo-\nrithms usually perform better than complex ones (Cantu-Paz\nand Kamath 2005). In fact, it was suggested that instead of\nusing a single large network to solve large and complex prob-\nlems, it is better to use a neural network ensemble that adopts\nthe divide-and-conquer strategy (Yao and Liu 1996, 1998). A\nneural network ensemble combines a set of simple networks\nthat learn to decompose the problem into sub-problems and\nthen solve them ef\ufb01ciently (Yao and Islam 2008).\n3 The ant colony optimization training algorithm\nThe ACO metaheuristic is inspired by the foraging behaviour\nof real ant colonies. ACO algorithms were initially proposed\nto solve combinatorial optimization problems (Dorigo and\nGambardella 1997; Bullnheimer et al. 1999; Dorigo et al.\n1999). In general, an ACO algorithm consists of two modes,\ni.e., the forward and backward modes. In the forward mode, a\npopulation of ants construct solutions probabilistically based\non existing pheromone trails. In the backward mode, the solu-\ntion constructed, including the solution quality, is used to\nupdate pheromone trails. After several iterations, the ants\nwill converge into a near-optimum or optimum solution.\nRecently, ACOR was proposed (Socha 2004) and applied\nto train feed-forward neural networks since the training\n123\n", []], "2.2 Training artificial neural networks": ["1512\nM. Mavrovouniotis, S. Yang\nof swarm intelligence for pattern classi\ufb01cation include parti-\ncleswarmoptimization(PSO) (CarvalhoandLudermir 2006;\nMendes et al. 2002), arti\ufb01cial bee colony (ABC) (Ozturk and\nKaraboga 2009) and ant colony optimization (ACO) (Blum\nand Socha 2005; Socha and Blum 2007). Among these devel-\nopments, ACO has attracted less attention than PSO and ABC\nsince it was originally introduced to solve discrete optimiza-\ntion problems (Dorigo and Gambardella 1997; Dorigo and\nSt\u00fctzle 2004) rather than training neural networks, which is a\nnumerical (continuous) optimization problem (Socha 2004;\nSocha and Blum 2007).\nACO training includes two main developments. First, the\nhybridizationofACOwithback-propagation(Liuetal.2006)\nuses the traditional ACO framework, where a population\nof ants construct solutions (e.g., a combination of connec-\ntion weights) and update the pheromone table (Dorigo et al.\n1996). Recently, an improved variation has been proposed\nin Mavrovouniotis and Yang (2013), which is based on the\npheromone update policy of the MAX-MIN ant system\n(St\u00fctzle and Hoos 1997). Second, the ACO for continuous\noptimization, denoted as ACOR, which follows a different\napproach from the well-known ACO framework, was pro-\nposed in Blum and Socha (2005). ACOR utilizes the contin-\nuous probability density function.\nThe key idea of the aforementioned hybrid ACO with\nback-propagation training (Mavrovouniotis and Yang 2013;\nLiu et al. 2006) is to run ACO for several iterations to\nselect the initial connection weights, and then perform\nback-propagation training. This paper extends the work\nin Mavrovouniotis and Yang (2013) and applies back-\npropagation, as a local search improvement, to each solution\nconstructed at each ACO iteration. To fully investigate the\nperformance of the proposed ACO training methods, they\nare further compared with several other swarm intelligence,\nevolutionary and traditional training methods on several real-\nworld problem datasets.\nThe rest of the paper is outlined as follows. Section 2\ndescribes the training process in neural networks. Section 3\ndescribes the proposed ACO framework for training feed-\nforward neural networks. In Sect. 4, the experimental results\nand analysis are given. Finally, several concluding remarks\nand direction for future work are given in Sect. 5.\n2 Training feed-forward neural networks\n2.1 Description of arti\ufb01cial neural networks\nA feed-forward neural network consists of a number of units\n(neurons) that are allocated in different layers, i.e., input, hid-\nden, or output layers, which are interconnected. Typically,\ndirected graphs are used to represent the network, where\nnodes represent the units and arcs represent the connections\n(a)\n(b)\nFig. 1 a Feed-forward neural network with a single hidden layer. b\nUnit (from any layer) process of a feed-forward neural network\nbetween them. Each arc holds a value, which is the connec-\ntion weight between a pair of units. Within the feed-forward\nmodel, all connections of the network are strictly forwarded\nfrom the input units to the hidden units and \ufb01nally to the out-\nput units. For example, Fig. 1a presents a feed-forward neural\nnetwork with one input layer of three units, one hidden layer\nof \ufb01ve units and one output layer of two units.\nEach unit i performs a function, which is de\ufb01ned as:\nyi = fi\n\u239b\n\u239d\nn\n\u0004\nj=1\nwi j x j \u2212\u03b8i\n\u239e\n\u23a0,\n(1)\nwhere fi represents theactivationfunction(usuallyasigmoid\nor Gaussian function) of unit i, yi is the output of unit i, wi j\nrepresents the connection weight between units i and j, x j\nrepresents the j-th input of the unit, and \u03b8i is the threshold\n(or bias) of unit i. An illustration of the processing of a unit,\nsay unit i, is given i is given in Fig. 1b.\n2.2 Training arti\ufb01cial neural networks\nOnce the network\u2019s architecture is decided, then training\nneeds to be performed to determine the weights of the con-\nnections before the network is used. Feed-forward neural net-\nworks are typically applied for pattern classi\ufb01cation (Bishop\n1995) and supervised learning is a convenient way to train\nthem.\nSupervised learning requires a training set that consists of\nseveral input parameters and corresponding target parameter\nthat de\ufb01nes the correct classi\ufb01cation. Each input parameter\n123\n", []], "2.1 Description of artificial neural networks": ["1512\nM. Mavrovouniotis, S. Yang\nof swarm intelligence for pattern classi\ufb01cation include parti-\ncleswarmoptimization(PSO) (CarvalhoandLudermir 2006;\nMendes et al. 2002), arti\ufb01cial bee colony (ABC) (Ozturk and\nKaraboga 2009) and ant colony optimization (ACO) (Blum\nand Socha 2005; Socha and Blum 2007). Among these devel-\nopments, ACO has attracted less attention than PSO and ABC\nsince it was originally introduced to solve discrete optimiza-\ntion problems (Dorigo and Gambardella 1997; Dorigo and\nSt\u00fctzle 2004) rather than training neural networks, which is a\nnumerical (continuous) optimization problem (Socha 2004;\nSocha and Blum 2007).\nACO training includes two main developments. First, the\nhybridizationofACOwithback-propagation(Liuetal.2006)\nuses the traditional ACO framework, where a population\nof ants construct solutions (e.g., a combination of connec-\ntion weights) and update the pheromone table (Dorigo et al.\n1996). Recently, an improved variation has been proposed\nin Mavrovouniotis and Yang (2013), which is based on the\npheromone update policy of the MAX-MIN ant system\n(St\u00fctzle and Hoos 1997). Second, the ACO for continuous\noptimization, denoted as ACOR, which follows a different\napproach from the well-known ACO framework, was pro-\nposed in Blum and Socha (2005). ACOR utilizes the contin-\nuous probability density function.\nThe key idea of the aforementioned hybrid ACO with\nback-propagation training (Mavrovouniotis and Yang 2013;\nLiu et al. 2006) is to run ACO for several iterations to\nselect the initial connection weights, and then perform\nback-propagation training. This paper extends the work\nin Mavrovouniotis and Yang (2013) and applies back-\npropagation, as a local search improvement, to each solution\nconstructed at each ACO iteration. To fully investigate the\nperformance of the proposed ACO training methods, they\nare further compared with several other swarm intelligence,\nevolutionary and traditional training methods on several real-\nworld problem datasets.\nThe rest of the paper is outlined as follows. Section 2\ndescribes the training process in neural networks. Section 3\ndescribes the proposed ACO framework for training feed-\nforward neural networks. In Sect. 4, the experimental results\nand analysis are given. Finally, several concluding remarks\nand direction for future work are given in Sect. 5.\n2 Training feed-forward neural networks\n2.1 Description of arti\ufb01cial neural networks\nA feed-forward neural network consists of a number of units\n(neurons) that are allocated in different layers, i.e., input, hid-\nden, or output layers, which are interconnected. Typically,\ndirected graphs are used to represent the network, where\nnodes represent the units and arcs represent the connections\n(a)\n(b)\nFig. 1 a Feed-forward neural network with a single hidden layer. b\nUnit (from any layer) process of a feed-forward neural network\nbetween them. Each arc holds a value, which is the connec-\ntion weight between a pair of units. Within the feed-forward\nmodel, all connections of the network are strictly forwarded\nfrom the input units to the hidden units and \ufb01nally to the out-\nput units. For example, Fig. 1a presents a feed-forward neural\nnetwork with one input layer of three units, one hidden layer\nof \ufb01ve units and one output layer of two units.\nEach unit i performs a function, which is de\ufb01ned as:\nyi = fi\n\u239b\n\u239d\nn\n\u0004\nj=1\nwi j x j \u2212\u03b8i\n\u239e\n\u23a0,\n(1)\nwhere fi represents theactivationfunction(usuallyasigmoid\nor Gaussian function) of unit i, yi is the output of unit i, wi j\nrepresents the connection weight between units i and j, x j\nrepresents the j-th input of the unit, and \u03b8i is the threshold\n(or bias) of unit i. An illustration of the processing of a unit,\nsay unit i, is given i is given in Fig. 1b.\n2.2 Training arti\ufb01cial neural networks\nOnce the network\u2019s architecture is decided, then training\nneeds to be performed to determine the weights of the con-\nnections before the network is used. Feed-forward neural net-\nworks are typically applied for pattern classi\ufb01cation (Bishop\n1995) and supervised learning is a convenient way to train\nthem.\nSupervised learning requires a training set that consists of\nseveral input parameters and corresponding target parameter\nthat de\ufb01nes the correct classi\ufb01cation. Each input parameter\n123\n", []], "2 Training feed-forward neural networks": ["1512\nM. Mavrovouniotis, S. Yang\nof swarm intelligence for pattern classi\ufb01cation include parti-\ncleswarmoptimization(PSO) (CarvalhoandLudermir 2006;\nMendes et al. 2002), arti\ufb01cial bee colony (ABC) (Ozturk and\nKaraboga 2009) and ant colony optimization (ACO) (Blum\nand Socha 2005; Socha and Blum 2007). Among these devel-\nopments, ACO has attracted less attention than PSO and ABC\nsince it was originally introduced to solve discrete optimiza-\ntion problems (Dorigo and Gambardella 1997; Dorigo and\nSt\u00fctzle 2004) rather than training neural networks, which is a\nnumerical (continuous) optimization problem (Socha 2004;\nSocha and Blum 2007).\nACO training includes two main developments. First, the\nhybridizationofACOwithback-propagation(Liuetal.2006)\nuses the traditional ACO framework, where a population\nof ants construct solutions (e.g., a combination of connec-\ntion weights) and update the pheromone table (Dorigo et al.\n1996). Recently, an improved variation has been proposed\nin Mavrovouniotis and Yang (2013), which is based on the\npheromone update policy of the MAX-MIN ant system\n(St\u00fctzle and Hoos 1997). Second, the ACO for continuous\noptimization, denoted as ACOR, which follows a different\napproach from the well-known ACO framework, was pro-\nposed in Blum and Socha (2005). ACOR utilizes the contin-\nuous probability density function.\nThe key idea of the aforementioned hybrid ACO with\nback-propagation training (Mavrovouniotis and Yang 2013;\nLiu et al. 2006) is to run ACO for several iterations to\nselect the initial connection weights, and then perform\nback-propagation training. This paper extends the work\nin Mavrovouniotis and Yang (2013) and applies back-\npropagation, as a local search improvement, to each solution\nconstructed at each ACO iteration. To fully investigate the\nperformance of the proposed ACO training methods, they\nare further compared with several other swarm intelligence,\nevolutionary and traditional training methods on several real-\nworld problem datasets.\nThe rest of the paper is outlined as follows. Section 2\ndescribes the training process in neural networks. Section 3\ndescribes the proposed ACO framework for training feed-\nforward neural networks. In Sect. 4, the experimental results\nand analysis are given. Finally, several concluding remarks\nand direction for future work are given in Sect. 5.\n2 Training feed-forward neural networks\n2.1 Description of arti\ufb01cial neural networks\nA feed-forward neural network consists of a number of units\n(neurons) that are allocated in different layers, i.e., input, hid-\nden, or output layers, which are interconnected. Typically,\ndirected graphs are used to represent the network, where\nnodes represent the units and arcs represent the connections\n(a)\n(b)\nFig. 1 a Feed-forward neural network with a single hidden layer. b\nUnit (from any layer) process of a feed-forward neural network\nbetween them. Each arc holds a value, which is the connec-\ntion weight between a pair of units. Within the feed-forward\nmodel, all connections of the network are strictly forwarded\nfrom the input units to the hidden units and \ufb01nally to the out-\nput units. For example, Fig. 1a presents a feed-forward neural\nnetwork with one input layer of three units, one hidden layer\nof \ufb01ve units and one output layer of two units.\nEach unit i performs a function, which is de\ufb01ned as:\nyi = fi\n\u239b\n\u239d\nn\n\u0004\nj=1\nwi j x j \u2212\u03b8i\n\u239e\n\u23a0,\n(1)\nwhere fi represents theactivationfunction(usuallyasigmoid\nor Gaussian function) of unit i, yi is the output of unit i, wi j\nrepresents the connection weight between units i and j, x j\nrepresents the j-th input of the unit, and \u03b8i is the threshold\n(or bias) of unit i. An illustration of the processing of a unit,\nsay unit i, is given i is given in Fig. 1b.\n2.2 Training arti\ufb01cial neural networks\nOnce the network\u2019s architecture is decided, then training\nneeds to be performed to determine the weights of the con-\nnections before the network is used. Feed-forward neural net-\nworks are typically applied for pattern classi\ufb01cation (Bishop\n1995) and supervised learning is a convenient way to train\nthem.\nSupervised learning requires a training set that consists of\nseveral input parameters and corresponding target parameter\nthat de\ufb01nes the correct classi\ufb01cation. Each input parameter\n123\n", []], "1 Introduction": ["Soft Comput (2015) 19:1511\u20131522\nDOI 10.1007/s00500-014-1334-5\nFOCUS\nTraining neural networks with ant colony optimization algorithms\nfor pattern classi\ufb01cation\nMichalis Mavrovouniotis \u00b7 Shengxiang Yang\nPublished online: 18 June 2014\n\u00a9 Springer-Verlag Berlin Heidelberg 2014\nAbstract\nFeed-forward neural networks are commonly\nused for pattern classi\ufb01cation. The classi\ufb01cation accuracy\nof feed-forward neural networks depends on the con\ufb01gura-\ntion selected and the training process. Once the architec-\nture of the network is decided, training algorithms, usu-\nally gradient descent techniques, are used to determine the\nconnection weights of the feed-forward neural network.\nHowever, gradient descent techniques often get trapped in\nlocal optima of the search landscape. To address this issue,\nan ant colony optimization (ACO) algorithm is applied\nto train feed-forward neural networks for pattern classi\ufb01-\ncation in this paper. In addition, the ACO training algo-\nrithm is hybridized with gradient descent training. Both\nstandalone and hybrid ACO training algorithms are evalu-\nated on several benchmark pattern classi\ufb01cation problems,\nand compared with other swarm intelligence, evolution-\nary and traditional training algorithms. The experimental\nresults show the ef\ufb01ciency of the proposed ACO train-\ning algorithms for feed-forward neural networks for pattern\nclassi\ufb01cation.\nKeywords\nNeural networks \u00b7 Pattern classi\ufb01cation \u00b7\nAnt colony optimization\nCommunicated by V. Loia.\nM. Mavrovouniotis (B) \u00b7 S. Yang\nCentre for Computational Intelligence (CCI), School of Computer\nScience and Informatics, De Montfort University, The Gateway,\nLeicester LE1 9BH, UK\ne-mail: mmavrovouniotis@dmu.ac.uk\nS. Yang\ne-mail: syang@dmu.ac.uk\n1 Introduction\nArti\ufb01cial neural networks are commonly used for pattern\nclassi\ufb01cationproblems(CarpenterandGrossberg1988;Day-\nhoff 1990; Mehrotra et al. 1997; Zhang 2000). Feed-forward\nneural networks are typically used to perform the classi\ufb01ca-\ntion task (Bishop 1995). However, for a feed-forward neural\nnetwork to perform classi\ufb01cation properly, a prior con\ufb01gu-\nration is required: (a) the architecture of the network needs\nto be determined, and (b) the connection weights of the net-\nwork need to be determined. In this paper, we focus on the\nlatter con\ufb01guration of a feed-forward neural network, where\nthe optimal combination of numerical values for the connec-\ntions weights is to be found.\nTypically, gradient descent techniques, such as the back-\npropagation algorithm (Rumelhart et al. 1986), are used to\nadjust the connection weights. A serious drawback of gradi-\nent descent training techniques is that they often get trapped\nin local optima since they perform trajectory searching (Sut-\nton 1986; Whitley et al. 1990). One way to overcome this\ndrawback is to adopt non-trajectory searching methods that\nperform longer \u201cjumps\u201d in the search space than trajectory\nmethods, e.g., global optimization algorithms. Such algo-\nrithms are less likely to get trapped in a local optima than gra-\ndient descent algorithms. Usually, evolutionary algorithms,\ne.g., genetic algorithms (GAs) (Alba and Chicano 2004;\nMontana and Davis 1989), evolution strategies (Mandischer\n2002), differential evolution (DE) (Ilonen et al. 2003) and\nestimation of distribution algorithms (Cotta et al. 2001), are\nused to train feed-forward neural networks.\nRecently, another class of global optimization algorithms,\ni.e., swarm intelligence (Bonabeau et al. 1997), has been used\nfor training. Swarm intelligence algorithms are inspired from\nthe natural behaviour of social insects, such as the ant forag-\ning, bird \ufb02ocking, \ufb01sh schooling, and so on. The applications\n123\n", [1413, 1416, 1419, 1420, 1423, 1424, 1425, 1428, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445]], "Abstract ": ["Soft Comput (2015) 19:1511\u20131522\nDOI 10.1007/s00500-014-1334-5\nFOCUS\nTraining neural networks with ant colony optimization algorithms\nfor pattern classi\ufb01cation\nMichalis Mavrovouniotis \u00b7 Shengxiang Yang\nPublished online: 18 June 2014\n\u00a9 Springer-Verlag Berlin Heidelberg 2014\nAbstract\nFeed-forward neural networks are commonly\nused for pattern classi\ufb01cation. The classi\ufb01cation accuracy\nof feed-forward neural networks depends on the con\ufb01gura-\ntion selected and the training process. Once the architec-\nture of the network is decided, training algorithms, usu-\nally gradient descent techniques, are used to determine the\nconnection weights of the feed-forward neural network.\nHowever, gradient descent techniques often get trapped in\nlocal optima of the search landscape. To address this issue,\nan ant colony optimization (ACO) algorithm is applied\nto train feed-forward neural networks for pattern classi\ufb01-\ncation in this paper. In addition, the ACO training algo-\nrithm is hybridized with gradient descent training. Both\nstandalone and hybrid ACO training algorithms are evalu-\nated on several benchmark pattern classi\ufb01cation problems,\nand compared with other swarm intelligence, evolution-\nary and traditional training algorithms. The experimental\nresults show the ef\ufb01ciency of the proposed ACO train-\ning algorithms for feed-forward neural networks for pattern\nclassi\ufb01cation.\nKeywords\nNeural networks \u00b7 Pattern classi\ufb01cation \u00b7\nAnt colony optimization\nCommunicated by V. Loia.\nM. Mavrovouniotis (B) \u00b7 S. Yang\nCentre for Computational Intelligence (CCI), School of Computer\nScience and Informatics, De Montfort University, The Gateway,\nLeicester LE1 9BH, UK\ne-mail: mmavrovouniotis@dmu.ac.uk\nS. Yang\ne-mail: syang@dmu.ac.uk\n1 Introduction\nArti\ufb01cial neural networks are commonly used for pattern\nclassi\ufb01cationproblems(CarpenterandGrossberg1988;Day-\nhoff 1990; Mehrotra et al. 1997; Zhang 2000). Feed-forward\nneural networks are typically used to perform the classi\ufb01ca-\ntion task (Bishop 1995). However, for a feed-forward neural\nnetwork to perform classi\ufb01cation properly, a prior con\ufb01gu-\nration is required: (a) the architecture of the network needs\nto be determined, and (b) the connection weights of the net-\nwork need to be determined. In this paper, we focus on the\nlatter con\ufb01guration of a feed-forward neural network, where\nthe optimal combination of numerical values for the connec-\ntions weights is to be found.\nTypically, gradient descent techniques, such as the back-\npropagation algorithm (Rumelhart et al. 1986), are used to\nadjust the connection weights. A serious drawback of gradi-\nent descent training techniques is that they often get trapped\nin local optima since they perform trajectory searching (Sut-\nton 1986; Whitley et al. 1990). One way to overcome this\ndrawback is to adopt non-trajectory searching methods that\nperform longer \u201cjumps\u201d in the search space than trajectory\nmethods, e.g., global optimization algorithms. Such algo-\nrithms are less likely to get trapped in a local optima than gra-\ndient descent algorithms. Usually, evolutionary algorithms,\ne.g., genetic algorithms (GAs) (Alba and Chicano 2004;\nMontana and Davis 1989), evolution strategies (Mandischer\n2002), differential evolution (DE) (Ilonen et al. 2003) and\nestimation of distribution algorithms (Cotta et al. 2001), are\nused to train feed-forward neural networks.\nRecently, another class of global optimization algorithms,\ni.e., swarm intelligence (Bonabeau et al. 1997), has been used\nfor training. Swarm intelligence algorithms are inspired from\nthe natural behaviour of social insects, such as the ant forag-\ning, bird \ufb02ocking, \ufb01sh schooling, and so on. The applications\n123\n", [1413, 1416, 1419, 1420, 1423, 1424, 1425, 1428, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445]], "Training neural networks with ant colony optimization algorithms for pattern classification": ["Soft Comput (2015) 19:1511\u20131522\nDOI 10.1007/s00500-014-1334-5\nFOCUS\nTraining neural networks with ant colony optimization algorithms\nfor pattern classi\ufb01cation\nMichalis Mavrovouniotis \u00b7 Shengxiang Yang\nPublished online: 18 June 2014\n\u00a9 Springer-Verlag Berlin Heidelberg 2014\nAbstract\nFeed-forward neural networks are commonly\nused for pattern classi\ufb01cation. The classi\ufb01cation accuracy\nof feed-forward neural networks depends on the con\ufb01gura-\ntion selected and the training process. Once the architec-\nture of the network is decided, training algorithms, usu-\nally gradient descent techniques, are used to determine the\nconnection weights of the feed-forward neural network.\nHowever, gradient descent techniques often get trapped in\nlocal optima of the search landscape. To address this issue,\nan ant colony optimization (ACO) algorithm is applied\nto train feed-forward neural networks for pattern classi\ufb01-\ncation in this paper. In addition, the ACO training algo-\nrithm is hybridized with gradient descent training. Both\nstandalone and hybrid ACO training algorithms are evalu-\nated on several benchmark pattern classi\ufb01cation problems,\nand compared with other swarm intelligence, evolution-\nary and traditional training algorithms. The experimental\nresults show the ef\ufb01ciency of the proposed ACO train-\ning algorithms for feed-forward neural networks for pattern\nclassi\ufb01cation.\nKeywords\nNeural networks \u00b7 Pattern classi\ufb01cation \u00b7\nAnt colony optimization\nCommunicated by V. Loia.\nM. Mavrovouniotis (B) \u00b7 S. Yang\nCentre for Computational Intelligence (CCI), School of Computer\nScience and Informatics, De Montfort University, The Gateway,\nLeicester LE1 9BH, UK\ne-mail: mmavrovouniotis@dmu.ac.uk\nS. Yang\ne-mail: syang@dmu.ac.uk\n1 Introduction\nArti\ufb01cial neural networks are commonly used for pattern\nclassi\ufb01cationproblems(CarpenterandGrossberg1988;Day-\nhoff 1990; Mehrotra et al. 1997; Zhang 2000). Feed-forward\nneural networks are typically used to perform the classi\ufb01ca-\ntion task (Bishop 1995). However, for a feed-forward neural\nnetwork to perform classi\ufb01cation properly, a prior con\ufb01gu-\nration is required: (a) the architecture of the network needs\nto be determined, and (b) the connection weights of the net-\nwork need to be determined. In this paper, we focus on the\nlatter con\ufb01guration of a feed-forward neural network, where\nthe optimal combination of numerical values for the connec-\ntions weights is to be found.\nTypically, gradient descent techniques, such as the back-\npropagation algorithm (Rumelhart et al. 1986), are used to\nadjust the connection weights. A serious drawback of gradi-\nent descent training techniques is that they often get trapped\nin local optima since they perform trajectory searching (Sut-\nton 1986; Whitley et al. 1990). One way to overcome this\ndrawback is to adopt non-trajectory searching methods that\nperform longer \u201cjumps\u201d in the search space than trajectory\nmethods, e.g., global optimization algorithms. Such algo-\nrithms are less likely to get trapped in a local optima than gra-\ndient descent algorithms. Usually, evolutionary algorithms,\ne.g., genetic algorithms (GAs) (Alba and Chicano 2004;\nMontana and Davis 1989), evolution strategies (Mandischer\n2002), differential evolution (DE) (Ilonen et al. 2003) and\nestimation of distribution algorithms (Cotta et al. 2001), are\nused to train feed-forward neural networks.\nRecently, another class of global optimization algorithms,\ni.e., swarm intelligence (Bonabeau et al. 1997), has been used\nfor training. Swarm intelligence algorithms are inspired from\nthe natural behaviour of social insects, such as the ant forag-\ning, bird \ufb02ocking, \ufb01sh schooling, and so on. The applications\n123\n", [1413, 1416, 1419, 1420, 1423, 1424, 1425, 1428, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445]]}